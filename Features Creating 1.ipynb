{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"# 导入基本的一些库\nimport warnings\nwarnings.simplefilter(action='ignore', category=FutureWarning)\nwarnings.filterwarnings(\"ignore\")\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport gc\nfrom tqdm import tqdm_notebook\nimport datetime\nimport os\nimport random\n\nfrom joblib import Parallel, delayed\n%env JOBLIB_TEMP_FOLDER=/tmp\n\nimport scipy as sc\nfrom scipy import stats\nfrom scipy import signal\nfrom scipy import fftpack \nfrom scipy import optimize\nfrom scipy import fftpack\nimport pywt\n\nfrom tsfresh.feature_extraction import feature_calculators\nimport librosa\nimport librosa.display as ld\n\nfrom sklearn.metrics import mean_absolute_error\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.model_selection import KFold\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.cluster import KMeans\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\n#读取数据\nPATH = \"../input/LANL-Earthquake-Prediction/\"\ntrain = pd.read_pickle(\"../input/lanl-training-as-pickle/train.pkl\")\n# 清理内存\ngc.collect()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# DENOISING\n# 信号长度\nSIGNAL_LEN = 150000\n# 采样率\nSAMPLE_RATE = 4000\n# 信号长度\nSIG_LEN = 150000\n#每次处理的信号个数\nNUM_SEG_PER_PROC = 4000\n# 使用的线程的个数\nNUM_THREADS = 6\n\n# 奈奎斯特采样频率\nNY_FREQ_IDX = 75000  # 信号个数/2，如果比这个大，那就会出现信号失真的现象\n# 截断频率\nCUTOFF = 18000\n# 最高频率\nMAX_FREQ_IDX = 20000\n# 频率窗大小\nFREQ_STEP = 2500\n\n# 平均绝对值偏差\ndef maddest(d, axis=None):\n    return np.mean(np.absolute(d - np.mean(d, axis)), axis)\n\n# 高通滤波器\ndef high_pass_filter(x, low_cutoff=1000, SAMPLE_RATE=SAMPLE_RATE):\n    \n    # 计算奈奎斯特频率 0.5*采样率\n    nyquist = 0.5 * SAMPLE_RATE\n    # 使用奈奎斯特频率归一化的截止频率\n    norm_low_cutoff = low_cutoff / nyquist\n    \n    #使用sos滤波器进行高通滤波，滤除噪音\n    sos = signal.butter(10, Wn=[norm_low_cutoff], btype='highpass', output='sos')\n    filtered_sig = signal.sosfilt(sos, x)\n\n    return filtered_sig\n\n# 信号去噪，这个采用别人的方案\ndef denoise_signal(x, wavelet='db4', level=1):\n    \"\"\"\n    1. Adapted from waveletSmooth function found here:\n    http://connor-johnson.com/2016/01/24/using-pywavelets-to-remove-high-frequency-noise/\n    2. Threshold equation and using hard mode in threshold as mentioned\n    in section '3.2 denoising based on optimized singular values' from paper by Tomas Vantuch:\n    http://dspace.vsb.cz/bitstream/handle/10084/133114/VAN431_FEI_P1807_1801V001_2018.pdf\n    \"\"\"\n    \n    # Decompose to get the wavelet coefficients\n    coeff = pywt.wavedec(x, wavelet, mode=\"per\")\n    \n    # Calculate sigma for threshold as defined in http://dspace.vsb.cz/bitstream/handle/10084/133114/VAN431_FEI_P1807_1801V001_2018.pdf\n    # As noted by @harshit92 MAD referred to in the paper is Mean Absolute Deviation not Median Absolute Deviation\n    sigma = (1/0.6745) * maddest(coeff[-level])\n\n    # Calculate the univeral threshold\n    uthresh = sigma * np.sqrt(2*np.log(len(x)))\n    coeff[1:] = (pywt.threshold(i, value=uthresh, mode='hard') for i in coeff[1:])\n    \n    # Reconstruct the signal using the thresholded coefficients\n    return pywt.waverec(coeff, wavelet, mode='per')\n\n# 移动平均法,periods的大小为平均的周期，移动平均法用来反映趋势，去掉噪声带来的干扰\ndef moving_average(data_set, periods=3):\n    weights = np.ones(periods) / periods\n    return np.convolve(data_set, weights, mode='same')\n\n# 4 阶巴特沃斯低通滤波器\ndef des_bw_filter_lp(cutoff=CUTOFF):  # low pass filter\n    b, a = signal.butter(4, Wn=cutoff/NY_FREQ_IDX)\n    return b, a\n\n# 4 阶巴特沃斯高通滤波器\ndef des_bw_filter_hp(cutoff=CUTOFF):  # high pass filter\n    b, a = signal.butter(4, Wn=cutoff/NY_FREQ_IDX, btype='highpass')\n    return b, a\n\n# 4 阶巴特沃斯带通滤波器\ndef des_bw_filter_bp(low, high):  # band pass filter\n    b, a = signal.butter(4, Wn=(low/NY_FREQ_IDX, high/NY_FREQ_IDX), btype='bandpass')\n    return b, a\n\n# 获取趋势特征，通过对信号进行线性回归，得到其斜率lr.coef_[0]\ndef add_trend_feature(arr, abs_values=False):\n    idx = np.array(range(len(arr)))\n    if abs_values:\n        arr = np.abs(arr)\n    lr = LinearRegression()\n    lr.fit(idx.reshape(-1, 1), arr)\n    return lr.coef_[0]\n\n# sta_lta也就是sta/lta,长短期视窗法，sta短视窗，可以预测短期地震波动，lta长视窗，放映长期趋势\ndef classic_sta_lta(x, length_sta, length_lta):\n    # 计算x^2的累加\n    sta = np.cumsum(x ** 2)\n    # 转换为浮点型\n    sta = np.require(sta, dtype=np.float)\n    lta = sta.copy()\n    # 通过相减计算sta，和lta,其中length_sta<length_lta\n    sta[length_sta:] = sta[length_sta:] - sta[:-length_sta]\n    sta /= length_sta\n    lta[length_lta:] = lta[length_lta:] - lta[:-length_lta]\n    lta /= length_lta\n    \n    # sta比lta要短，所以末端补0\n    sta[:length_lta - 1] = 0\n    # 使用一个较小值代替sta里面的接近0值\n    dtiny = np.finfo(0.0).tiny\n    idx = lta < dtiny\n    lta[idx] = dtiny\n    #计算sta/lta\n    return sta / lta","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"#并行构造特征\ndef create_features_parallel(seg, mean=1):    \n    \n    X = pd.DataFrame(index=range(1))\n    if mean == 1:\n        X[\"time_to_failure\"] = seg.time_to_failure.values[-1]\n    \n    # 读取信号并且去均值\n    xc = pd.Series(seg['acoustic_data'].values)\n    xcdm = xc - np.mean(xc)\n    \n    # 使用截止频率18000做低通滤波\n    b, a = des_bw_filter_lp(cutoff=18000)\n    xcz = signal.lfilter(b, a, xcdm)\n    \n    # 做傅里叶变换，并取20000以下的频率做分析\n    zc = np.fft.fft(xcz)\n    zc = zc[:MAX_FREQ_IDX]\n\n    # FFT变换的实部和虚部\n    realFFT = np.real(zc)\n    imagFFT = np.imag(zc)\n    \n    # 每隔2500,一直到20000取频率窗\n    freq_bands = [x for x in range(0, MAX_FREQ_IDX, FREQ_STEP)]\n    # 通过实部虚部计算fft的幅度\n    magFFT = np.sqrt(realFFT ** 2 + imagFFT ** 2)\n    # 通过实部虚部计算fft的相位\n    phzFFT = np.arctan(imagFFT / realFFT)\n    # 相位的负无穷为负二分之π，正无穷为正二分之π\n    phzFFT[phzFFT == -np.inf] = -np.pi / 2.0\n    phzFFT[phzFFT == np.inf] = np.pi / 2.0\n    # 使用0代替nan\n    phzFFT = np.nan_to_num(phzFFT)\n\n    # 计算每个频率窗里面的一些统计数据(百分位点数据，幅度的均值，方差，最大值，相位的均值和方差)\n    for freq in freq_bands:\n        X['FFT_Mag_01q%d' % freq] = np.quantile(magFFT[freq: freq + FREQ_STEP], 0.01)\n        X['FFT_Mag_10q%d' % freq] = np.quantile(magFFT[freq: freq + FREQ_STEP], 0.1)\n        X['FFT_Mag_90q%d' % freq] = np.quantile(magFFT[freq: freq + FREQ_STEP], 0.9)\n        X['FFT_Mag_99q%d' % freq] = np.quantile(magFFT[freq: freq + FREQ_STEP], 0.99)\n        X['FFT_Mag_mean%d' % freq] = np.mean(magFFT[freq: freq + FREQ_STEP])\n        X['FFT_Mag_std%d' % freq] = np.std(magFFT[freq: freq + FREQ_STEP])\n        X['FFT_Mag_max%d' % freq] = np.max(magFFT[freq: freq + FREQ_STEP])\n\n        X['FFT_Phz_mean%d' % freq] = np.mean(phzFFT[freq: freq + FREQ_STEP])\n        X['FFT_Phz_std%d' % freq] = np.std(phzFFT[freq: freq + FREQ_STEP])\n    \n    # 计算实部的统计特性\n    X['FFT_Rmean'] = realFFT.mean()\n    X['FFT_Rstd'] = realFFT.std()\n    X['FFT_Rmax'] = realFFT.max()\n    X['FFT_Rmin'] = realFFT.min()\n    \n    # 计算虚部的统计特性\n    X['FFT_Imean'] = imagFFT.mean()\n    X['FFT_Istd'] = imagFFT.std()\n    X['FFT_Imax'] = imagFFT.max()\n    X['FFT_Imin'] = imagFFT.min()\n    \n    # 计算前6000个实部的统计特性(最多只有20000个)\n    X['FFT_Rmean_first_6000'] = realFFT[:6000].mean()\n    X['FFT_Rstd__first_6000'] = realFFT[:6000].std()\n    X['FFT_Rmax_first_6000'] = realFFT[:6000].max()\n    X['FFT_Rmin_first_6000'] = realFFT[:6000].min()\n    # 计算前18000个实部的统计特性\n    X['FFT_Rmean_first_18000'] = realFFT[:18000].mean()\n    X['FFT_Rstd_first_18000'] = realFFT[:18000].std()\n    X['FFT_Rmax_first_18000'] = realFFT[:18000].max()\n    X['FFT_Rmin_first_18000'] = realFFT[:18000].min()\n\n    # 删除无用的变量清楚缓存\n    del xcz\n    del zc\n\n    # 之前是对0到18000频率段内所有信号在频率内做分析，下面是每2500hz的频率窗内的时域的信号做分析\n    # < 2500\n    b, a = des_bw_filter_lp(cutoff=2500)\n    xc0 = signal.lfilter(b, a, xcdm)\n    # > 2500 < 5000\n    b, a = des_bw_filter_bp(low=2500, high=5000)\n    xc1 = signal.lfilter(b, a, xcdm)\n    # > 5000 < 7500\n    b, a = des_bw_filter_bp(low=5000, high=7500)\n    xc2 = signal.lfilter(b, a, xcdm)\n    # > 7500 < 10000\n    b, a = des_bw_filter_bp(low=7500, high=10000)\n    xc3 = signal.lfilter(b, a, xcdm)\n    # > 10000 < 12500\n    b, a = des_bw_filter_bp(low=10000, high=12500)\n    xc4 = signal.lfilter(b, a, xcdm)\n    # > 12500 < 15000\n    b, a = des_bw_filter_bp(low=12500, high=15000)\n    xc5 = signal.lfilter(b, a, xcdm)\n    # > 15000 < 17500\n    b, a = des_bw_filter_bp(low=15000, high=17500)\n    xc6 = signal.lfilter(b, a, xcdm)\n    # > 17500 < 20000\n    b, a = des_bw_filter_bp(low=17500, high=20000)\n    xc7 = signal.lfilter(b, a, xcdm)\n    # > 20000\n    b, a = des_bw_filter_hp(cutoff=20000)\n    xc8 = signal.lfilter(b, a, xcdm)\n    \n    #将9个信号合成一个数组\n    sigs = [xc, pd.Series(xc0), pd.Series(xc1), pd.Series(xc2), pd.Series(xc3),\n            pd.Series(xc4), pd.Series(xc5), pd.Series(xc6), pd.Series(xc7), pd.Series(xc8)]\n    \n    # 迭代计算时域统计特性\n    for i, sig in enumerate(sigs):\n        # 平均值，标准差，最大值，最小值\n        X['mean_%d' % i] = sig.mean()\n        X['std_%d' % i] = sig.std()\n        X['max_%d' % i] = sig.max()\n        X['min_%d' % i] = sig.min()\n        \n        # 离散差值的平均(离散差值，后一个信号减前一个信号所组成的序列)\n        X['mean_change_abs_%d' % i] = np.mean(np.diff(sig))\n        # 非0的个数\n        X['mean_change_rate_%d' % i] = np.mean(np.nonzero((np.diff(sig) / sig[:-1]))[0])\n        # 绝对值的最大最小值\n        X['abs_max_%d' % i] = np.abs(sig).max()\n        X['abs_min_%d' % i] = np.abs(sig).min()\n        \n        # 前50000个信号的标准差\n        X['std_first_50000_%d' % i] = sig[:50000].std()\n        # 后50000个信号的标准差\n        X['std_last_50000_%d' % i] = sig[-50000:].std()\n        # 前1万个信号的标准差\n        X['std_first_10000_%d' % i] = sig[:10000].std()\n        # 后1万个信号的标准差\n        X['std_last_10000_%d' % i] = sig[-10000:].std()\n        \n        # 平均的特性\n        X['avg_first_50000_%d' % i] = sig[:50000].mean()\n        X['avg_last_50000_%d' % i] = sig[-50000:].mean()\n        X['avg_first_10000_%d' % i] = sig[:10000].mean()\n        X['avg_last_10000_%d' % i] = sig[-10000:].mean()\n        \n        # 最小值的特性\n        X['min_first_50000_%d' % i] = sig[:50000].min()\n        X['min_last_50000_%d' % i] = sig[-50000:].min()\n        X['min_first_10000_%d' % i] = sig[:10000].min()\n        X['min_last_10000_%d' % i] = sig[-10000:].min()\n        \n        # 最大值的特性\n        X['max_first_50000_%d' % i] = sig[:50000].max()\n        X['max_last_50000_%d' % i] = sig[-50000:].max()\n        X['max_first_10000_%d' % i] = sig[:10000].max()\n        X['max_last_10000_%d' % i] = sig[-10000:].max()\n        \n        # 衍生的特征\n        X['max_to_min_%d' % i] = sig.max() / np.abs(sig.min())\n        X['max_to_min_diff_%d' % i] = sig.max() - np.abs(sig.min())\n        # 信号振幅比500大的个数\n        X['count_big_%d' % i] = len(sig[np.abs(sig) > 500])\n        # 信号求和\n        X['sum_%d' % i] = sig.sum()\n\n        X['mean_change_rate_first_50000_%d' % i] = np.mean(np.nonzero((np.diff(sig[:50000]) / sig[:50000][:-1]))[0])\n        X['mean_change_rate_last_50000_%d' % i] = np.mean(np.nonzero((np.diff(sig[-50000:]) / sig[-50000:][:-1]))[0])\n        X['mean_change_rate_first_10000_%d' % i] = np.mean(np.nonzero((np.diff(sig[:10000]) / sig[:10000][:-1]))[0])\n        X['mean_change_rate_last_10000_%d' % i] = np.mean(np.nonzero((np.diff(sig[-10000:]) / sig[-10000:][:-1]))[0])\n\n        X['q95_%d' % i] = np.quantile(sig, 0.95)\n        X['q99_%d' % i] = np.quantile(sig, 0.99)\n        X['q05_%d' % i] = np.quantile(sig, 0.05)\n        X['q01_%d' % i] = np.quantile(sig, 0.01)\n\n        X['abs_q95_%d' % i] = np.quantile(np.abs(sig), 0.95)\n        X['abs_q99_%d' % i] = np.quantile(np.abs(sig), 0.99)\n        X['abs_q05_%d' % i] = np.quantile(np.abs(sig), 0.05)\n        X['abs_q01_%d' % i] = np.quantile(np.abs(sig), 0.01)\n\n        X['trend_%d' % i] = add_trend_feature(sig)\n        X['abs_trend_%d' % i] = add_trend_feature(sig, abs_values=True)\n        X['abs_mean_%d' % i] = np.abs(sig).mean()\n        X['abs_std_%d' % i] = np.abs(sig).std()\n        \n        # 平均偏离误差\n        X['mad_%d' % i] = sig.mad()\n        # 峰度(4阶矩)\n        X['kurt_%d' % i] = sig.kurtosis()\n        # 偏度(3阶矩)\n        X['skew_%d' % i] = sig.skew()\n        # 中值点\n        X['med_%d' % i] = sig.median()\n        \n        # 希尔伯特变换后的均值\n        X['Hilbert_mean_%d' % i] = np.abs(signal.hilbert(sig)).mean()\n        # hann窗后的均值\n        X['Hann_window_mean'] = (signal.convolve(xc, signal.hann(150), mode='same') / sum(signal.hann(150))).mean()\n        \n        # 计算sta_lta\n        X['classic_sta_lta1_mean_%d' % i] = classic_sta_lta(sig, 500, 10000).mean()\n        X['classic_sta_lta2_mean_%d' % i] = classic_sta_lta(sig, 5000, 100000).mean()\n        X['classic_sta_lta3_mean_%d' % i] = classic_sta_lta(sig, 3333, 6666).mean()\n        X['classic_sta_lta4_mean_%d' % i] = classic_sta_lta(sig, 10000, 25000).mean()\n        \n        # 计算滑动平均\n        X['Moving_average_700_mean_%d' % i] = sig.rolling(window=700).mean().mean(skipna=True)\n        X['Moving_average_1500_mean_%d' % i] = sig.rolling(window=1500).mean().mean(skipna=True)\n        X['Moving_average_3000_mean_%d' % i] = sig.rolling(window=3000).mean().mean(skipna=True)\n        X['Moving_average_6000_mean_%d' % i] = sig.rolling(window=6000).mean().mean(skipna=True)\n        \n        # 指数加权平均滑动平均\n        ewma = pd.Series.ewm\n        X['exp_Moving_average_300_mean_%d' % i] = ewma(sig, span=300).mean().mean(skipna=True)\n        X['exp_Moving_average_3000_mean_%d' % i] = ewma(sig, span=3000).mean().mean(skipna=True)\n        X['exp_Moving_average_30000_mean_%d' % i] = ewma(sig, span=6000).mean().mean(skipna=True)\n        \n        # 计算一些关于std的特征\n        no_of_std = 2\n        X['MA_700MA_std_mean_%d' % i] = sig.rolling(window=700).std().mean()\n        X['MA_700MA_BB_high_mean_%d' % i] = (\n                    X['Moving_average_700_mean_%d' % i] + no_of_std * X['MA_700MA_std_mean_%d' % i]).mean()\n        X['MA_700MA_BB_low_mean_%d' % i] = (\n                    X['Moving_average_700_mean_%d' % i] - no_of_std * X['MA_700MA_std_mean_%d' % i]).mean()\n        X['MA_400MA_std_mean_%d' % i] = sig.rolling(window=400).std().mean()\n        X['MA_400MA_BB_high_mean_%d' % i] = (\n                    X['Moving_average_700_mean_%d' % i] + no_of_std * X['MA_400MA_std_mean_%d' % i]).mean()\n        X['MA_400MA_BB_low_mean_%d' % i] = (\n                    X['Moving_average_700_mean_%d' % i] - no_of_std * X['MA_400MA_std_mean_%d' % i]).mean()\n        X['MA_1000MA_std_mean_%d' % i] = sig.rolling(window=1000).std().mean()\n        \n        #\n        X['iqr_%d' % i] = np.subtract(*np.percentile(sig, [75, 25]))\n        # 得到一个较大值\n        X['q999_%d' % i] = np.quantile(sig, 0.999)\n        # 得到一个较小值\n        X['q001_%d' % i] = np.quantile(sig, 0.001)\n        # 裁掉首末0.1的数据后取平均\n        X['ave10_%d' % i] = stats.trim_mean(sig, 0.1)\n    \n    # 对xc取不同滚动窗计算其统计特征\n    for windows in [10, 100, 1000]:\n        x_roll_std = xc.rolling(windows).std().dropna().values\n        x_roll_mean = xc.rolling(windows).mean().dropna().values\n\n        X['ave_roll_std_' + str(windows)] = x_roll_std.mean()\n        X['std_roll_std_' + str(windows)] = x_roll_std.std()\n        X['max_roll_std_' + str(windows)] = x_roll_std.max()\n        X['min_roll_std_' + str(windows)] = x_roll_std.min()\n        X['q01_roll_std_' + str(windows)] = np.quantile(x_roll_std, 0.01)\n        X['q05_roll_std_' + str(windows)] = np.quantile(x_roll_std, 0.05)\n        X['q95_roll_std_' + str(windows)] = np.quantile(x_roll_std, 0.95)\n        X['q99_roll_std_' + str(windows)] = np.quantile(x_roll_std, 0.99)\n        X['av_change_abs_roll_std_' + str(windows)] = np.mean(np.diff(x_roll_std))\n        X['av_change_rate_roll_std_' + str(windows)] = np.mean(\n            np.nonzero((np.diff(x_roll_std) / x_roll_std[:-1]))[0])\n        X['abs_max_roll_std_' + str(windows)] = np.abs(x_roll_std).max()\n\n        X['ave_roll_mean_' + str(windows)] = x_roll_mean.mean()\n        X['std_roll_mean_' + str(windows)] = x_roll_mean.std()\n        X['max_roll_mean_' + str(windows)] = x_roll_mean.max()\n        X['min_roll_mean_' + str(windows)] = x_roll_mean.min()\n        X['q01_roll_mean_' + str(windows)] = np.quantile(x_roll_mean, 0.01)\n        X['q05_roll_mean_' + str(windows)] = np.quantile(x_roll_mean, 0.05)\n        X['q95_roll_mean_' + str(windows)] = np.quantile(x_roll_mean, 0.95)\n        X['q99_roll_mean_' + str(windows)] = np.quantile(x_roll_mean, 0.99)\n        X['av_change_abs_roll_mean_' + str(windows)] = np.mean(np.diff(x_roll_mean))\n        X['av_change_rate_roll_mean_' + str(windows)] = np.mean(\n            np.nonzero((np.diff(x_roll_mean) / x_roll_mean[:-1]))[0])\n        X['abs_max_roll_mean_' + str(windows)] = np.abs(x_roll_mean).max()\n\n    return X","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"################################################### TRAIN ###################################################\n# 创造特征\nrows = 150000\nseg = train.iloc[1*rows:1*rows+rows]\nres = create_features_parallel(seg, mean=1)\nprint(res.shape)\nres","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"################################################### TRAIN ###################################################\nsegments = int(np.floor(train.shape[0] / rows))\nprint(\"Number of segments: \", segments)\n\n# 取15000个样本做训练集\nn_samples = 15000\n\n# 放训练集的地方\ntrain_X = pd.DataFrame(index=range(n_samples), columns=create_features_parallel(seg, mean=1).columns, dtype=np.float64)\n# train_y = pd.DataFrame(train.time_to_failure.values[::rows][1:], index=range(n_samples), dtype=np.float64, columns=['time_to_failure'])\n\n# 从原始信号中采用15000段信号\nseg_gen = (train.iloc[seg_id:seg_id+rows] for seg_id in np.random.randint(train.shape[0]-150000, size=n_samples))\n# 对这15000段信号产生数据集\nfeatures = Parallel(n_jobs=-1, verbose=2)(delayed(create_features_parallel)(seg, mean=1) for seg in seg_gen) #4.519464272770625\n# 显示进度，并把features赋值给train_X\nfor seg_id, feat in tqdm_notebook(enumerate(features)):\n    train_X.loc[seg_id] = feat.values\n\n# 清理内存\ndel features\ngc.collect();","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# 保存数据\ncols = [i for i in train_X.columns if i != \"time_to_failure\"]\ntrain_X[cols].to_csv(\"train_X_features_865.csv\", index=False)\ntrain_y = train_X[\"time_to_failure\"]\ntrain_y.to_csv(\"train_y.csv\", index=False)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}