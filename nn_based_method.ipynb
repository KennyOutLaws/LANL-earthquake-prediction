{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import scipy as sc\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "\n",
    "# 忽视警告\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "from tqdm import tqdm_notebook\n",
    "import datetime\n",
    "import time\n",
    "import random\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "# 要用的模型，以及一些预处理的方法\n",
    "from tensorflow import keras\n",
    "from catboost import Pool, CatBoostRegressor\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.model_selection import GridSearchCV, KFold, RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FFT_Mag_01q0</th>\n",
       "      <th>FFT_Mag_10q0</th>\n",
       "      <th>FFT_Mag_90q0</th>\n",
       "      <th>FFT_Mag_99q0</th>\n",
       "      <th>FFT_Mag_mean0</th>\n",
       "      <th>FFT_Mag_std0</th>\n",
       "      <th>FFT_Mag_max0</th>\n",
       "      <th>FFT_Phz_mean0</th>\n",
       "      <th>FFT_Phz_std0</th>\n",
       "      <th>FFT_Mag_01q2500</th>\n",
       "      <th>FFT_Mag_10q2500</th>\n",
       "      <th>FFT_Mag_90q2500</th>\n",
       "      <th>FFT_Mag_99q2500</th>\n",
       "      <th>FFT_Mag_mean2500</th>\n",
       "      <th>FFT_Mag_std2500</th>\n",
       "      <th>FFT_Mag_max2500</th>\n",
       "      <th>FFT_Phz_mean2500</th>\n",
       "      <th>FFT_Phz_std2500</th>\n",
       "      <th>FFT_Mag_01q5000</th>\n",
       "      <th>FFT_Mag_10q5000</th>\n",
       "      <th>FFT_Mag_90q5000</th>\n",
       "      <th>FFT_Mag_99q5000</th>\n",
       "      <th>FFT_Mag_mean5000</th>\n",
       "      <th>FFT_Mag_std5000</th>\n",
       "      <th>FFT_Mag_max5000</th>\n",
       "      <th>FFT_Phz_mean5000</th>\n",
       "      <th>FFT_Phz_std5000</th>\n",
       "      <th>FFT_Mag_01q7500</th>\n",
       "      <th>FFT_Mag_10q7500</th>\n",
       "      <th>FFT_Mag_90q7500</th>\n",
       "      <th>FFT_Mag_99q7500</th>\n",
       "      <th>FFT_Mag_mean7500</th>\n",
       "      <th>FFT_Mag_std7500</th>\n",
       "      <th>FFT_Mag_max7500</th>\n",
       "      <th>FFT_Phz_mean7500</th>\n",
       "      <th>FFT_Phz_std7500</th>\n",
       "      <th>FFT_Mag_01q10000</th>\n",
       "      <th>FFT_Mag_10q10000</th>\n",
       "      <th>FFT_Mag_90q10000</th>\n",
       "      <th>FFT_Mag_99q10000</th>\n",
       "      <th>...</th>\n",
       "      <th>q01_roll_std_100</th>\n",
       "      <th>q05_roll_std_100</th>\n",
       "      <th>q95_roll_std_100</th>\n",
       "      <th>q99_roll_std_100</th>\n",
       "      <th>av_change_abs_roll_std_100</th>\n",
       "      <th>av_change_rate_roll_std_100</th>\n",
       "      <th>abs_max_roll_std_100</th>\n",
       "      <th>ave_roll_mean_100</th>\n",
       "      <th>std_roll_mean_100</th>\n",
       "      <th>max_roll_mean_100</th>\n",
       "      <th>min_roll_mean_100</th>\n",
       "      <th>q01_roll_mean_100</th>\n",
       "      <th>q05_roll_mean_100</th>\n",
       "      <th>q95_roll_mean_100</th>\n",
       "      <th>q99_roll_mean_100</th>\n",
       "      <th>av_change_abs_roll_mean_100</th>\n",
       "      <th>av_change_rate_roll_mean_100</th>\n",
       "      <th>abs_max_roll_mean_100</th>\n",
       "      <th>ave_roll_std_1000</th>\n",
       "      <th>std_roll_std_1000</th>\n",
       "      <th>max_roll_std_1000</th>\n",
       "      <th>min_roll_std_1000</th>\n",
       "      <th>q01_roll_std_1000</th>\n",
       "      <th>q05_roll_std_1000</th>\n",
       "      <th>q95_roll_std_1000</th>\n",
       "      <th>q99_roll_std_1000</th>\n",
       "      <th>av_change_abs_roll_std_1000</th>\n",
       "      <th>av_change_rate_roll_std_1000</th>\n",
       "      <th>abs_max_roll_std_1000</th>\n",
       "      <th>ave_roll_mean_1000</th>\n",
       "      <th>std_roll_mean_1000</th>\n",
       "      <th>max_roll_mean_1000</th>\n",
       "      <th>min_roll_mean_1000</th>\n",
       "      <th>q01_roll_mean_1000</th>\n",
       "      <th>q05_roll_mean_1000</th>\n",
       "      <th>q95_roll_mean_1000</th>\n",
       "      <th>q99_roll_mean_1000</th>\n",
       "      <th>av_change_abs_roll_mean_1000</th>\n",
       "      <th>av_change_rate_roll_mean_1000</th>\n",
       "      <th>abs_max_roll_mean_1000</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>139.522396</td>\n",
       "      <td>409.718152</td>\n",
       "      <td>2599.097192</td>\n",
       "      <td>4061.567699</td>\n",
       "      <td>1345.706663</td>\n",
       "      <td>938.175660</td>\n",
       "      <td>11969.918774</td>\n",
       "      <td>0.022472</td>\n",
       "      <td>0.913523</td>\n",
       "      <td>237.008292</td>\n",
       "      <td>731.742174</td>\n",
       "      <td>4249.831881</td>\n",
       "      <td>6874.568414</td>\n",
       "      <td>2317.422748</td>\n",
       "      <td>1425.766416</td>\n",
       "      <td>8646.302978</td>\n",
       "      <td>-0.016085</td>\n",
       "      <td>0.907828</td>\n",
       "      <td>448.854260</td>\n",
       "      <td>1338.451624</td>\n",
       "      <td>6620.832265</td>\n",
       "      <td>9452.082006</td>\n",
       "      <td>3818.343685</td>\n",
       "      <td>2036.886799</td>\n",
       "      <td>13104.251576</td>\n",
       "      <td>0.006786</td>\n",
       "      <td>0.897903</td>\n",
       "      <td>566.136528</td>\n",
       "      <td>1828.685542</td>\n",
       "      <td>11398.359936</td>\n",
       "      <td>18595.373516</td>\n",
       "      <td>5886.087254</td>\n",
       "      <td>3894.189563</td>\n",
       "      <td>23532.881664</td>\n",
       "      <td>-0.036087</td>\n",
       "      <td>0.909921</td>\n",
       "      <td>256.880152</td>\n",
       "      <td>933.998090</td>\n",
       "      <td>5958.916634</td>\n",
       "      <td>10835.791291</td>\n",
       "      <td>...</td>\n",
       "      <td>2.275451</td>\n",
       "      <td>2.442780</td>\n",
       "      <td>8.526104</td>\n",
       "      <td>18.892797</td>\n",
       "      <td>0.000020</td>\n",
       "      <td>74941.769634</td>\n",
       "      <td>50.909740</td>\n",
       "      <td>4.618451</td>\n",
       "      <td>0.436482</td>\n",
       "      <td>12.19</td>\n",
       "      <td>-2.40</td>\n",
       "      <td>3.62</td>\n",
       "      <td>3.93</td>\n",
       "      <td>5.29</td>\n",
       "      <td>5.66</td>\n",
       "      <td>5.203469e-06</td>\n",
       "      <td>74938.678297</td>\n",
       "      <td>12.19</td>\n",
       "      <td>4.209590</td>\n",
       "      <td>2.974309</td>\n",
       "      <td>28.705276</td>\n",
       "      <td>2.502630</td>\n",
       "      <td>2.607830</td>\n",
       "      <td>2.672366</td>\n",
       "      <td>10.317476</td>\n",
       "      <td>14.107140</td>\n",
       "      <td>1.352170e-05</td>\n",
       "      <td>74563.128945</td>\n",
       "      <td>28.705276</td>\n",
       "      <td>4.618982</td>\n",
       "      <td>0.250223</td>\n",
       "      <td>5.430</td>\n",
       "      <td>3.926</td>\n",
       "      <td>4.034</td>\n",
       "      <td>4.201</td>\n",
       "      <td>5.028</td>\n",
       "      <td>5.195</td>\n",
       "      <td>4.080537e-06</td>\n",
       "      <td>74563.065284</td>\n",
       "      <td>5.430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>103.006025</td>\n",
       "      <td>432.256164</td>\n",
       "      <td>3894.194205</td>\n",
       "      <td>8899.077054</td>\n",
       "      <td>1778.081264</td>\n",
       "      <td>1753.736076</td>\n",
       "      <td>13008.467215</td>\n",
       "      <td>-0.016746</td>\n",
       "      <td>0.913844</td>\n",
       "      <td>265.294292</td>\n",
       "      <td>1096.751852</td>\n",
       "      <td>7355.981733</td>\n",
       "      <td>11124.480251</td>\n",
       "      <td>3806.170646</td>\n",
       "      <td>2546.431723</td>\n",
       "      <td>17024.790802</td>\n",
       "      <td>-0.003393</td>\n",
       "      <td>0.920536</td>\n",
       "      <td>647.666936</td>\n",
       "      <td>2056.427540</td>\n",
       "      <td>11181.052161</td>\n",
       "      <td>16426.982660</td>\n",
       "      <td>6207.629093</td>\n",
       "      <td>3586.244884</td>\n",
       "      <td>23566.293654</td>\n",
       "      <td>-0.001122</td>\n",
       "      <td>0.908535</td>\n",
       "      <td>670.834218</td>\n",
       "      <td>2226.225751</td>\n",
       "      <td>15177.013868</td>\n",
       "      <td>25823.792387</td>\n",
       "      <td>7711.334054</td>\n",
       "      <td>5419.906778</td>\n",
       "      <td>35981.079671</td>\n",
       "      <td>-0.006243</td>\n",
       "      <td>0.922031</td>\n",
       "      <td>332.465194</td>\n",
       "      <td>1068.575688</td>\n",
       "      <td>8027.668012</td>\n",
       "      <td>14524.229995</td>\n",
       "      <td>...</td>\n",
       "      <td>2.322834</td>\n",
       "      <td>2.510906</td>\n",
       "      <td>13.634641</td>\n",
       "      <td>30.138576</td>\n",
       "      <td>0.000033</td>\n",
       "      <td>74709.627147</td>\n",
       "      <td>52.708284</td>\n",
       "      <td>4.325410</td>\n",
       "      <td>0.513053</td>\n",
       "      <td>11.78</td>\n",
       "      <td>-2.70</td>\n",
       "      <td>2.99</td>\n",
       "      <td>3.62</td>\n",
       "      <td>5.00</td>\n",
       "      <td>5.57</td>\n",
       "      <td>3.802535e-06</td>\n",
       "      <td>74705.618281</td>\n",
       "      <td>11.78</td>\n",
       "      <td>5.414893</td>\n",
       "      <td>4.472418</td>\n",
       "      <td>29.594507</td>\n",
       "      <td>2.548829</td>\n",
       "      <td>2.664467</td>\n",
       "      <td>2.760705</td>\n",
       "      <td>16.239974</td>\n",
       "      <td>23.913015</td>\n",
       "      <td>-9.045880e-05</td>\n",
       "      <td>74208.764935</td>\n",
       "      <td>29.594507</td>\n",
       "      <td>4.325288</td>\n",
       "      <td>0.207712</td>\n",
       "      <td>5.216</td>\n",
       "      <td>3.612</td>\n",
       "      <td>3.812</td>\n",
       "      <td>3.990</td>\n",
       "      <td>4.663</td>\n",
       "      <td>4.827</td>\n",
       "      <td>-7.516779e-07</td>\n",
       "      <td>74208.713592</td>\n",
       "      <td>5.216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>121.840541</td>\n",
       "      <td>354.132240</td>\n",
       "      <td>1812.762440</td>\n",
       "      <td>2953.824113</td>\n",
       "      <td>1030.634121</td>\n",
       "      <td>684.285591</td>\n",
       "      <td>10665.922219</td>\n",
       "      <td>-0.033928</td>\n",
       "      <td>0.928496</td>\n",
       "      <td>235.951723</td>\n",
       "      <td>714.632635</td>\n",
       "      <td>3486.537639</td>\n",
       "      <td>5040.008929</td>\n",
       "      <td>1975.605682</td>\n",
       "      <td>1095.447506</td>\n",
       "      <td>7816.698187</td>\n",
       "      <td>-0.005391</td>\n",
       "      <td>0.917317</td>\n",
       "      <td>491.740705</td>\n",
       "      <td>1354.334138</td>\n",
       "      <td>6334.734457</td>\n",
       "      <td>9033.277200</td>\n",
       "      <td>3670.042914</td>\n",
       "      <td>1931.795674</td>\n",
       "      <td>12545.320475</td>\n",
       "      <td>-0.007111</td>\n",
       "      <td>0.903919</td>\n",
       "      <td>435.187536</td>\n",
       "      <td>1456.769253</td>\n",
       "      <td>9188.303499</td>\n",
       "      <td>14115.878775</td>\n",
       "      <td>4780.926331</td>\n",
       "      <td>3099.433090</td>\n",
       "      <td>19756.115049</td>\n",
       "      <td>-0.006067</td>\n",
       "      <td>0.904687</td>\n",
       "      <td>246.821665</td>\n",
       "      <td>796.153576</td>\n",
       "      <td>4675.630875</td>\n",
       "      <td>7543.952280</td>\n",
       "      <td>...</td>\n",
       "      <td>2.256304</td>\n",
       "      <td>2.409472</td>\n",
       "      <td>8.253215</td>\n",
       "      <td>15.107173</td>\n",
       "      <td>-0.000033</td>\n",
       "      <td>74872.665159</td>\n",
       "      <td>34.318383</td>\n",
       "      <td>4.310323</td>\n",
       "      <td>0.401061</td>\n",
       "      <td>7.06</td>\n",
       "      <td>1.85</td>\n",
       "      <td>3.37</td>\n",
       "      <td>3.68</td>\n",
       "      <td>4.96</td>\n",
       "      <td>5.27</td>\n",
       "      <td>-8.672448e-07</td>\n",
       "      <td>74863.629626</td>\n",
       "      <td>7.06</td>\n",
       "      <td>3.922947</td>\n",
       "      <td>2.161912</td>\n",
       "      <td>16.474262</td>\n",
       "      <td>2.456007</td>\n",
       "      <td>2.581889</td>\n",
       "      <td>2.650754</td>\n",
       "      <td>8.401994</td>\n",
       "      <td>14.176844</td>\n",
       "      <td>-7.340644e-06</td>\n",
       "      <td>74532.874909</td>\n",
       "      <td>16.474262</td>\n",
       "      <td>4.310783</td>\n",
       "      <td>0.238572</td>\n",
       "      <td>5.049</td>\n",
       "      <td>3.676</td>\n",
       "      <td>3.811</td>\n",
       "      <td>3.921</td>\n",
       "      <td>4.707</td>\n",
       "      <td>4.835</td>\n",
       "      <td>-1.174497e-06</td>\n",
       "      <td>74532.222230</td>\n",
       "      <td>5.049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>101.571556</td>\n",
       "      <td>334.674233</td>\n",
       "      <td>1639.884609</td>\n",
       "      <td>2581.813048</td>\n",
       "      <td>964.089147</td>\n",
       "      <td>587.651030</td>\n",
       "      <td>9512.216925</td>\n",
       "      <td>0.014567</td>\n",
       "      <td>0.903097</td>\n",
       "      <td>176.859785</td>\n",
       "      <td>481.129483</td>\n",
       "      <td>2268.498888</td>\n",
       "      <td>3233.275867</td>\n",
       "      <td>1309.797183</td>\n",
       "      <td>697.269900</td>\n",
       "      <td>4148.957142</td>\n",
       "      <td>-0.006280</td>\n",
       "      <td>0.906151</td>\n",
       "      <td>250.144239</td>\n",
       "      <td>662.097318</td>\n",
       "      <td>3122.971376</td>\n",
       "      <td>4407.508271</td>\n",
       "      <td>1817.541485</td>\n",
       "      <td>952.182540</td>\n",
       "      <td>5884.476832</td>\n",
       "      <td>-0.010407</td>\n",
       "      <td>0.907498</td>\n",
       "      <td>262.344445</td>\n",
       "      <td>706.090616</td>\n",
       "      <td>4182.270206</td>\n",
       "      <td>6690.867135</td>\n",
       "      <td>2270.692048</td>\n",
       "      <td>1414.974192</td>\n",
       "      <td>8266.686137</td>\n",
       "      <td>0.027824</td>\n",
       "      <td>0.913188</td>\n",
       "      <td>187.227021</td>\n",
       "      <td>542.287912</td>\n",
       "      <td>2838.605178</td>\n",
       "      <td>4923.677013</td>\n",
       "      <td>...</td>\n",
       "      <td>2.207677</td>\n",
       "      <td>2.335497</td>\n",
       "      <td>3.704693</td>\n",
       "      <td>7.415490</td>\n",
       "      <td>-0.000003</td>\n",
       "      <td>74975.714895</td>\n",
       "      <td>23.088543</td>\n",
       "      <td>4.543683</td>\n",
       "      <td>0.349356</td>\n",
       "      <td>7.31</td>\n",
       "      <td>2.31</td>\n",
       "      <td>3.73</td>\n",
       "      <td>3.97</td>\n",
       "      <td>5.11</td>\n",
       "      <td>5.37</td>\n",
       "      <td>6.004003e-07</td>\n",
       "      <td>74969.725070</td>\n",
       "      <td>7.31</td>\n",
       "      <td>2.942335</td>\n",
       "      <td>0.820362</td>\n",
       "      <td>9.268846</td>\n",
       "      <td>2.437511</td>\n",
       "      <td>2.525215</td>\n",
       "      <td>2.580794</td>\n",
       "      <td>4.529544</td>\n",
       "      <td>7.517345</td>\n",
       "      <td>-2.720343e-07</td>\n",
       "      <td>74586.537529</td>\n",
       "      <td>9.268846</td>\n",
       "      <td>4.544816</td>\n",
       "      <td>0.207969</td>\n",
       "      <td>5.076</td>\n",
       "      <td>3.878</td>\n",
       "      <td>4.009</td>\n",
       "      <td>4.205</td>\n",
       "      <td>4.890</td>\n",
       "      <td>4.960</td>\n",
       "      <td>1.570470e-06</td>\n",
       "      <td>74586.537529</td>\n",
       "      <td>5.076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>193.779369</td>\n",
       "      <td>602.762412</td>\n",
       "      <td>9999.530411</td>\n",
       "      <td>17349.812757</td>\n",
       "      <td>3346.487848</td>\n",
       "      <td>4028.266506</td>\n",
       "      <td>19602.021689</td>\n",
       "      <td>-0.018520</td>\n",
       "      <td>0.897478</td>\n",
       "      <td>544.992831</td>\n",
       "      <td>2009.314064</td>\n",
       "      <td>19216.443087</td>\n",
       "      <td>28079.956253</td>\n",
       "      <td>9516.446876</td>\n",
       "      <td>6616.195101</td>\n",
       "      <td>33997.695980</td>\n",
       "      <td>0.005338</td>\n",
       "      <td>0.907971</td>\n",
       "      <td>1811.036130</td>\n",
       "      <td>5807.624888</td>\n",
       "      <td>33631.964685</td>\n",
       "      <td>47794.755493</td>\n",
       "      <td>17470.873596</td>\n",
       "      <td>10592.785260</td>\n",
       "      <td>56225.168772</td>\n",
       "      <td>-0.013342</td>\n",
       "      <td>0.914594</td>\n",
       "      <td>1481.614653</td>\n",
       "      <td>4331.207985</td>\n",
       "      <td>26813.695795</td>\n",
       "      <td>42300.444512</td>\n",
       "      <td>13985.697200</td>\n",
       "      <td>9145.840345</td>\n",
       "      <td>59767.643908</td>\n",
       "      <td>-0.028152</td>\n",
       "      <td>0.904733</td>\n",
       "      <td>374.326102</td>\n",
       "      <td>1286.247534</td>\n",
       "      <td>12241.922510</td>\n",
       "      <td>25798.892511</td>\n",
       "      <td>...</td>\n",
       "      <td>2.419011</td>\n",
       "      <td>2.599048</td>\n",
       "      <td>14.802593</td>\n",
       "      <td>45.381436</td>\n",
       "      <td>0.000490</td>\n",
       "      <td>74780.417650</td>\n",
       "      <td>299.865819</td>\n",
       "      <td>4.607950</td>\n",
       "      <td>0.975320</td>\n",
       "      <td>34.59</td>\n",
       "      <td>-25.12</td>\n",
       "      <td>3.04</td>\n",
       "      <td>3.86</td>\n",
       "      <td>5.32</td>\n",
       "      <td>6.22</td>\n",
       "      <td>3.135424e-05</td>\n",
       "      <td>74778.225834</td>\n",
       "      <td>34.59</td>\n",
       "      <td>6.863442</td>\n",
       "      <td>12.795296</td>\n",
       "      <td>152.640688</td>\n",
       "      <td>2.619829</td>\n",
       "      <td>2.723817</td>\n",
       "      <td>2.816206</td>\n",
       "      <td>17.081704</td>\n",
       "      <td>50.443731</td>\n",
       "      <td>1.401113e-04</td>\n",
       "      <td>74401.529958</td>\n",
       "      <td>152.640688</td>\n",
       "      <td>4.608671</td>\n",
       "      <td>0.230372</td>\n",
       "      <td>6.991</td>\n",
       "      <td>2.321</td>\n",
       "      <td>4.121</td>\n",
       "      <td>4.265</td>\n",
       "      <td>4.966</td>\n",
       "      <td>5.106</td>\n",
       "      <td>4.006711e-06</td>\n",
       "      <td>74401.059981</td>\n",
       "      <td>6.991</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   FFT_Mag_01q0           ...            abs_max_roll_mean_1000\n",
       "0    139.522396           ...                             5.430\n",
       "1    103.006025           ...                             5.216\n",
       "2    121.840541           ...                             5.049\n",
       "3    101.571556           ...                             5.076\n",
       "4    193.779369           ...                             6.991\n",
       "\n",
       "[5 rows x 865 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 数据导入\n",
    "train_X_0 = pd.read_csv(\"../input/feature1/train_X_features_865.csv\")\n",
    "train_X_1 = pd.read_csv(\"../input/feature2/train_X_features_865_1.csv\")\n",
    "y_0 = pd.read_csv(\"../input/feature1/train_y.csv\", index_col=False,  header=None)\n",
    "y_1 = pd.read_csv(\"../input/feature2/train_y1.csv\", index_col=False,  header=None)\n",
    "train_X = pd.concat([train_X_0, train_X_1], axis=0)\n",
    "train_X = train_X.reset_index(drop=True)\n",
    "train_X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(33000,)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#得到y数据\n",
    "y = pd.concat([y_0, y_1], axis=0)\n",
    "y = y.reset_index(drop=True)\n",
    "y[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_y = pd.Series(y[0].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2624, 866)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_X = pd.read_csv(\"../input/feature2/test_X_features_10.csv\")\n",
    "test_X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#标准化数据\n",
    "scaler = StandardScaler()\n",
    "train_columns = train_X.columns\n",
    "\n",
    "train_X[train_columns] = scaler.fit_transform(train_X[train_columns])\n",
    "test_X[train_columns] = scaler.transform(test_X[train_columns])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 设置交叉验证的次数\n",
    "train_columns = train_X.columns\n",
    "n_fold = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义神经网络\n",
    "def create_model(input_dim=10):\n",
    "    # 神经网络的序列模型, dense为神经元，dropout用来正则化\n",
    "    model = keras.Sequential()\n",
    "    # 第一层256个神经元\n",
    "    model.add(keras.layers.Dense(256, activation=\"relu\", input_dim=input_dim))\n",
    "    model.add(keras.layers.Dropout(0.4))\n",
    "    # 第二层128个神经元\n",
    "    model.add(keras.layers.Dense(128, activation=\"relu\"))\n",
    "    model.add(keras.layers.Dropout(0.3))\n",
    "    # 第三96个神经元\n",
    "    model.add(keras.layers.Dense(96, activation=\"relu\"))\n",
    "    model.add(keras.layers.Dropout(0.3))\n",
    "    # 最后一层1个神经元(只有一个time_to_failure作为结果)\n",
    "    model.add(keras.layers.Dense(1, activation=\"linear\"))\n",
    "    #使用adam作为优化器,其初始学习率为0.001\n",
    "    optimizer = keras.optimizers.Adam(lr=0.001) #'rmsprop'\n",
    "    # 评判指标为mae\n",
    "    model.compile(optimizer=optimizer,loss='mae')\n",
    "    return model\n",
    "\n",
    "# 设置EarlyStop为回调函数，监督验证集的损失变换，如果40次loss没有下降则结束\n",
    "patience = 40\n",
    "call_ES = keras.callbacks.EarlyStopping(monitor='val_loss', patience=patience, verbose=1, restore_best_weights=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold 0\n",
      "WARNING:tensorflow:From /opt/conda/lib/python3.6/site-packages/tensorflow/python/ops/resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /opt/conda/lib/python3.6/site-packages/tensorflow/python/keras/layers/core.py:143: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "Train on 26400 samples, validate on 6600 samples\n",
      "WARNING:tensorflow:From /opt/conda/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/300\n",
      "26400/26400 [==============================] - 6s 242us/sample - loss: 2.5035 - val_loss: 2.3079\n",
      "Epoch 2/300\n",
      "26400/26400 [==============================] - 3s 108us/sample - loss: 2.2374 - val_loss: 2.3322\n",
      "Epoch 3/300\n",
      "26400/26400 [==============================] - 3s 108us/sample - loss: 2.1800 - val_loss: 2.1108\n",
      "Epoch 4/300\n",
      "26400/26400 [==============================] - 3s 107us/sample - loss: 2.1172 - val_loss: 2.0718\n",
      "Epoch 5/300\n",
      "26400/26400 [==============================] - 3s 109us/sample - loss: 2.0740 - val_loss: 2.0010\n",
      "Epoch 6/300\n",
      "26400/26400 [==============================] - 3s 107us/sample - loss: 2.0500 - val_loss: 2.0435\n",
      "Epoch 7/300\n",
      "26400/26400 [==============================] - 3s 108us/sample - loss: 2.0442 - val_loss: 2.0006\n",
      "Epoch 8/300\n",
      "26400/26400 [==============================] - 3s 107us/sample - loss: 2.0141 - val_loss: 2.1005\n",
      "Epoch 9/300\n",
      "26400/26400 [==============================] - 3s 108us/sample - loss: 1.9903 - val_loss: 2.0492\n",
      "Epoch 10/300\n",
      "26400/26400 [==============================] - 3s 108us/sample - loss: 1.9611 - val_loss: 1.9568\n",
      "Epoch 11/300\n",
      "26400/26400 [==============================] - 3s 112us/sample - loss: 1.9442 - val_loss: 2.0686\n",
      "Epoch 12/300\n",
      "26400/26400 [==============================] - 3s 111us/sample - loss: 1.9368 - val_loss: 1.9597\n",
      "Epoch 13/300\n",
      "26400/26400 [==============================] - 3s 109us/sample - loss: 1.9223 - val_loss: 1.9484\n",
      "Epoch 14/300\n",
      "26400/26400 [==============================] - 3s 110us/sample - loss: 1.8909 - val_loss: 1.9557\n",
      "Epoch 15/300\n",
      "26400/26400 [==============================] - 3s 113us/sample - loss: 1.8693 - val_loss: 1.9036\n",
      "Epoch 16/300\n",
      "26400/26400 [==============================] - 3s 110us/sample - loss: 1.8485 - val_loss: 1.8888\n",
      "Epoch 17/300\n",
      "26400/26400 [==============================] - 3s 111us/sample - loss: 1.8324 - val_loss: 1.9056\n",
      "Epoch 18/300\n",
      "26400/26400 [==============================] - 3s 108us/sample - loss: 1.8153 - val_loss: 1.8498\n",
      "Epoch 19/300\n",
      "26400/26400 [==============================] - 3s 107us/sample - loss: 1.7924 - val_loss: 1.9033\n",
      "Epoch 20/300\n",
      "26400/26400 [==============================] - 3s 106us/sample - loss: 1.7853 - val_loss: 1.8816\n",
      "Epoch 21/300\n",
      "26400/26400 [==============================] - 3s 106us/sample - loss: 1.7619 - val_loss: 1.8621\n",
      "Epoch 22/300\n",
      "26400/26400 [==============================] - 3s 106us/sample - loss: 1.7446 - val_loss: 1.8046\n",
      "Epoch 23/300\n",
      "26400/26400 [==============================] - 3s 108us/sample - loss: 1.7382 - val_loss: 1.8263\n",
      "Epoch 24/300\n",
      "26400/26400 [==============================] - 3s 106us/sample - loss: 1.7253 - val_loss: 1.8280\n",
      "Epoch 25/300\n",
      "26400/26400 [==============================] - 3s 106us/sample - loss: 1.7037 - val_loss: 1.7844\n",
      "Epoch 26/300\n",
      "26400/26400 [==============================] - 3s 107us/sample - loss: 1.6876 - val_loss: 1.7861\n",
      "Epoch 27/300\n",
      "26400/26400 [==============================] - 3s 105us/sample - loss: 1.6743 - val_loss: 1.8357\n",
      "Epoch 28/300\n",
      "26400/26400 [==============================] - 3s 106us/sample - loss: 1.6600 - val_loss: 1.7631\n",
      "Epoch 29/300\n",
      "26400/26400 [==============================] - 3s 106us/sample - loss: 1.6440 - val_loss: 1.7779\n",
      "Epoch 30/300\n",
      "26400/26400 [==============================] - 3s 106us/sample - loss: 1.6270 - val_loss: 1.8195\n",
      "Epoch 31/300\n",
      "26400/26400 [==============================] - 3s 105us/sample - loss: 1.6138 - val_loss: 1.8907\n",
      "Epoch 32/300\n",
      "26400/26400 [==============================] - 3s 105us/sample - loss: 1.6014 - val_loss: 1.7543\n",
      "Epoch 33/300\n",
      "26400/26400 [==============================] - 3s 105us/sample - loss: 1.5829 - val_loss: 1.7595\n",
      "Epoch 34/300\n",
      "26400/26400 [==============================] - 3s 105us/sample - loss: 1.5865 - val_loss: 1.7954\n",
      "Epoch 35/300\n",
      "26400/26400 [==============================] - 3s 105us/sample - loss: 1.5787 - val_loss: 1.7654\n",
      "Epoch 36/300\n",
      "26400/26400 [==============================] - 3s 107us/sample - loss: 1.5664 - val_loss: 1.7427\n",
      "Epoch 37/300\n",
      "26400/26400 [==============================] - 3s 106us/sample - loss: 1.5520 - val_loss: 1.8280\n",
      "Epoch 38/300\n",
      "26400/26400 [==============================] - 3s 105us/sample - loss: 1.5365 - val_loss: 1.7264\n",
      "Epoch 39/300\n",
      "26400/26400 [==============================] - 3s 106us/sample - loss: 1.5256 - val_loss: 1.7419\n",
      "Epoch 40/300\n",
      "26400/26400 [==============================] - 3s 106us/sample - loss: 1.5296 - val_loss: 1.7731\n",
      "Epoch 41/300\n",
      "26400/26400 [==============================] - 3s 106us/sample - loss: 1.5281 - val_loss: 1.7848\n",
      "Epoch 42/300\n",
      "26400/26400 [==============================] - 3s 106us/sample - loss: 1.5172 - val_loss: 1.7715\n",
      "Epoch 43/300\n",
      "26400/26400 [==============================] - 3s 107us/sample - loss: 1.5001 - val_loss: 1.7076\n",
      "Epoch 44/300\n",
      "26400/26400 [==============================] - 3s 106us/sample - loss: 1.4855 - val_loss: 1.7452\n",
      "Epoch 45/300\n",
      "26400/26400 [==============================] - 3s 105us/sample - loss: 1.4747 - val_loss: 1.7215\n",
      "Epoch 46/300\n",
      "26400/26400 [==============================] - 3s 105us/sample - loss: 1.4705 - val_loss: 1.8122\n",
      "Epoch 47/300\n",
      "26400/26400 [==============================] - 3s 104us/sample - loss: 1.4518 - val_loss: 1.6984\n",
      "Epoch 48/300\n",
      "26400/26400 [==============================] - 3s 104us/sample - loss: 1.4599 - val_loss: 1.7075\n",
      "Epoch 49/300\n",
      "26400/26400 [==============================] - 3s 105us/sample - loss: 1.4488 - val_loss: 1.7196\n",
      "Epoch 50/300\n",
      "26400/26400 [==============================] - 3s 105us/sample - loss: 1.4610 - val_loss: 1.6724\n",
      "Epoch 51/300\n",
      "26400/26400 [==============================] - 3s 104us/sample - loss: 1.4430 - val_loss: 1.6749\n",
      "Epoch 52/300\n",
      "26400/26400 [==============================] - 3s 105us/sample - loss: 1.4387 - val_loss: 1.6683\n",
      "Epoch 53/300\n",
      "26400/26400 [==============================] - 3s 105us/sample - loss: 1.4227 - val_loss: 1.7428\n",
      "Epoch 54/300\n",
      "26400/26400 [==============================] - 3s 105us/sample - loss: 1.4258 - val_loss: 1.6740\n",
      "Epoch 55/300\n",
      "26400/26400 [==============================] - 3s 104us/sample - loss: 1.4157 - val_loss: 1.6945\n",
      "Epoch 56/300\n",
      "26400/26400 [==============================] - 3s 105us/sample - loss: 1.4067 - val_loss: 1.7157\n",
      "Epoch 57/300\n",
      "26400/26400 [==============================] - 3s 105us/sample - loss: 1.4092 - val_loss: 1.6985\n",
      "Epoch 58/300\n",
      "26400/26400 [==============================] - 3s 105us/sample - loss: 1.3947 - val_loss: 1.6678\n",
      "Epoch 59/300\n",
      "26400/26400 [==============================] - 3s 104us/sample - loss: 1.3894 - val_loss: 1.6845\n",
      "Epoch 60/300\n",
      "26400/26400 [==============================] - 3s 104us/sample - loss: 1.3887 - val_loss: 1.6465\n",
      "Epoch 61/300\n",
      "26400/26400 [==============================] - 3s 104us/sample - loss: 1.3730 - val_loss: 1.6902\n",
      "Epoch 62/300\n",
      "26400/26400 [==============================] - 3s 104us/sample - loss: 1.3669 - val_loss: 1.7007\n",
      "Epoch 63/300\n",
      "26400/26400 [==============================] - 3s 104us/sample - loss: 1.3651 - val_loss: 1.6905\n",
      "Epoch 64/300\n",
      "26400/26400 [==============================] - 3s 105us/sample - loss: 1.3630 - val_loss: 1.6804\n",
      "Epoch 65/300\n",
      "26400/26400 [==============================] - 3s 103us/sample - loss: 1.3530 - val_loss: 1.6174\n",
      "Epoch 66/300\n",
      "26400/26400 [==============================] - 3s 106us/sample - loss: 1.3557 - val_loss: 1.6063\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 67/300\n",
      "26400/26400 [==============================] - 3s 105us/sample - loss: 1.3487 - val_loss: 1.6840\n",
      "Epoch 68/300\n",
      "26400/26400 [==============================] - 3s 104us/sample - loss: 1.3466 - val_loss: 1.6257\n",
      "Epoch 69/300\n",
      "26400/26400 [==============================] - 3s 104us/sample - loss: 1.3443 - val_loss: 1.6637\n",
      "Epoch 70/300\n",
      "26400/26400 [==============================] - 3s 104us/sample - loss: 1.3266 - val_loss: 1.6611\n",
      "Epoch 71/300\n",
      "26400/26400 [==============================] - 3s 105us/sample - loss: 1.3396 - val_loss: 1.6247\n",
      "Epoch 72/300\n",
      "26400/26400 [==============================] - 3s 105us/sample - loss: 1.3235 - val_loss: 1.6238\n",
      "Epoch 73/300\n",
      "26400/26400 [==============================] - 3s 104us/sample - loss: 1.3142 - val_loss: 1.6725\n",
      "Epoch 74/300\n",
      "26400/26400 [==============================] - 3s 104us/sample - loss: 1.3063 - val_loss: 1.6231\n",
      "Epoch 75/300\n",
      "26400/26400 [==============================] - 3s 103us/sample - loss: 1.3130 - val_loss: 1.6500\n",
      "Epoch 76/300\n",
      "26400/26400 [==============================] - 3s 104us/sample - loss: 1.3029 - val_loss: 1.6401\n",
      "Epoch 77/300\n",
      "26400/26400 [==============================] - 3s 104us/sample - loss: 1.3001 - val_loss: 1.7161\n",
      "Epoch 78/300\n",
      "26400/26400 [==============================] - 3s 104us/sample - loss: 1.2838 - val_loss: 1.6121\n",
      "Epoch 79/300\n",
      "26400/26400 [==============================] - 3s 105us/sample - loss: 1.2948 - val_loss: 1.5872\n",
      "Epoch 80/300\n",
      "26400/26400 [==============================] - 3s 104us/sample - loss: 1.2891 - val_loss: 1.6745\n",
      "Epoch 81/300\n",
      "26400/26400 [==============================] - 3s 104us/sample - loss: 1.2876 - val_loss: 1.6510\n",
      "Epoch 82/300\n",
      "26400/26400 [==============================] - 3s 105us/sample - loss: 1.2769 - val_loss: 1.6237\n",
      "Epoch 83/300\n",
      "26400/26400 [==============================] - 3s 103us/sample - loss: 1.2715 - val_loss: 1.6021\n",
      "Epoch 84/300\n",
      "26400/26400 [==============================] - 3s 104us/sample - loss: 1.2640 - val_loss: 1.5862\n",
      "Epoch 85/300\n",
      "26400/26400 [==============================] - 3s 103us/sample - loss: 1.2660 - val_loss: 1.5849\n",
      "Epoch 86/300\n",
      "26400/26400 [==============================] - 3s 105us/sample - loss: 1.2611 - val_loss: 1.5636\n",
      "Epoch 87/300\n",
      "26400/26400 [==============================] - 3s 104us/sample - loss: 1.2652 - val_loss: 1.6670\n",
      "Epoch 88/300\n",
      "26400/26400 [==============================] - 3s 104us/sample - loss: 1.2483 - val_loss: 1.6238\n",
      "Epoch 89/300\n",
      "26400/26400 [==============================] - 3s 105us/sample - loss: 1.2526 - val_loss: 1.5769\n",
      "Epoch 90/300\n",
      "26400/26400 [==============================] - 3s 104us/sample - loss: 1.2513 - val_loss: 1.6130\n",
      "Epoch 91/300\n",
      "26400/26400 [==============================] - 3s 104us/sample - loss: 1.2431 - val_loss: 1.6145\n",
      "Epoch 92/300\n",
      "26400/26400 [==============================] - 3s 103us/sample - loss: 1.2417 - val_loss: 1.6062\n",
      "Epoch 93/300\n",
      "26400/26400 [==============================] - 3s 103us/sample - loss: 1.2417 - val_loss: 1.5962\n",
      "Epoch 94/300\n",
      "26400/26400 [==============================] - 3s 103us/sample - loss: 1.2465 - val_loss: 1.5814\n",
      "Epoch 95/300\n",
      "26400/26400 [==============================] - 3s 104us/sample - loss: 1.2373 - val_loss: 1.6245\n",
      "Epoch 96/300\n",
      "26400/26400 [==============================] - 3s 103us/sample - loss: 1.2285 - val_loss: 1.6031\n",
      "Epoch 97/300\n",
      "26400/26400 [==============================] - 3s 103us/sample - loss: 1.2277 - val_loss: 1.5880\n",
      "Epoch 98/300\n",
      "26400/26400 [==============================] - 3s 105us/sample - loss: 1.2377 - val_loss: 1.5953\n",
      "Epoch 99/300\n",
      "26400/26400 [==============================] - 3s 104us/sample - loss: 1.2255 - val_loss: 1.5773\n",
      "Epoch 100/300\n",
      "26400/26400 [==============================] - 3s 106us/sample - loss: 1.2169 - val_loss: 1.5733\n",
      "Epoch 101/300\n",
      "26400/26400 [==============================] - 3s 105us/sample - loss: 1.2139 - val_loss: 1.5711\n",
      "Epoch 102/300\n",
      "26400/26400 [==============================] - 3s 105us/sample - loss: 1.2177 - val_loss: 1.5611\n",
      "Epoch 103/300\n",
      "26400/26400 [==============================] - 3s 104us/sample - loss: 1.2066 - val_loss: 1.5958\n",
      "Epoch 104/300\n",
      "26400/26400 [==============================] - 3s 104us/sample - loss: 1.2071 - val_loss: 1.5958\n",
      "Epoch 105/300\n",
      "26400/26400 [==============================] - 3s 105us/sample - loss: 1.2015 - val_loss: 1.6018\n",
      "Epoch 106/300\n",
      "26400/26400 [==============================] - 3s 105us/sample - loss: 1.2013 - val_loss: 1.5530\n",
      "Epoch 107/300\n",
      "26400/26400 [==============================] - 3s 104us/sample - loss: 1.1907 - val_loss: 1.5263\n",
      "Epoch 108/300\n",
      "26400/26400 [==============================] - 3s 104us/sample - loss: 1.2102 - val_loss: 1.6213\n",
      "Epoch 109/300\n",
      "26400/26400 [==============================] - 3s 103us/sample - loss: 1.1905 - val_loss: 1.6594\n",
      "Epoch 110/300\n",
      "26400/26400 [==============================] - 3s 103us/sample - loss: 1.2062 - val_loss: 1.6673\n",
      "Epoch 111/300\n",
      "26400/26400 [==============================] - 3s 104us/sample - loss: 1.1912 - val_loss: 1.6122\n",
      "Epoch 112/300\n",
      "26400/26400 [==============================] - 3s 104us/sample - loss: 1.1823 - val_loss: 1.5709\n",
      "Epoch 113/300\n",
      "26400/26400 [==============================] - 3s 103us/sample - loss: 1.1806 - val_loss: 1.5889\n",
      "Epoch 114/300\n",
      "26400/26400 [==============================] - 3s 104us/sample - loss: 1.1818 - val_loss: 1.5238\n",
      "Epoch 115/300\n",
      "26400/26400 [==============================] - 3s 104us/sample - loss: 1.1875 - val_loss: 1.5428\n",
      "Epoch 116/300\n",
      "26400/26400 [==============================] - 3s 103us/sample - loss: 1.1797 - val_loss: 1.5898\n",
      "Epoch 117/300\n",
      "26400/26400 [==============================] - 3s 104us/sample - loss: 1.1762 - val_loss: 1.5367\n",
      "Epoch 118/300\n",
      "26400/26400 [==============================] - 3s 104us/sample - loss: 1.1746 - val_loss: 1.5887\n",
      "Epoch 119/300\n",
      "26400/26400 [==============================] - 3s 105us/sample - loss: 1.1806 - val_loss: 1.5451\n",
      "Epoch 120/300\n",
      "26400/26400 [==============================] - 3s 106us/sample - loss: 1.1640 - val_loss: 1.5749\n",
      "Epoch 121/300\n",
      "26400/26400 [==============================] - 3s 106us/sample - loss: 1.1733 - val_loss: 1.5530\n",
      "Epoch 122/300\n",
      "26400/26400 [==============================] - 3s 106us/sample - loss: 1.1650 - val_loss: 1.5448\n",
      "Epoch 123/300\n",
      "26400/26400 [==============================] - 3s 105us/sample - loss: 1.1629 - val_loss: 1.5865\n",
      "Epoch 124/300\n",
      "26400/26400 [==============================] - 3s 104us/sample - loss: 1.1621 - val_loss: 1.5217\n",
      "Epoch 125/300\n",
      "26400/26400 [==============================] - 3s 103us/sample - loss: 1.1631 - val_loss: 1.5107\n",
      "Epoch 126/300\n",
      "26400/26400 [==============================] - 3s 105us/sample - loss: 1.1541 - val_loss: 1.5436\n",
      "Epoch 127/300\n",
      "26400/26400 [==============================] - 3s 109us/sample - loss: 1.1553 - val_loss: 1.5832\n",
      "Epoch 128/300\n",
      "26400/26400 [==============================] - 3s 108us/sample - loss: 1.1506 - val_loss: 1.5170\n",
      "Epoch 129/300\n",
      "26400/26400 [==============================] - 3s 109us/sample - loss: 1.1514 - val_loss: 1.5448\n",
      "Epoch 130/300\n",
      "26400/26400 [==============================] - 3s 106us/sample - loss: 1.1445 - val_loss: 1.5179\n",
      "Epoch 131/300\n",
      "26400/26400 [==============================] - 3s 103us/sample - loss: 1.1482 - val_loss: 1.5245\n",
      "Epoch 132/300\n",
      "26400/26400 [==============================] - 3s 103us/sample - loss: 1.1378 - val_loss: 1.5675\n",
      "Epoch 133/300\n",
      "26400/26400 [==============================] - 3s 105us/sample - loss: 1.1487 - val_loss: 1.5524\n",
      "Epoch 134/300\n",
      "26400/26400 [==============================] - 3s 104us/sample - loss: 1.1360 - val_loss: 1.5727\n",
      "Epoch 135/300\n",
      "26400/26400 [==============================] - 3s 104us/sample - loss: 1.1391 - val_loss: 1.5245\n",
      "Epoch 136/300\n",
      "26400/26400 [==============================] - 3s 103us/sample - loss: 1.1365 - val_loss: 1.5562\n",
      "Epoch 137/300\n",
      "26400/26400 [==============================] - 3s 105us/sample - loss: 1.1362 - val_loss: 1.5339\n",
      "Epoch 138/300\n",
      "26400/26400 [==============================] - 3s 103us/sample - loss: 1.1239 - val_loss: 1.5126\n",
      "Epoch 139/300\n",
      "26400/26400 [==============================] - 3s 104us/sample - loss: 1.1266 - val_loss: 1.5075\n",
      "Epoch 140/300\n",
      "26400/26400 [==============================] - 3s 104us/sample - loss: 1.1293 - val_loss: 1.5063\n",
      "Epoch 141/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26400/26400 [==============================] - 3s 103us/sample - loss: 1.1251 - val_loss: 1.5540\n",
      "Epoch 142/300\n",
      "26400/26400 [==============================] - 3s 103us/sample - loss: 1.1274 - val_loss: 1.5140\n",
      "Epoch 143/300\n",
      "26400/26400 [==============================] - 3s 104us/sample - loss: 1.1214 - val_loss: 1.5327\n",
      "Epoch 144/300\n",
      "26400/26400 [==============================] - 3s 104us/sample - loss: 1.1174 - val_loss: 1.5419\n",
      "Epoch 145/300\n",
      "26400/26400 [==============================] - 3s 104us/sample - loss: 1.1184 - val_loss: 1.5370\n",
      "Epoch 146/300\n",
      "26400/26400 [==============================] - 3s 105us/sample - loss: 1.1187 - val_loss: 1.5342\n",
      "Epoch 147/300\n",
      "26400/26400 [==============================] - 3s 104us/sample - loss: 1.1137 - val_loss: 1.5950\n",
      "Epoch 148/300\n",
      "26400/26400 [==============================] - 3s 104us/sample - loss: 1.1294 - val_loss: 1.5082\n",
      "Epoch 149/300\n",
      "26400/26400 [==============================] - 3s 103us/sample - loss: 1.1094 - val_loss: 1.5274\n",
      "Epoch 150/300\n",
      "26400/26400 [==============================] - 3s 103us/sample - loss: 1.1063 - val_loss: 1.5721\n",
      "Epoch 151/300\n",
      "26400/26400 [==============================] - 3s 104us/sample - loss: 1.1140 - val_loss: 1.5055\n",
      "Epoch 152/300\n",
      "26400/26400 [==============================] - 3s 104us/sample - loss: 1.1018 - val_loss: 1.4898\n",
      "Epoch 153/300\n",
      "26400/26400 [==============================] - 3s 104us/sample - loss: 1.1012 - val_loss: 1.4964\n",
      "Epoch 154/300\n",
      "26400/26400 [==============================] - 3s 103us/sample - loss: 1.0965 - val_loss: 1.5892\n",
      "Epoch 155/300\n",
      "26400/26400 [==============================] - 3s 105us/sample - loss: 1.1017 - val_loss: 1.5123\n",
      "Epoch 156/300\n",
      "26400/26400 [==============================] - 3s 104us/sample - loss: 1.0964 - val_loss: 1.5605\n",
      "Epoch 157/300\n",
      "26400/26400 [==============================] - 3s 104us/sample - loss: 1.1021 - val_loss: 1.4751\n",
      "Epoch 158/300\n",
      "26400/26400 [==============================] - 3s 105us/sample - loss: 1.0963 - val_loss: 1.5182\n",
      "Epoch 159/300\n",
      "26400/26400 [==============================] - 3s 105us/sample - loss: 1.0966 - val_loss: 1.5139\n",
      "Epoch 160/300\n",
      "26400/26400 [==============================] - 3s 105us/sample - loss: 1.0841 - val_loss: 1.5240\n",
      "Epoch 161/300\n",
      "26400/26400 [==============================] - 3s 103us/sample - loss: 1.0889 - val_loss: 1.5902\n",
      "Epoch 162/300\n",
      "26400/26400 [==============================] - 3s 104us/sample - loss: 1.0798 - val_loss: 1.5607\n",
      "Epoch 163/300\n",
      "26400/26400 [==============================] - 3s 104us/sample - loss: 1.0879 - val_loss: 1.4896\n",
      "Epoch 164/300\n",
      "26400/26400 [==============================] - 3s 103us/sample - loss: 1.0946 - val_loss: 1.5836\n",
      "Epoch 165/300\n",
      "26400/26400 [==============================] - 3s 103us/sample - loss: 1.0942 - val_loss: 1.5214\n",
      "Epoch 166/300\n",
      "26400/26400 [==============================] - 3s 106us/sample - loss: 1.0890 - val_loss: 1.5094\n",
      "Epoch 167/300\n",
      "26400/26400 [==============================] - 3s 106us/sample - loss: 1.0869 - val_loss: 1.4851\n",
      "Epoch 168/300\n",
      "26400/26400 [==============================] - 3s 103us/sample - loss: 1.0789 - val_loss: 1.5323\n",
      "Epoch 169/300\n",
      "26400/26400 [==============================] - 3s 104us/sample - loss: 1.0873 - val_loss: 1.4782\n",
      "Epoch 170/300\n",
      "26400/26400 [==============================] - 3s 103us/sample - loss: 1.0844 - val_loss: 1.4900\n",
      "Epoch 171/300\n",
      "26400/26400 [==============================] - 3s 104us/sample - loss: 1.0771 - val_loss: 1.4777\n",
      "Epoch 172/300\n",
      "26400/26400 [==============================] - 3s 104us/sample - loss: 1.0799 - val_loss: 1.5730\n",
      "Epoch 173/300\n",
      "26400/26400 [==============================] - 3s 104us/sample - loss: 1.0759 - val_loss: 1.5259\n",
      "Epoch 174/300\n",
      "26400/26400 [==============================] - 3s 104us/sample - loss: 1.0764 - val_loss: 1.5078\n",
      "Epoch 175/300\n",
      "26400/26400 [==============================] - 3s 104us/sample - loss: 1.0744 - val_loss: 1.4854\n",
      "Epoch 176/300\n",
      "26400/26400 [==============================] - 3s 105us/sample - loss: 1.0740 - val_loss: 1.4749\n",
      "Epoch 177/300\n",
      "26400/26400 [==============================] - 3s 105us/sample - loss: 1.0836 - val_loss: 1.5074\n",
      "Epoch 178/300\n",
      "26400/26400 [==============================] - 3s 104us/sample - loss: 1.0687 - val_loss: 1.4548\n",
      "Epoch 179/300\n",
      "26400/26400 [==============================] - 3s 103us/sample - loss: 1.0691 - val_loss: 1.5015\n",
      "Epoch 180/300\n",
      "26400/26400 [==============================] - 3s 104us/sample - loss: 1.0600 - val_loss: 1.5852\n",
      "Epoch 181/300\n",
      "26400/26400 [==============================] - 3s 104us/sample - loss: 1.0662 - val_loss: 1.4861\n",
      "Epoch 182/300\n",
      "26400/26400 [==============================] - 3s 103us/sample - loss: 1.0611 - val_loss: 1.4874\n",
      "Epoch 183/300\n",
      "26400/26400 [==============================] - 3s 102us/sample - loss: 1.0607 - val_loss: 1.4817\n",
      "Epoch 184/300\n",
      "26400/26400 [==============================] - 3s 103us/sample - loss: 1.0651 - val_loss: 1.5002\n",
      "Epoch 185/300\n",
      "26400/26400 [==============================] - 3s 103us/sample - loss: 1.0567 - val_loss: 1.5579\n",
      "Epoch 186/300\n",
      "26400/26400 [==============================] - 3s 104us/sample - loss: 1.0615 - val_loss: 1.4786\n",
      "Epoch 187/300\n",
      "26400/26400 [==============================] - 3s 104us/sample - loss: 1.0508 - val_loss: 1.5015\n",
      "Epoch 188/300\n",
      "26400/26400 [==============================] - 3s 105us/sample - loss: 1.0515 - val_loss: 1.5209\n",
      "Epoch 189/300\n",
      "26400/26400 [==============================] - 3s 106us/sample - loss: 1.0533 - val_loss: 1.5111\n",
      "Epoch 190/300\n",
      "26400/26400 [==============================] - 3s 103us/sample - loss: 1.0566 - val_loss: 1.4773\n",
      "Epoch 191/300\n",
      "26400/26400 [==============================] - 3s 104us/sample - loss: 1.0559 - val_loss: 1.5046\n",
      "Epoch 192/300\n",
      "26400/26400 [==============================] - 3s 103us/sample - loss: 1.0527 - val_loss: 1.4928\n",
      "Epoch 193/300\n",
      "26400/26400 [==============================] - 3s 104us/sample - loss: 1.0483 - val_loss: 1.5225\n",
      "Epoch 194/300\n",
      "26400/26400 [==============================] - 3s 103us/sample - loss: 1.0547 - val_loss: 1.5520\n",
      "Epoch 195/300\n",
      "26400/26400 [==============================] - 3s 104us/sample - loss: 1.0473 - val_loss: 1.5056\n",
      "Epoch 196/300\n",
      "26400/26400 [==============================] - 3s 103us/sample - loss: 1.0401 - val_loss: 1.5095\n",
      "Epoch 197/300\n",
      "26400/26400 [==============================] - 3s 103us/sample - loss: 1.0395 - val_loss: 1.5028\n",
      "Epoch 198/300\n",
      "26400/26400 [==============================] - 3s 103us/sample - loss: 1.0495 - val_loss: 1.5362\n",
      "Epoch 199/300\n",
      "26400/26400 [==============================] - 3s 103us/sample - loss: 1.0479 - val_loss: 1.4514\n",
      "Epoch 200/300\n",
      "26400/26400 [==============================] - 3s 103us/sample - loss: 1.0382 - val_loss: 1.4753\n",
      "Epoch 201/300\n",
      "26400/26400 [==============================] - 3s 104us/sample - loss: 1.0385 - val_loss: 1.5102\n",
      "Epoch 202/300\n",
      "26400/26400 [==============================] - 3s 104us/sample - loss: 1.0385 - val_loss: 1.4859\n",
      "Epoch 203/300\n",
      "26400/26400 [==============================] - 3s 103us/sample - loss: 1.0376 - val_loss: 1.4731\n",
      "Epoch 204/300\n",
      "26400/26400 [==============================] - 3s 104us/sample - loss: 1.0392 - val_loss: 1.4773\n",
      "Epoch 205/300\n",
      "26400/26400 [==============================] - 3s 103us/sample - loss: 1.0358 - val_loss: 1.4710\n",
      "Epoch 206/300\n",
      "26400/26400 [==============================] - 3s 104us/sample - loss: 1.0327 - val_loss: 1.4697\n",
      "Epoch 207/300\n",
      "26400/26400 [==============================] - 3s 103us/sample - loss: 1.0338 - val_loss: 1.5247\n",
      "Epoch 208/300\n",
      "26400/26400 [==============================] - 3s 103us/sample - loss: 1.0347 - val_loss: 1.4912\n",
      "Epoch 209/300\n",
      "26400/26400 [==============================] - 3s 104us/sample - loss: 1.0286 - val_loss: 1.4528\n",
      "Epoch 210/300\n",
      "26400/26400 [==============================] - 3s 103us/sample - loss: 1.0368 - val_loss: 1.5397\n",
      "Epoch 211/300\n",
      "26400/26400 [==============================] - 3s 104us/sample - loss: 1.0332 - val_loss: 1.5147\n",
      "Epoch 212/300\n",
      "26400/26400 [==============================] - 3s 103us/sample - loss: 1.0280 - val_loss: 1.4564\n",
      "Epoch 213/300\n",
      "26400/26400 [==============================] - 3s 104us/sample - loss: 1.0267 - val_loss: 1.4691\n",
      "Epoch 214/300\n",
      "26400/26400 [==============================] - 3s 104us/sample - loss: 1.0328 - val_loss: 1.4882\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 215/300\n",
      "26400/26400 [==============================] - 3s 104us/sample - loss: 1.0280 - val_loss: 1.5171\n",
      "Epoch 216/300\n",
      "26400/26400 [==============================] - 3s 103us/sample - loss: 1.0295 - val_loss: 1.4738\n",
      "Epoch 217/300\n",
      "26400/26400 [==============================] - 3s 104us/sample - loss: 1.0317 - val_loss: 1.4577\n",
      "Epoch 218/300\n",
      "26400/26400 [==============================] - 3s 104us/sample - loss: 1.0257 - val_loss: 1.5015\n",
      "Epoch 219/300\n",
      "26400/26400 [==============================] - 3s 102us/sample - loss: 1.0348 - val_loss: 1.4608\n",
      "Epoch 220/300\n",
      "26400/26400 [==============================] - 3s 103us/sample - loss: 1.0164 - val_loss: 1.4988\n",
      "Epoch 221/300\n",
      "26400/26400 [==============================] - 3s 103us/sample - loss: 1.0257 - val_loss: 1.4529\n",
      "Epoch 222/300\n",
      "26400/26400 [==============================] - 3s 103us/sample - loss: 1.0223 - val_loss: 1.5001\n",
      "Epoch 223/300\n",
      "26400/26400 [==============================] - 3s 103us/sample - loss: 1.0208 - val_loss: 1.4530\n",
      "Epoch 224/300\n",
      "26400/26400 [==============================] - 3s 103us/sample - loss: 1.0240 - val_loss: 1.5197\n",
      "Epoch 225/300\n",
      "26400/26400 [==============================] - 3s 103us/sample - loss: 1.0265 - val_loss: 1.4532\n",
      "Epoch 226/300\n",
      "26400/26400 [==============================] - 3s 103us/sample - loss: 1.0155 - val_loss: 1.5684\n",
      "Epoch 227/300\n",
      "26400/26400 [==============================] - 3s 103us/sample - loss: 1.0270 - val_loss: 1.4629\n",
      "Epoch 228/300\n",
      "26400/26400 [==============================] - 3s 103us/sample - loss: 1.0120 - val_loss: 1.4441\n",
      "Epoch 229/300\n",
      "26400/26400 [==============================] - 3s 103us/sample - loss: 1.0129 - val_loss: 1.4771\n",
      "Epoch 230/300\n",
      "26400/26400 [==============================] - 3s 103us/sample - loss: 1.0085 - val_loss: 1.4979\n",
      "Epoch 231/300\n",
      "26400/26400 [==============================] - 3s 103us/sample - loss: 1.0155 - val_loss: 1.5245\n",
      "Epoch 232/300\n",
      "26400/26400 [==============================] - 3s 106us/sample - loss: 1.0062 - val_loss: 1.5192\n",
      "Epoch 233/300\n",
      "26400/26400 [==============================] - 3s 107us/sample - loss: 1.0049 - val_loss: 1.5165\n",
      "Epoch 234/300\n",
      "26400/26400 [==============================] - 3s 103us/sample - loss: 1.0066 - val_loss: 1.4912\n",
      "Epoch 235/300\n",
      "26400/26400 [==============================] - 3s 104us/sample - loss: 1.0026 - val_loss: 1.4242\n",
      "Epoch 236/300\n",
      "26400/26400 [==============================] - 3s 103us/sample - loss: 1.0080 - val_loss: 1.4396\n",
      "Epoch 237/300\n",
      "26400/26400 [==============================] - 3s 104us/sample - loss: 1.0102 - val_loss: 1.4665\n",
      "Epoch 238/300\n",
      "26400/26400 [==============================] - 3s 103us/sample - loss: 1.0084 - val_loss: 1.4333\n",
      "Epoch 239/300\n",
      "26400/26400 [==============================] - 3s 104us/sample - loss: 1.0124 - val_loss: 1.4258\n",
      "Epoch 240/300\n",
      "26400/26400 [==============================] - 3s 107us/sample - loss: 1.0059 - val_loss: 1.4770\n",
      "Epoch 241/300\n",
      "26400/26400 [==============================] - 3s 106us/sample - loss: 1.0042 - val_loss: 1.4988\n",
      "Epoch 242/300\n",
      "26400/26400 [==============================] - 3s 107us/sample - loss: 1.0019 - val_loss: 1.4829\n",
      "Epoch 243/300\n",
      "26400/26400 [==============================] - 3s 107us/sample - loss: 1.0058 - val_loss: 1.4519\n",
      "Epoch 244/300\n",
      "26400/26400 [==============================] - 3s 104us/sample - loss: 1.0033 - val_loss: 1.4947\n",
      "Epoch 245/300\n",
      "26400/26400 [==============================] - 3s 103us/sample - loss: 0.9998 - val_loss: 1.4946\n",
      "Epoch 246/300\n",
      "26400/26400 [==============================] - 3s 104us/sample - loss: 0.9967 - val_loss: 1.4377\n",
      "Epoch 247/300\n",
      "26400/26400 [==============================] - 3s 104us/sample - loss: 1.0025 - val_loss: 1.4644\n",
      "Epoch 248/300\n",
      "26400/26400 [==============================] - 3s 103us/sample - loss: 1.0060 - val_loss: 1.4909\n",
      "Epoch 249/300\n",
      "26400/26400 [==============================] - 3s 103us/sample - loss: 1.0053 - val_loss: 1.4581\n",
      "Epoch 250/300\n",
      "26400/26400 [==============================] - 3s 103us/sample - loss: 1.0006 - val_loss: 1.4725\n",
      "Epoch 251/300\n",
      "26400/26400 [==============================] - 3s 103us/sample - loss: 1.0049 - val_loss: 1.4711\n",
      "Epoch 252/300\n",
      "26400/26400 [==============================] - 3s 103us/sample - loss: 0.9854 - val_loss: 1.4902\n",
      "Epoch 253/300\n",
      "26400/26400 [==============================] - 3s 104us/sample - loss: 1.0006 - val_loss: 1.4440\n",
      "Epoch 254/300\n",
      "26400/26400 [==============================] - 3s 103us/sample - loss: 1.0033 - val_loss: 1.4808\n",
      "Epoch 255/300\n",
      "26400/26400 [==============================] - 3s 105us/sample - loss: 0.9927 - val_loss: 1.4999\n",
      "Epoch 256/300\n",
      "26400/26400 [==============================] - 3s 103us/sample - loss: 0.9855 - val_loss: 1.4681\n",
      "Epoch 257/300\n",
      "26400/26400 [==============================] - 3s 104us/sample - loss: 0.9747 - val_loss: 1.4849\n",
      "Epoch 258/300\n",
      "26400/26400 [==============================] - 3s 103us/sample - loss: 0.9990 - val_loss: 1.4999\n",
      "Epoch 259/300\n",
      "26400/26400 [==============================] - 3s 103us/sample - loss: 0.9881 - val_loss: 1.4911\n",
      "Epoch 260/300\n",
      "26400/26400 [==============================] - 3s 103us/sample - loss: 0.9920 - val_loss: 1.4926\n",
      "Epoch 261/300\n",
      "26400/26400 [==============================] - 3s 103us/sample - loss: 0.9869 - val_loss: 1.4492\n",
      "Epoch 262/300\n",
      "26400/26400 [==============================] - 3s 103us/sample - loss: 0.9856 - val_loss: 1.4368\n",
      "Epoch 263/300\n",
      "26400/26400 [==============================] - 3s 103us/sample - loss: 0.9819 - val_loss: 1.5406\n",
      "Epoch 264/300\n",
      "26400/26400 [==============================] - 3s 103us/sample - loss: 0.9986 - val_loss: 1.4980\n",
      "Epoch 265/300\n",
      "25856/26400 [============================>.] - ETA: 0s - loss: 0.9892Restoring model weights from the end of the best epoch.\n",
      "26400/26400 [==============================] - 3s 105us/sample - loss: 0.9892 - val_loss: 1.4474\n",
      "Epoch 00265: early stopping\n",
      "loss: 1.003 | val_loss: 1.424\n",
      "fold 1\n",
      "Train on 26400 samples, validate on 6600 samples\n",
      "Epoch 1/300\n",
      "26400/26400 [==============================] - 3s 120us/sample - loss: 2.4915 - val_loss: 2.3602\n",
      "Epoch 2/300\n",
      "26400/26400 [==============================] - 3s 103us/sample - loss: 2.2467 - val_loss: 2.1267\n",
      "Epoch 3/300\n",
      "26400/26400 [==============================] - 3s 102us/sample - loss: 2.1689 - val_loss: 2.1574\n",
      "Epoch 4/300\n",
      "26400/26400 [==============================] - 3s 103us/sample - loss: 2.1088 - val_loss: 2.1807\n",
      "Epoch 5/300\n",
      "26400/26400 [==============================] - 3s 102us/sample - loss: 2.0614 - val_loss: 2.1985\n",
      "Epoch 6/300\n",
      "26400/26400 [==============================] - 3s 102us/sample - loss: 2.0566 - val_loss: 2.1421\n",
      "Epoch 7/300\n",
      "26400/26400 [==============================] - 3s 102us/sample - loss: 2.0355 - val_loss: 2.2989\n",
      "Epoch 8/300\n",
      "26400/26400 [==============================] - 3s 102us/sample - loss: 2.0062 - val_loss: 1.9673\n",
      "Epoch 9/300\n",
      "26400/26400 [==============================] - 3s 102us/sample - loss: 1.9962 - val_loss: 1.9512\n",
      "Epoch 10/300\n",
      "26400/26400 [==============================] - 3s 103us/sample - loss: 1.9716 - val_loss: 1.9852\n",
      "Epoch 11/300\n",
      "26400/26400 [==============================] - 3s 104us/sample - loss: 1.9441 - val_loss: 2.0440\n",
      "Epoch 12/300\n",
      "26400/26400 [==============================] - 3s 103us/sample - loss: 1.9248 - val_loss: 1.8931\n",
      "Epoch 13/300\n",
      "26400/26400 [==============================] - 3s 102us/sample - loss: 1.9015 - val_loss: 1.9297\n",
      "Epoch 14/300\n",
      "26400/26400 [==============================] - 3s 102us/sample - loss: 1.8857 - val_loss: 1.9648\n",
      "Epoch 15/300\n",
      "26400/26400 [==============================] - 3s 103us/sample - loss: 1.8752 - val_loss: 1.9427\n",
      "Epoch 16/300\n",
      "26400/26400 [==============================] - 3s 102us/sample - loss: 1.8457 - val_loss: 1.9706\n",
      "Epoch 17/300\n",
      "26400/26400 [==============================] - 3s 102us/sample - loss: 1.8164 - val_loss: 1.9077\n",
      "Epoch 18/300\n",
      "26400/26400 [==============================] - 3s 103us/sample - loss: 1.8175 - val_loss: 1.9861\n",
      "Epoch 19/300\n",
      "26400/26400 [==============================] - 3s 102us/sample - loss: 1.7982 - val_loss: 1.8293\n",
      "Epoch 20/300\n",
      "26400/26400 [==============================] - 3s 102us/sample - loss: 1.7768 - val_loss: 1.9530\n",
      "Epoch 21/300\n",
      "26400/26400 [==============================] - 3s 103us/sample - loss: 1.7601 - val_loss: 1.8703\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22/300\n",
      "26400/26400 [==============================] - 3s 104us/sample - loss: 1.7371 - val_loss: 2.0320\n",
      "Epoch 23/300\n",
      "26400/26400 [==============================] - 3s 104us/sample - loss: 1.7124 - val_loss: 1.8487\n",
      "Epoch 24/300\n",
      "26400/26400 [==============================] - 3s 103us/sample - loss: 1.7002 - val_loss: 1.8548\n",
      "Epoch 25/300\n",
      "26400/26400 [==============================] - 3s 105us/sample - loss: 1.6837 - val_loss: 1.7840\n",
      "Epoch 26/300\n",
      "26400/26400 [==============================] - 3s 103us/sample - loss: 1.6838 - val_loss: 1.9763\n",
      "Epoch 27/300\n",
      "26400/26400 [==============================] - 3s 103us/sample - loss: 1.6648 - val_loss: 1.7940\n",
      "Epoch 28/300\n",
      "26400/26400 [==============================] - 3s 103us/sample - loss: 1.6530 - val_loss: 1.8169\n",
      "Epoch 29/300\n",
      "26400/26400 [==============================] - 3s 102us/sample - loss: 1.6275 - val_loss: 1.7923\n",
      "Epoch 30/300\n",
      "26400/26400 [==============================] - 3s 103us/sample - loss: 1.6200 - val_loss: 1.7479\n",
      "Epoch 31/300\n",
      "26400/26400 [==============================] - 3s 102us/sample - loss: 1.6051 - val_loss: 1.8256\n",
      "Epoch 32/300\n",
      "26400/26400 [==============================] - 3s 104us/sample - loss: 1.5876 - val_loss: 1.8274\n",
      "Epoch 33/300\n",
      "26400/26400 [==============================] - 3s 103us/sample - loss: 1.5867 - val_loss: 1.7303\n",
      "Epoch 34/300\n",
      "26400/26400 [==============================] - 3s 102us/sample - loss: 1.5735 - val_loss: 1.7770\n",
      "Epoch 35/300\n",
      "26400/26400 [==============================] - 3s 102us/sample - loss: 1.5600 - val_loss: 1.7598\n",
      "Epoch 36/300\n",
      "26400/26400 [==============================] - 3s 102us/sample - loss: 1.5560 - val_loss: 1.7369\n",
      "Epoch 37/300\n",
      "26400/26400 [==============================] - 3s 103us/sample - loss: 1.5402 - val_loss: 1.7341\n",
      "Epoch 38/300\n",
      "26400/26400 [==============================] - 3s 102us/sample - loss: 1.5280 - val_loss: 1.7282\n",
      "Epoch 39/300\n",
      "26400/26400 [==============================] - 3s 103us/sample - loss: 1.5200 - val_loss: 1.7384\n",
      "Epoch 40/300\n",
      "26400/26400 [==============================] - 3s 103us/sample - loss: 1.5134 - val_loss: 1.7580\n",
      "Epoch 41/300\n",
      "26400/26400 [==============================] - 3s 104us/sample - loss: 1.4985 - val_loss: 1.6906\n",
      "Epoch 42/300\n",
      "26400/26400 [==============================] - 3s 103us/sample - loss: 1.4866 - val_loss: 1.7387\n",
      "Epoch 43/300\n",
      "26400/26400 [==============================] - 3s 102us/sample - loss: 1.4826 - val_loss: 1.8942\n",
      "Epoch 44/300\n",
      "26400/26400 [==============================] - 3s 102us/sample - loss: 1.4741 - val_loss: 1.7612\n",
      "Epoch 45/300\n",
      "26400/26400 [==============================] - 3s 102us/sample - loss: 1.4779 - val_loss: 1.7727\n",
      "Epoch 46/300\n",
      "26400/26400 [==============================] - 3s 103us/sample - loss: 1.4674 - val_loss: 1.6806\n",
      "Epoch 47/300\n",
      "26400/26400 [==============================] - 3s 102us/sample - loss: 1.4546 - val_loss: 1.6763\n",
      "Epoch 48/300\n",
      "26400/26400 [==============================] - 3s 102us/sample - loss: 1.4481 - val_loss: 1.6976\n",
      "Epoch 49/300\n",
      "26400/26400 [==============================] - 3s 101us/sample - loss: 1.4351 - val_loss: 1.6995\n",
      "Epoch 50/300\n",
      "26400/26400 [==============================] - 3s 103us/sample - loss: 1.4376 - val_loss: 1.6664\n",
      "Epoch 51/300\n",
      "26400/26400 [==============================] - 3s 101us/sample - loss: 1.4264 - val_loss: 1.6805\n",
      "Epoch 52/300\n",
      "26400/26400 [==============================] - 3s 102us/sample - loss: 1.4251 - val_loss: 1.7146\n",
      "Epoch 53/300\n",
      "26400/26400 [==============================] - 3s 103us/sample - loss: 1.4101 - val_loss: 1.7022\n",
      "Epoch 54/300\n",
      "26400/26400 [==============================] - 3s 102us/sample - loss: 1.4043 - val_loss: 1.6911\n",
      "Epoch 55/300\n",
      "26400/26400 [==============================] - 3s 103us/sample - loss: 1.3977 - val_loss: 1.6521\n",
      "Epoch 56/300\n",
      "26400/26400 [==============================] - 3s 103us/sample - loss: 1.3865 - val_loss: 1.6755\n",
      "Epoch 57/300\n",
      "26400/26400 [==============================] - 3s 102us/sample - loss: 1.3867 - val_loss: 1.7068\n",
      "Epoch 58/300\n",
      "26400/26400 [==============================] - 3s 103us/sample - loss: 1.3752 - val_loss: 1.6743\n",
      "Epoch 59/300\n",
      "26400/26400 [==============================] - 3s 102us/sample - loss: 1.3810 - val_loss: 1.6500\n",
      "Epoch 60/300\n",
      "26400/26400 [==============================] - 3s 103us/sample - loss: 1.3658 - val_loss: 1.7052\n",
      "Epoch 61/300\n",
      "26400/26400 [==============================] - 3s 102us/sample - loss: 1.3659 - val_loss: 1.7200\n",
      "Epoch 62/300\n",
      "26400/26400 [==============================] - 3s 104us/sample - loss: 1.3627 - val_loss: 1.6687\n",
      "Epoch 63/300\n",
      "26400/26400 [==============================] - 3s 102us/sample - loss: 1.3619 - val_loss: 1.6712\n",
      "Epoch 64/300\n",
      "26400/26400 [==============================] - 3s 103us/sample - loss: 1.3448 - val_loss: 1.6076\n",
      "Epoch 65/300\n",
      "26400/26400 [==============================] - 3s 103us/sample - loss: 1.3467 - val_loss: 1.6572\n",
      "Epoch 66/300\n",
      "26400/26400 [==============================] - 3s 102us/sample - loss: 1.3392 - val_loss: 1.6443\n",
      "Epoch 67/300\n",
      "26400/26400 [==============================] - 3s 102us/sample - loss: 1.3219 - val_loss: 1.6666\n",
      "Epoch 68/300\n",
      "26400/26400 [==============================] - 3s 103us/sample - loss: 1.3200 - val_loss: 1.6191\n",
      "Epoch 69/300\n",
      "26400/26400 [==============================] - 3s 104us/sample - loss: 1.3255 - val_loss: 1.6051\n",
      "Epoch 70/300\n",
      "26400/26400 [==============================] - 3s 103us/sample - loss: 1.3155 - val_loss: 1.6475\n",
      "Epoch 71/300\n",
      "26400/26400 [==============================] - 3s 104us/sample - loss: 1.3125 - val_loss: 1.6695\n",
      "Epoch 72/300\n",
      "26400/26400 [==============================] - 3s 102us/sample - loss: 1.3049 - val_loss: 1.6553\n",
      "Epoch 73/300\n",
      "26400/26400 [==============================] - 3s 103us/sample - loss: 1.2980 - val_loss: 1.6209\n",
      "Epoch 74/300\n",
      "26400/26400 [==============================] - 3s 103us/sample - loss: 1.2935 - val_loss: 1.6068\n",
      "Epoch 75/300\n",
      "26400/26400 [==============================] - 3s 102us/sample - loss: 1.2855 - val_loss: 1.5921\n",
      "Epoch 76/300\n",
      "26400/26400 [==============================] - 3s 103us/sample - loss: 1.2787 - val_loss: 1.6359\n",
      "Epoch 77/300\n",
      "26400/26400 [==============================] - 3s 103us/sample - loss: 1.2928 - val_loss: 1.6205\n",
      "Epoch 78/300\n",
      "26400/26400 [==============================] - 3s 104us/sample - loss: 1.2804 - val_loss: 1.5993\n",
      "Epoch 79/300\n",
      "26400/26400 [==============================] - 3s 105us/sample - loss: 1.2833 - val_loss: 1.5800\n",
      "Epoch 80/300\n",
      "26400/26400 [==============================] - 3s 105us/sample - loss: 1.2652 - val_loss: 1.6032\n",
      "Epoch 81/300\n",
      "26400/26400 [==============================] - 3s 102us/sample - loss: 1.2696 - val_loss: 1.6337\n",
      "Epoch 82/300\n",
      "26400/26400 [==============================] - 3s 103us/sample - loss: 1.2595 - val_loss: 1.5824\n",
      "Epoch 83/300\n",
      "26400/26400 [==============================] - 3s 103us/sample - loss: 1.2599 - val_loss: 1.5885\n",
      "Epoch 84/300\n",
      "26400/26400 [==============================] - 3s 101us/sample - loss: 1.2600 - val_loss: 1.6018\n",
      "Epoch 85/300\n",
      "26400/26400 [==============================] - 3s 103us/sample - loss: 1.2513 - val_loss: 1.5884\n",
      "Epoch 86/300\n",
      "26400/26400 [==============================] - 3s 103us/sample - loss: 1.2563 - val_loss: 1.6412\n",
      "Epoch 87/300\n",
      "26400/26400 [==============================] - 3s 103us/sample - loss: 1.2473 - val_loss: 1.6119\n",
      "Epoch 88/300\n",
      "26400/26400 [==============================] - 3s 105us/sample - loss: 1.2446 - val_loss: 1.6013\n",
      "Epoch 89/300\n",
      "26400/26400 [==============================] - 3s 104us/sample - loss: 1.2458 - val_loss: 1.6177\n",
      "Epoch 90/300\n",
      "26400/26400 [==============================] - 3s 105us/sample - loss: 1.2391 - val_loss: 1.6374\n",
      "Epoch 91/300\n",
      "26400/26400 [==============================] - 3s 105us/sample - loss: 1.2374 - val_loss: 1.6008\n",
      "Epoch 92/300\n",
      "26400/26400 [==============================] - 3s 103us/sample - loss: 1.2268 - val_loss: 1.6216\n",
      "Epoch 93/300\n",
      "26400/26400 [==============================] - 3s 101us/sample - loss: 1.2326 - val_loss: 1.7162\n",
      "Epoch 94/300\n",
      "26400/26400 [==============================] - 3s 102us/sample - loss: 1.2268 - val_loss: 1.6019\n",
      "Epoch 95/300\n",
      "26400/26400 [==============================] - 3s 101us/sample - loss: 1.2141 - val_loss: 1.5762\n",
      "Epoch 96/300\n",
      "26400/26400 [==============================] - 3s 102us/sample - loss: 1.2188 - val_loss: 1.6119\n",
      "Epoch 97/300\n",
      "26400/26400 [==============================] - 3s 102us/sample - loss: 1.2097 - val_loss: 1.5533\n",
      "Epoch 98/300\n",
      "26400/26400 [==============================] - 3s 102us/sample - loss: 1.2074 - val_loss: 1.5322\n",
      "Epoch 99/300\n",
      "26400/26400 [==============================] - 3s 103us/sample - loss: 1.2088 - val_loss: 1.5847\n",
      "Epoch 100/300\n",
      "26400/26400 [==============================] - 3s 102us/sample - loss: 1.2040 - val_loss: 1.6131\n",
      "Epoch 101/300\n",
      "26400/26400 [==============================] - 3s 103us/sample - loss: 1.2048 - val_loss: 1.5406\n",
      "Epoch 102/300\n",
      "26400/26400 [==============================] - 3s 102us/sample - loss: 1.2030 - val_loss: 1.6008\n",
      "Epoch 103/300\n",
      "26400/26400 [==============================] - 3s 102us/sample - loss: 1.1891 - val_loss: 1.5403\n",
      "Epoch 104/300\n",
      "26400/26400 [==============================] - 3s 103us/sample - loss: 1.1967 - val_loss: 1.6022\n",
      "Epoch 105/300\n",
      "26400/26400 [==============================] - 3s 102us/sample - loss: 1.1966 - val_loss: 1.5483\n",
      "Epoch 106/300\n",
      "26400/26400 [==============================] - 3s 102us/sample - loss: 1.1938 - val_loss: 1.5939\n",
      "Epoch 107/300\n",
      "26400/26400 [==============================] - 3s 102us/sample - loss: 1.1972 - val_loss: 1.6353\n",
      "Epoch 108/300\n",
      "26400/26400 [==============================] - 3s 103us/sample - loss: 1.1931 - val_loss: 1.5677\n",
      "Epoch 109/300\n",
      "26400/26400 [==============================] - 3s 102us/sample - loss: 1.1890 - val_loss: 1.5385\n",
      "Epoch 110/300\n",
      "26400/26400 [==============================] - 3s 103us/sample - loss: 1.1741 - val_loss: 1.5821\n",
      "Epoch 111/300\n",
      "26400/26400 [==============================] - 3s 103us/sample - loss: 1.1733 - val_loss: 1.6142\n",
      "Epoch 112/300\n",
      "26400/26400 [==============================] - 3s 103us/sample - loss: 1.1728 - val_loss: 1.5442\n",
      "Epoch 113/300\n",
      "26400/26400 [==============================] - 3s 103us/sample - loss: 1.1833 - val_loss: 1.5770\n",
      "Epoch 114/300\n",
      "26400/26400 [==============================] - 3s 102us/sample - loss: 1.1745 - val_loss: 1.5402\n",
      "Epoch 115/300\n",
      "26400/26400 [==============================] - 3s 102us/sample - loss: 1.1659 - val_loss: 1.5614\n",
      "Epoch 116/300\n",
      "26400/26400 [==============================] - 3s 102us/sample - loss: 1.1701 - val_loss: 1.5432\n",
      "Epoch 117/300\n",
      "26400/26400 [==============================] - 3s 103us/sample - loss: 1.1616 - val_loss: 1.5305\n",
      "Epoch 118/300\n",
      "26400/26400 [==============================] - 3s 103us/sample - loss: 1.1597 - val_loss: 1.5442\n",
      "Epoch 119/300\n",
      "26400/26400 [==============================] - 3s 102us/sample - loss: 1.1583 - val_loss: 1.5628\n",
      "Epoch 120/300\n",
      "26400/26400 [==============================] - 3s 102us/sample - loss: 1.1656 - val_loss: 1.5599\n",
      "Epoch 121/300\n",
      "26400/26400 [==============================] - 3s 103us/sample - loss: 1.1546 - val_loss: 1.6337\n",
      "Epoch 122/300\n",
      "26400/26400 [==============================] - 3s 102us/sample - loss: 1.1442 - val_loss: 1.5635\n",
      "Epoch 123/300\n",
      "26400/26400 [==============================] - 3s 103us/sample - loss: 1.1442 - val_loss: 1.5503\n",
      "Epoch 124/300\n",
      "26400/26400 [==============================] - 3s 103us/sample - loss: 1.1453 - val_loss: 1.5809\n",
      "Epoch 125/300\n",
      "26400/26400 [==============================] - 3s 102us/sample - loss: 1.1398 - val_loss: 1.5506\n",
      "Epoch 126/300\n",
      "26400/26400 [==============================] - 3s 103us/sample - loss: 1.1458 - val_loss: 1.5601\n",
      "Epoch 127/300\n",
      "26400/26400 [==============================] - 3s 103us/sample - loss: 1.1412 - val_loss: 1.5722\n",
      "Epoch 128/300\n",
      "26400/26400 [==============================] - 3s 103us/sample - loss: 1.1340 - val_loss: 1.4927\n",
      "Epoch 129/300\n",
      "26400/26400 [==============================] - 3s 102us/sample - loss: 1.1361 - val_loss: 1.5908\n",
      "Epoch 130/300\n",
      "26400/26400 [==============================] - 3s 103us/sample - loss: 1.1316 - val_loss: 1.5900\n",
      "Epoch 131/300\n",
      "26400/26400 [==============================] - 3s 103us/sample - loss: 1.1250 - val_loss: 1.5658\n",
      "Epoch 132/300\n",
      "26400/26400 [==============================] - 3s 102us/sample - loss: 1.1286 - val_loss: 1.5782\n",
      "Epoch 133/300\n",
      "26400/26400 [==============================] - 3s 105us/sample - loss: 1.1301 - val_loss: 1.5454\n",
      "Epoch 134/300\n",
      "26400/26400 [==============================] - 3s 104us/sample - loss: 1.1267 - val_loss: 1.4756\n",
      "Epoch 135/300\n",
      "26400/26400 [==============================] - 3s 104us/sample - loss: 1.1307 - val_loss: 1.6677\n",
      "Epoch 136/300\n",
      "26400/26400 [==============================] - 3s 103us/sample - loss: 1.1171 - val_loss: 1.5165\n",
      "Epoch 137/300\n",
      "26400/26400 [==============================] - 3s 102us/sample - loss: 1.1232 - val_loss: 1.5986\n",
      "Epoch 138/300\n",
      "26400/26400 [==============================] - 3s 102us/sample - loss: 1.1272 - val_loss: 1.5102\n",
      "Epoch 139/300\n",
      "26400/26400 [==============================] - 3s 103us/sample - loss: 1.1215 - val_loss: 1.6046\n",
      "Epoch 140/300\n",
      "26400/26400 [==============================] - 3s 102us/sample - loss: 1.1164 - val_loss: 1.5398\n",
      "Epoch 141/300\n",
      "26400/26400 [==============================] - 3s 102us/sample - loss: 1.1079 - val_loss: 1.5181\n",
      "Epoch 142/300\n",
      "26400/26400 [==============================] - 3s 102us/sample - loss: 1.1198 - val_loss: 1.5170\n",
      "Epoch 143/300\n",
      "26400/26400 [==============================] - 3s 102us/sample - loss: 1.1231 - val_loss: 1.5654\n",
      "Epoch 144/300\n",
      "26400/26400 [==============================] - 3s 104us/sample - loss: 1.1054 - val_loss: 1.5854\n",
      "Epoch 145/300\n",
      "26400/26400 [==============================] - 3s 102us/sample - loss: 1.1137 - val_loss: 1.5249\n",
      "Epoch 146/300\n",
      "26400/26400 [==============================] - 3s 102us/sample - loss: 1.1045 - val_loss: 1.4958\n",
      "Epoch 147/300\n",
      "26400/26400 [==============================] - 3s 102us/sample - loss: 1.0971 - val_loss: 1.5256\n",
      "Epoch 148/300\n",
      "26400/26400 [==============================] - 3s 103us/sample - loss: 1.1038 - val_loss: 1.5679\n",
      "Epoch 149/300\n",
      "26400/26400 [==============================] - 3s 103us/sample - loss: 1.1114 - val_loss: 1.4949\n",
      "Epoch 150/300\n",
      "26400/26400 [==============================] - 3s 103us/sample - loss: 1.1110 - val_loss: 1.4684\n",
      "Epoch 151/300\n",
      "26400/26400 [==============================] - 3s 101us/sample - loss: 1.0987 - val_loss: 1.6036\n",
      "Epoch 152/300\n",
      "26400/26400 [==============================] - 3s 103us/sample - loss: 1.0958 - val_loss: 1.5540\n",
      "Epoch 153/300\n",
      "26400/26400 [==============================] - 3s 102us/sample - loss: 1.0893 - val_loss: 1.5109\n",
      "Epoch 154/300\n",
      "26400/26400 [==============================] - 3s 103us/sample - loss: 1.0883 - val_loss: 1.5191\n",
      "Epoch 155/300\n",
      "26400/26400 [==============================] - 3s 102us/sample - loss: 1.0848 - val_loss: 1.5180\n",
      "Epoch 156/300\n",
      "26400/26400 [==============================] - 3s 103us/sample - loss: 1.0889 - val_loss: 1.5344\n",
      "Epoch 157/300\n",
      "26400/26400 [==============================] - 3s 103us/sample - loss: 1.0848 - val_loss: 1.5544\n",
      "Epoch 158/300\n",
      "26400/26400 [==============================] - 3s 103us/sample - loss: 1.0628 - val_loss: 1.5338\n",
      "Epoch 159/300\n",
      "26400/26400 [==============================] - 3s 103us/sample - loss: 1.0883 - val_loss: 1.5134\n",
      "Epoch 160/300\n",
      "26400/26400 [==============================] - 3s 102us/sample - loss: 1.0887 - val_loss: 1.5484\n",
      "Epoch 161/300\n",
      "26400/26400 [==============================] - 3s 103us/sample - loss: 1.0721 - val_loss: 1.4642\n",
      "Epoch 162/300\n",
      "26400/26400 [==============================] - 3s 103us/sample - loss: 1.0757 - val_loss: 1.4943\n",
      "Epoch 163/300\n",
      "26400/26400 [==============================] - 3s 103us/sample - loss: 1.0695 - val_loss: 1.4970\n",
      "Epoch 164/300\n",
      "26400/26400 [==============================] - 3s 102us/sample - loss: 1.0714 - val_loss: 1.4730\n",
      "Epoch 165/300\n",
      "26400/26400 [==============================] - 3s 103us/sample - loss: 1.0845 - val_loss: 1.5011\n",
      "Epoch 166/300\n",
      "26400/26400 [==============================] - 3s 104us/sample - loss: 1.0759 - val_loss: 1.4682\n",
      "Epoch 167/300\n",
      "26400/26400 [==============================] - 3s 102us/sample - loss: 1.0586 - val_loss: 1.4691\n",
      "Epoch 168/300\n",
      "26400/26400 [==============================] - 3s 103us/sample - loss: 1.0688 - val_loss: 1.4805\n",
      "Epoch 169/300\n",
      "26400/26400 [==============================] - 3s 103us/sample - loss: 1.0633 - val_loss: 1.4770\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 170/300\n",
      "26400/26400 [==============================] - 3s 103us/sample - loss: 1.0664 - val_loss: 1.4786\n",
      "Epoch 171/300\n",
      "26400/26400 [==============================] - 3s 101us/sample - loss: 1.0622 - val_loss: 1.5467\n",
      "Epoch 172/300\n",
      "26400/26400 [==============================] - 3s 103us/sample - loss: 1.0712 - val_loss: 1.5664\n",
      "Epoch 173/300\n",
      "26400/26400 [==============================] - 3s 101us/sample - loss: 1.0630 - val_loss: 1.5563\n",
      "Epoch 174/300\n",
      "26400/26400 [==============================] - 3s 102us/sample - loss: 1.0706 - val_loss: 1.5293\n",
      "Epoch 175/300\n",
      "26400/26400 [==============================] - 3s 102us/sample - loss: 1.0636 - val_loss: 1.5629\n",
      "Epoch 176/300\n",
      "26400/26400 [==============================] - 3s 102us/sample - loss: 1.0689 - val_loss: 1.5424\n",
      "Epoch 177/300\n",
      "26400/26400 [==============================] - 3s 102us/sample - loss: 1.0655 - val_loss: 1.4964\n",
      "Epoch 178/300\n",
      "26400/26400 [==============================] - 3s 102us/sample - loss: 1.0743 - val_loss: 1.5420\n",
      "Epoch 179/300\n",
      "26400/26400 [==============================] - 3s 102us/sample - loss: 1.0589 - val_loss: 1.4952\n",
      "Epoch 180/300\n",
      "26400/26400 [==============================] - 3s 103us/sample - loss: 1.0514 - val_loss: 1.4892\n",
      "Epoch 181/300\n",
      "26400/26400 [==============================] - 3s 102us/sample - loss: 1.0607 - val_loss: 1.5015\n",
      "Epoch 182/300\n",
      "26400/26400 [==============================] - 3s 102us/sample - loss: 1.0416 - val_loss: 1.4782\n",
      "Epoch 183/300\n",
      "26400/26400 [==============================] - 3s 103us/sample - loss: 1.0584 - val_loss: 1.4875\n",
      "Epoch 184/300\n",
      "26400/26400 [==============================] - 3s 102us/sample - loss: 1.0547 - val_loss: 1.4885\n",
      "Epoch 185/300\n",
      "26400/26400 [==============================] - 3s 102us/sample - loss: 1.0574 - val_loss: 1.5071\n",
      "Epoch 186/300\n",
      "26400/26400 [==============================] - 3s 102us/sample - loss: 1.0594 - val_loss: 1.4738\n",
      "Epoch 187/300\n",
      "26400/26400 [==============================] - 3s 102us/sample - loss: 1.0543 - val_loss: 1.5194\n",
      "Epoch 188/300\n",
      "26400/26400 [==============================] - 3s 103us/sample - loss: 1.0434 - val_loss: 1.4867\n",
      "Epoch 189/300\n",
      "26400/26400 [==============================] - 3s 103us/sample - loss: 1.0379 - val_loss: 1.5233\n",
      "Epoch 190/300\n",
      "26400/26400 [==============================] - 3s 102us/sample - loss: 1.0474 - val_loss: 1.4858\n",
      "Epoch 191/300\n",
      "25920/26400 [============================>.] - ETA: 0s - loss: 1.0446Restoring model weights from the end of the best epoch.\n",
      "26400/26400 [==============================] - 3s 108us/sample - loss: 1.0436 - val_loss: 1.5242\n",
      "Epoch 00191: early stopping\n",
      "loss: 1.072 | val_loss: 1.464\n",
      "fold 2\n",
      "Train on 26400 samples, validate on 6600 samples\n",
      "Epoch 1/300\n",
      "26400/26400 [==============================] - 3s 124us/sample - loss: 2.4628 - val_loss: 2.4141\n",
      "Epoch 2/300\n",
      "26400/26400 [==============================] - 3s 102us/sample - loss: 2.2551 - val_loss: 2.1715\n",
      "Epoch 3/300\n",
      "26400/26400 [==============================] - 3s 102us/sample - loss: 2.1601 - val_loss: 2.0897\n",
      "Epoch 4/300\n",
      "26400/26400 [==============================] - 3s 102us/sample - loss: 2.0923 - val_loss: 2.1339\n",
      "Epoch 5/300\n",
      "26400/26400 [==============================] - 3s 102us/sample - loss: 2.0755 - val_loss: 2.1608\n",
      "Epoch 6/300\n",
      "26400/26400 [==============================] - 3s 103us/sample - loss: 2.0444 - val_loss: 2.0480\n",
      "Epoch 7/300\n",
      "26400/26400 [==============================] - 3s 103us/sample - loss: 2.0182 - val_loss: 2.0708\n",
      "Epoch 8/300\n",
      "26400/26400 [==============================] - 3s 103us/sample - loss: 1.9960 - val_loss: 1.9924\n",
      "Epoch 9/300\n",
      "26400/26400 [==============================] - 3s 103us/sample - loss: 1.9706 - val_loss: 1.9488\n",
      "Epoch 10/300\n",
      "26400/26400 [==============================] - 3s 103us/sample - loss: 1.9658 - val_loss: 1.9142\n",
      "Epoch 11/300\n",
      "26400/26400 [==============================] - 3s 107us/sample - loss: 1.9456 - val_loss: 1.9563\n",
      "Epoch 12/300\n",
      "26400/26400 [==============================] - 3s 106us/sample - loss: 1.9138 - val_loss: 1.9129\n",
      "Epoch 13/300\n",
      "26400/26400 [==============================] - 3s 105us/sample - loss: 1.8904 - val_loss: 1.8926\n",
      "Epoch 14/300\n",
      "26400/26400 [==============================] - 3s 106us/sample - loss: 1.8774 - val_loss: 1.9266\n",
      "Epoch 15/300\n",
      "26400/26400 [==============================] - 3s 103us/sample - loss: 1.8649 - val_loss: 1.9378\n",
      "Epoch 16/300\n",
      "26400/26400 [==============================] - 3s 101us/sample - loss: 1.8290 - val_loss: 1.8504\n",
      "Epoch 17/300\n",
      "26400/26400 [==============================] - 3s 102us/sample - loss: 1.8063 - val_loss: 1.8311\n",
      "Epoch 18/300\n",
      "26400/26400 [==============================] - 3s 102us/sample - loss: 1.7910 - val_loss: 1.8777\n",
      "Epoch 19/300\n",
      "26400/26400 [==============================] - 3s 102us/sample - loss: 1.7730 - val_loss: 1.8187\n",
      "Epoch 20/300\n",
      "26400/26400 [==============================] - 3s 102us/sample - loss: 1.7483 - val_loss: 1.9164\n",
      "Epoch 21/300\n",
      "26400/26400 [==============================] - 3s 102us/sample - loss: 1.7244 - val_loss: 1.8141\n",
      "Epoch 22/300\n",
      "26400/26400 [==============================] - 3s 102us/sample - loss: 1.7078 - val_loss: 1.7829\n",
      "Epoch 23/300\n",
      "26400/26400 [==============================] - 3s 104us/sample - loss: 1.7043 - val_loss: 1.7817\n",
      "Epoch 24/300\n",
      "26400/26400 [==============================] - 3s 103us/sample - loss: 1.6901 - val_loss: 1.8112\n",
      "Epoch 25/300\n",
      "26400/26400 [==============================] - 3s 102us/sample - loss: 1.6724 - val_loss: 1.7804\n",
      "Epoch 26/300\n",
      "26400/26400 [==============================] - 3s 102us/sample - loss: 1.6636 - val_loss: 1.7788\n",
      "Epoch 27/300\n",
      "26400/26400 [==============================] - 3s 103us/sample - loss: 1.6392 - val_loss: 1.8007\n",
      "Epoch 28/300\n",
      "26400/26400 [==============================] - 3s 102us/sample - loss: 1.6237 - val_loss: 1.7469\n",
      "Epoch 29/300\n",
      "26400/26400 [==============================] - 3s 101us/sample - loss: 1.6126 - val_loss: 1.7505\n",
      "Epoch 30/300\n",
      "26400/26400 [==============================] - 3s 102us/sample - loss: 1.6053 - val_loss: 1.7640\n",
      "Epoch 31/300\n",
      "26400/26400 [==============================] - 3s 102us/sample - loss: 1.5796 - val_loss: 1.7858\n",
      "Epoch 32/300\n",
      "26400/26400 [==============================] - 3s 102us/sample - loss: 1.5747 - val_loss: 1.7746\n",
      "Epoch 33/300\n",
      "26400/26400 [==============================] - 3s 103us/sample - loss: 1.5648 - val_loss: 1.8104\n",
      "Epoch 34/300\n",
      "26400/26400 [==============================] - 3s 102us/sample - loss: 1.5623 - val_loss: 1.8312\n",
      "Epoch 35/300\n",
      "26400/26400 [==============================] - 3s 102us/sample - loss: 1.5387 - val_loss: 1.7951\n",
      "Epoch 36/300\n",
      "26400/26400 [==============================] - 3s 102us/sample - loss: 1.5285 - val_loss: 1.6909\n",
      "Epoch 37/300\n",
      "26400/26400 [==============================] - 3s 102us/sample - loss: 1.5164 - val_loss: 1.7112\n",
      "Epoch 38/300\n",
      "26400/26400 [==============================] - 3s 101us/sample - loss: 1.5110 - val_loss: 1.7948\n",
      "Epoch 39/300\n",
      "26400/26400 [==============================] - 3s 102us/sample - loss: 1.5110 - val_loss: 1.7727\n",
      "Epoch 40/300\n",
      "26400/26400 [==============================] - 3s 103us/sample - loss: 1.4939 - val_loss: 1.6887\n",
      "Epoch 41/300\n",
      "26400/26400 [==============================] - 3s 102us/sample - loss: 1.4789 - val_loss: 1.6948\n",
      "Epoch 42/300\n",
      "26400/26400 [==============================] - 3s 101us/sample - loss: 1.4729 - val_loss: 1.7073\n",
      "Epoch 43/300\n",
      "26400/26400 [==============================] - 3s 102us/sample - loss: 1.4644 - val_loss: 1.6753\n",
      "Epoch 44/300\n",
      "26400/26400 [==============================] - 3s 101us/sample - loss: 1.4680 - val_loss: 1.6902\n",
      "Epoch 45/300\n",
      "26400/26400 [==============================] - 3s 104us/sample - loss: 1.4523 - val_loss: 1.6608\n",
      "Epoch 46/300\n",
      "26400/26400 [==============================] - 3s 103us/sample - loss: 1.4380 - val_loss: 1.6685\n",
      "Epoch 47/300\n",
      "26400/26400 [==============================] - 3s 102us/sample - loss: 1.4361 - val_loss: 1.6725\n",
      "Epoch 48/300\n",
      "26400/26400 [==============================] - 3s 102us/sample - loss: 1.4274 - val_loss: 1.6851\n",
      "Epoch 49/300\n",
      "26400/26400 [==============================] - 3s 102us/sample - loss: 1.4167 - val_loss: 1.6476\n",
      "Epoch 50/300\n",
      "26400/26400 [==============================] - 3s 103us/sample - loss: 1.4101 - val_loss: 1.6906\n",
      "Epoch 51/300\n",
      "26400/26400 [==============================] - 3s 102us/sample - loss: 1.3984 - val_loss: 1.6615\n",
      "Epoch 52/300\n",
      "26400/26400 [==============================] - 3s 101us/sample - loss: 1.4021 - val_loss: 1.6844\n",
      "Epoch 53/300\n",
      "26400/26400 [==============================] - 3s 103us/sample - loss: 1.3939 - val_loss: 1.6396\n",
      "Epoch 54/300\n",
      "26400/26400 [==============================] - 3s 103us/sample - loss: 1.3958 - val_loss: 1.6208\n",
      "Epoch 55/300\n",
      "26400/26400 [==============================] - 3s 104us/sample - loss: 1.3835 - val_loss: 1.6354\n",
      "Epoch 56/300\n",
      "26400/26400 [==============================] - 3s 103us/sample - loss: 1.3805 - val_loss: 1.6633\n",
      "Epoch 57/300\n",
      "26400/26400 [==============================] - 3s 103us/sample - loss: 1.3746 - val_loss: 1.6310\n",
      "Epoch 58/300\n",
      "26400/26400 [==============================] - 3s 102us/sample - loss: 1.3621 - val_loss: 1.6564\n",
      "Epoch 59/300\n",
      "26400/26400 [==============================] - 3s 102us/sample - loss: 1.3611 - val_loss: 1.6183\n",
      "Epoch 60/300\n",
      "26400/26400 [==============================] - 3s 102us/sample - loss: 1.3559 - val_loss: 1.6441\n",
      "Epoch 61/300\n",
      "26400/26400 [==============================] - 3s 102us/sample - loss: 1.3422 - val_loss: 1.6539\n",
      "Epoch 62/300\n",
      "26400/26400 [==============================] - 3s 104us/sample - loss: 1.3568 - val_loss: 1.6332\n",
      "Epoch 63/300\n",
      "26400/26400 [==============================] - 3s 102us/sample - loss: 1.3406 - val_loss: 1.6070\n",
      "Epoch 64/300\n",
      "26400/26400 [==============================] - 3s 101us/sample - loss: 1.3362 - val_loss: 1.6015\n",
      "Epoch 65/300\n",
      "26400/26400 [==============================] - 3s 102us/sample - loss: 1.3308 - val_loss: 1.5926\n",
      "Epoch 66/300\n",
      "26400/26400 [==============================] - 3s 102us/sample - loss: 1.3330 - val_loss: 1.6719\n",
      "Epoch 67/300\n",
      "26400/26400 [==============================] - 3s 102us/sample - loss: 1.3285 - val_loss: 1.6087\n",
      "Epoch 68/300\n",
      "26400/26400 [==============================] - 3s 102us/sample - loss: 1.3146 - val_loss: 1.6077\n",
      "Epoch 69/300\n",
      "26400/26400 [==============================] - 3s 102us/sample - loss: 1.3173 - val_loss: 1.5937\n",
      "Epoch 70/300\n",
      "26400/26400 [==============================] - 3s 102us/sample - loss: 1.3049 - val_loss: 1.5860\n",
      "Epoch 71/300\n",
      "26400/26400 [==============================] - 3s 102us/sample - loss: 1.3144 - val_loss: 1.6435\n",
      "Epoch 72/300\n",
      "26400/26400 [==============================] - 3s 102us/sample - loss: 1.2997 - val_loss: 1.5949\n",
      "Epoch 73/300\n",
      "26400/26400 [==============================] - 3s 102us/sample - loss: 1.2854 - val_loss: 1.6120\n",
      "Epoch 74/300\n",
      "26400/26400 [==============================] - 3s 102us/sample - loss: 1.2897 - val_loss: 1.6070\n",
      "Epoch 75/300\n",
      "26400/26400 [==============================] - 3s 102us/sample - loss: 1.2905 - val_loss: 1.5682\n",
      "Epoch 76/300\n",
      "26400/26400 [==============================] - 3s 102us/sample - loss: 1.2813 - val_loss: 1.6084\n",
      "Epoch 77/300\n",
      "26400/26400 [==============================] - 3s 102us/sample - loss: 1.2835 - val_loss: 1.5846\n",
      "Epoch 78/300\n",
      "26400/26400 [==============================] - 3s 102us/sample - loss: 1.2744 - val_loss: 1.5719\n",
      "Epoch 79/300\n",
      "26400/26400 [==============================] - 3s 102us/sample - loss: 1.2675 - val_loss: 1.5865\n",
      "Epoch 80/300\n",
      "26400/26400 [==============================] - 3s 102us/sample - loss: 1.2664 - val_loss: 1.5641\n",
      "Epoch 81/300\n",
      "26400/26400 [==============================] - 3s 102us/sample - loss: 1.2708 - val_loss: 1.5861\n",
      "Epoch 82/300\n",
      "26400/26400 [==============================] - 3s 102us/sample - loss: 1.2539 - val_loss: 1.5588\n",
      "Epoch 83/300\n",
      "26400/26400 [==============================] - 3s 103us/sample - loss: 1.2503 - val_loss: 1.6723\n",
      "Epoch 84/300\n",
      "26400/26400 [==============================] - 3s 102us/sample - loss: 1.2565 - val_loss: 1.6125\n",
      "Epoch 85/300\n",
      "26400/26400 [==============================] - 3s 104us/sample - loss: 1.2482 - val_loss: 1.6496\n",
      "Epoch 86/300\n",
      "26400/26400 [==============================] - 3s 102us/sample - loss: 1.2405 - val_loss: 1.5688\n",
      "Epoch 87/300\n",
      "26400/26400 [==============================] - 3s 102us/sample - loss: 1.2431 - val_loss: 1.5729\n",
      "Epoch 88/300\n",
      "26400/26400 [==============================] - 3s 102us/sample - loss: 1.2463 - val_loss: 1.5647\n",
      "Epoch 89/300\n",
      "26400/26400 [==============================] - 3s 102us/sample - loss: 1.2265 - val_loss: 1.5735\n",
      "Epoch 90/300\n",
      "26400/26400 [==============================] - 3s 103us/sample - loss: 1.2276 - val_loss: 1.5485\n",
      "Epoch 91/300\n",
      "26400/26400 [==============================] - 3s 103us/sample - loss: 1.2375 - val_loss: 1.5737\n",
      "Epoch 92/300\n",
      "26400/26400 [==============================] - 3s 102us/sample - loss: 1.2186 - val_loss: 1.5508\n",
      "Epoch 93/300\n",
      "26400/26400 [==============================] - 3s 103us/sample - loss: 1.2287 - val_loss: 1.5781\n",
      "Epoch 94/300\n",
      "26400/26400 [==============================] - 3s 103us/sample - loss: 1.2226 - val_loss: 1.5477\n",
      "Epoch 95/300\n",
      "26400/26400 [==============================] - 3s 102us/sample - loss: 1.2193 - val_loss: 1.5326\n",
      "Epoch 96/300\n",
      "26400/26400 [==============================] - 3s 102us/sample - loss: 1.2191 - val_loss: 1.5750\n",
      "Epoch 97/300\n",
      "26400/26400 [==============================] - 3s 103us/sample - loss: 1.2092 - val_loss: 1.6166\n",
      "Epoch 98/300\n",
      "26400/26400 [==============================] - 3s 102us/sample - loss: 1.2399 - val_loss: 1.5991\n",
      "Epoch 99/300\n",
      "26400/26400 [==============================] - 3s 102us/sample - loss: 1.2190 - val_loss: 1.5799\n",
      "Epoch 100/300\n",
      "26400/26400 [==============================] - 3s 102us/sample - loss: 1.2009 - val_loss: 1.5282\n",
      "Epoch 101/300\n",
      "26400/26400 [==============================] - 3s 102us/sample - loss: 1.2033 - val_loss: 1.5393\n",
      "Epoch 102/300\n",
      "26400/26400 [==============================] - 3s 103us/sample - loss: 1.2064 - val_loss: 1.5886\n",
      "Epoch 103/300\n",
      "26400/26400 [==============================] - 3s 103us/sample - loss: 1.1937 - val_loss: 1.5406\n",
      "Epoch 104/300\n",
      "26400/26400 [==============================] - 3s 102us/sample - loss: 1.1878 - val_loss: 1.5356\n",
      "Epoch 105/300\n",
      "26400/26400 [==============================] - 3s 102us/sample - loss: 1.1996 - val_loss: 1.5127\n",
      "Epoch 106/300\n",
      "26400/26400 [==============================] - 3s 102us/sample - loss: 1.1933 - val_loss: 1.5120\n",
      "Epoch 107/300\n",
      "26400/26400 [==============================] - 3s 103us/sample - loss: 1.1811 - val_loss: 1.5898\n",
      "Epoch 108/300\n",
      "26400/26400 [==============================] - 3s 102us/sample - loss: 1.1812 - val_loss: 1.5749\n",
      "Epoch 109/300\n",
      "26400/26400 [==============================] - 3s 102us/sample - loss: 1.1728 - val_loss: 1.5671\n",
      "Epoch 110/300\n",
      "26400/26400 [==============================] - 3s 103us/sample - loss: 1.1785 - val_loss: 1.5879\n",
      "Epoch 111/300\n",
      "26400/26400 [==============================] - 3s 102us/sample - loss: 1.1749 - val_loss: 1.5550\n",
      "Epoch 112/300\n",
      "26400/26400 [==============================] - 3s 104us/sample - loss: 1.1676 - val_loss: 1.5472\n",
      "Epoch 113/300\n",
      "26400/26400 [==============================] - 3s 104us/sample - loss: 1.1659 - val_loss: 1.5270\n",
      "Epoch 114/300\n",
      "26400/26400 [==============================] - 3s 104us/sample - loss: 1.1694 - val_loss: 1.6077\n",
      "Epoch 115/300\n",
      "26400/26400 [==============================] - 3s 103us/sample - loss: 1.1682 - val_loss: 1.5420\n",
      "Epoch 116/300\n",
      "26400/26400 [==============================] - 3s 103us/sample - loss: 1.1692 - val_loss: 1.5734\n",
      "Epoch 117/300\n",
      "26400/26400 [==============================] - 3s 103us/sample - loss: 1.1621 - val_loss: 1.6168\n",
      "Epoch 118/300\n",
      "26400/26400 [==============================] - 3s 102us/sample - loss: 1.1639 - val_loss: 1.5942\n",
      "Epoch 119/300\n",
      "26400/26400 [==============================] - 3s 102us/sample - loss: 1.1684 - val_loss: 1.5569\n",
      "Epoch 120/300\n",
      "26400/26400 [==============================] - 3s 102us/sample - loss: 1.1507 - val_loss: 1.5642\n",
      "Epoch 121/300\n",
      "26400/26400 [==============================] - 3s 102us/sample - loss: 1.1536 - val_loss: 1.5595\n",
      "Epoch 122/300\n",
      "26400/26400 [==============================] - 3s 102us/sample - loss: 1.1568 - val_loss: 1.5311\n",
      "Epoch 123/300\n",
      "26400/26400 [==============================] - 3s 101us/sample - loss: 1.1342 - val_loss: 1.5189\n",
      "Epoch 124/300\n",
      "26400/26400 [==============================] - 3s 103us/sample - loss: 1.1403 - val_loss: 1.5122\n",
      "Epoch 125/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26400/26400 [==============================] - 3s 102us/sample - loss: 1.1402 - val_loss: 1.5184\n",
      "Epoch 126/300\n",
      "26400/26400 [==============================] - 3s 106us/sample - loss: 1.1356 - val_loss: 1.5318\n",
      "Epoch 127/300\n",
      "26400/26400 [==============================] - 3s 104us/sample - loss: 1.1340 - val_loss: 1.5159\n",
      "Epoch 128/300\n",
      "26400/26400 [==============================] - 3s 105us/sample - loss: 1.1396 - val_loss: 1.5356\n",
      "Epoch 129/300\n",
      "26400/26400 [==============================] - 3s 107us/sample - loss: 1.1327 - val_loss: 1.5657\n",
      "Epoch 130/300\n",
      "26400/26400 [==============================] - 3s 103us/sample - loss: 1.1303 - val_loss: 1.5027\n",
      "Epoch 131/300\n",
      "26400/26400 [==============================] - 3s 102us/sample - loss: 1.1249 - val_loss: 1.5437\n",
      "Epoch 132/300\n",
      "26400/26400 [==============================] - 3s 102us/sample - loss: 1.1262 - val_loss: 1.5188\n",
      "Epoch 133/300\n",
      "26400/26400 [==============================] - 3s 103us/sample - loss: 1.1241 - val_loss: 1.4926\n",
      "Epoch 134/300\n",
      "26400/26400 [==============================] - 3s 102us/sample - loss: 1.1369 - val_loss: 1.5751\n",
      "Epoch 135/300\n",
      "26400/26400 [==============================] - 3s 102us/sample - loss: 1.1221 - val_loss: 1.5769\n",
      "Epoch 136/300\n",
      "26400/26400 [==============================] - 3s 102us/sample - loss: 1.1129 - val_loss: 1.5137\n",
      "Epoch 137/300\n",
      "26400/26400 [==============================] - 3s 102us/sample - loss: 1.1167 - val_loss: 1.5014\n",
      "Epoch 138/300\n",
      "26400/26400 [==============================] - 3s 102us/sample - loss: 1.1085 - val_loss: 1.5190\n",
      "Epoch 139/300\n",
      "26400/26400 [==============================] - 3s 102us/sample - loss: 1.1108 - val_loss: 1.5138\n",
      "Epoch 140/300\n",
      "26400/26400 [==============================] - 3s 102us/sample - loss: 1.1066 - val_loss: 1.5718\n",
      "Epoch 141/300\n",
      "26400/26400 [==============================] - 3s 102us/sample - loss: 1.1071 - val_loss: 1.5969\n",
      "Epoch 142/300\n",
      "26400/26400 [==============================] - 3s 102us/sample - loss: 1.1050 - val_loss: 1.5432\n",
      "Epoch 143/300\n",
      "26400/26400 [==============================] - 3s 104us/sample - loss: 1.1066 - val_loss: 1.5383\n",
      "Epoch 144/300\n",
      "26400/26400 [==============================] - 3s 103us/sample - loss: 1.1127 - val_loss: 1.4911\n",
      "Epoch 145/300\n",
      "26400/26400 [==============================] - 3s 102us/sample - loss: 1.0970 - val_loss: 1.4973\n",
      "Epoch 146/300\n",
      "26400/26400 [==============================] - 3s 103us/sample - loss: 1.0977 - val_loss: 1.5388\n",
      "Epoch 147/300\n",
      "26400/26400 [==============================] - 3s 102us/sample - loss: 1.0922 - val_loss: 1.4930\n",
      "Epoch 148/300\n",
      "26400/26400 [==============================] - 3s 103us/sample - loss: 1.1078 - val_loss: 1.4904\n",
      "Epoch 149/300\n",
      "26400/26400 [==============================] - 3s 103us/sample - loss: 1.0828 - val_loss: 1.5626\n",
      "Epoch 150/300\n",
      "26400/26400 [==============================] - 3s 102us/sample - loss: 1.0989 - val_loss: 1.5863\n",
      "Epoch 151/300\n",
      "26400/26400 [==============================] - 3s 104us/sample - loss: 1.0987 - val_loss: 1.5366\n",
      "Epoch 152/300\n",
      "26400/26400 [==============================] - 3s 102us/sample - loss: 1.0863 - val_loss: 1.5005\n",
      "Epoch 153/300\n",
      "26400/26400 [==============================] - 3s 101us/sample - loss: 1.0957 - val_loss: 1.5187\n",
      "Epoch 154/300\n",
      "26400/26400 [==============================] - 3s 102us/sample - loss: 1.0961 - val_loss: 1.5238\n",
      "Epoch 155/300\n",
      "26400/26400 [==============================] - 3s 102us/sample - loss: 1.0945 - val_loss: 1.4975\n",
      "Epoch 156/300\n",
      "26400/26400 [==============================] - 3s 103us/sample - loss: 1.0874 - val_loss: 1.4939\n",
      "Epoch 157/300\n",
      "26400/26400 [==============================] - 3s 102us/sample - loss: 1.0696 - val_loss: 1.4794\n",
      "Epoch 158/300\n",
      "26400/26400 [==============================] - 3s 102us/sample - loss: 1.0850 - val_loss: 1.5055\n",
      "Epoch 159/300\n",
      "26400/26400 [==============================] - 3s 102us/sample - loss: 1.0703 - val_loss: 1.5237\n",
      "Epoch 160/300\n",
      "26400/26400 [==============================] - 3s 102us/sample - loss: 1.0711 - val_loss: 1.4862\n",
      "Epoch 161/300\n",
      "26400/26400 [==============================] - 3s 102us/sample - loss: 1.0833 - val_loss: 1.5042\n",
      "Epoch 162/300\n",
      "26400/26400 [==============================] - 3s 102us/sample - loss: 1.0730 - val_loss: 1.5300\n",
      "Epoch 163/300\n",
      "26400/26400 [==============================] - 3s 102us/sample - loss: 1.0655 - val_loss: 1.5218\n",
      "Epoch 164/300\n",
      "26400/26400 [==============================] - 3s 102us/sample - loss: 1.0715 - val_loss: 1.4922\n",
      "Epoch 165/300\n",
      "26400/26400 [==============================] - 3s 102us/sample - loss: 1.0789 - val_loss: 1.4972\n",
      "Epoch 166/300\n",
      "26400/26400 [==============================] - 3s 104us/sample - loss: 1.0753 - val_loss: 1.5112\n",
      "Epoch 167/300\n",
      "26400/26400 [==============================] - 3s 103us/sample - loss: 1.0595 - val_loss: 1.5251\n",
      "Epoch 168/300\n",
      "26400/26400 [==============================] - 3s 101us/sample - loss: 1.0588 - val_loss: 1.4771\n",
      "Epoch 169/300\n",
      "26400/26400 [==============================] - 3s 102us/sample - loss: 1.0686 - val_loss: 1.4966\n",
      "Epoch 170/300\n",
      "26400/26400 [==============================] - 3s 101us/sample - loss: 1.0632 - val_loss: 1.4972\n",
      "Epoch 171/300\n",
      "26400/26400 [==============================] - 3s 102us/sample - loss: 1.0606 - val_loss: 1.4958\n",
      "Epoch 172/300\n",
      "26400/26400 [==============================] - 3s 103us/sample - loss: 1.0643 - val_loss: 1.4968\n",
      "Epoch 173/300\n",
      "26400/26400 [==============================] - 3s 103us/sample - loss: 1.0531 - val_loss: 1.5176\n",
      "Epoch 174/300\n",
      "26400/26400 [==============================] - 3s 102us/sample - loss: 1.0581 - val_loss: 1.5661\n",
      "Epoch 175/300\n",
      "26400/26400 [==============================] - 3s 102us/sample - loss: 1.0580 - val_loss: 1.5092\n",
      "Epoch 176/300\n",
      "26400/26400 [==============================] - 3s 102us/sample - loss: 1.0632 - val_loss: 1.4866\n",
      "Epoch 177/300\n",
      "26400/26400 [==============================] - 3s 102us/sample - loss: 1.0575 - val_loss: 1.4797\n",
      "Epoch 178/300\n",
      "26400/26400 [==============================] - 3s 102us/sample - loss: 1.0572 - val_loss: 1.5122\n",
      "Epoch 179/300\n",
      "26400/26400 [==============================] - 3s 102us/sample - loss: 1.0490 - val_loss: 1.4641\n",
      "Epoch 180/300\n",
      "26400/26400 [==============================] - 3s 102us/sample - loss: 1.0543 - val_loss: 1.4777\n",
      "Epoch 181/300\n",
      "26400/26400 [==============================] - 3s 101us/sample - loss: 1.0418 - val_loss: 1.5611\n",
      "Epoch 182/300\n",
      "26400/26400 [==============================] - 3s 102us/sample - loss: 1.0395 - val_loss: 1.4578\n",
      "Epoch 183/300\n",
      "26400/26400 [==============================] - 3s 102us/sample - loss: 1.0444 - val_loss: 1.4910\n",
      "Epoch 184/300\n",
      "26400/26400 [==============================] - 3s 103us/sample - loss: 1.0480 - val_loss: 1.4663\n",
      "Epoch 185/300\n",
      "26400/26400 [==============================] - 3s 102us/sample - loss: 1.0417 - val_loss: 1.4788\n",
      "Epoch 186/300\n",
      "26400/26400 [==============================] - 3s 102us/sample - loss: 1.0425 - val_loss: 1.4875\n",
      "Epoch 187/300\n",
      "26400/26400 [==============================] - 3s 102us/sample - loss: 1.0470 - val_loss: 1.4990\n",
      "Epoch 188/300\n",
      "26400/26400 [==============================] - 3s 102us/sample - loss: 1.0417 - val_loss: 1.5132\n",
      "Epoch 189/300\n",
      "26400/26400 [==============================] - 3s 102us/sample - loss: 1.0423 - val_loss: 1.5210\n",
      "Epoch 190/300\n",
      "26400/26400 [==============================] - 3s 101us/sample - loss: 1.0410 - val_loss: 1.5349\n",
      "Epoch 191/300\n",
      "26400/26400 [==============================] - 3s 103us/sample - loss: 1.0342 - val_loss: 1.5008\n",
      "Epoch 192/300\n",
      "26400/26400 [==============================] - 3s 102us/sample - loss: 1.0342 - val_loss: 1.4973\n",
      "Epoch 193/300\n",
      "26400/26400 [==============================] - 3s 103us/sample - loss: 1.0479 - val_loss: 1.4433\n",
      "Epoch 194/300\n",
      "26400/26400 [==============================] - 3s 102us/sample - loss: 1.0377 - val_loss: 1.5486\n",
      "Epoch 195/300\n",
      "26400/26400 [==============================] - 3s 102us/sample - loss: 1.0303 - val_loss: 1.5044\n",
      "Epoch 196/300\n",
      "26400/26400 [==============================] - 3s 103us/sample - loss: 1.0307 - val_loss: 1.4685\n",
      "Epoch 197/300\n",
      "26400/26400 [==============================] - 3s 102us/sample - loss: 1.0219 - val_loss: 1.5882\n",
      "Epoch 198/300\n",
      "26400/26400 [==============================] - 3s 102us/sample - loss: 1.0299 - val_loss: 1.4665\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 199/300\n",
      "26400/26400 [==============================] - 3s 102us/sample - loss: 1.0268 - val_loss: 1.4864\n",
      "Epoch 200/300\n",
      "26400/26400 [==============================] - 3s 103us/sample - loss: 1.0325 - val_loss: 1.4631\n",
      "Epoch 201/300\n",
      "26400/26400 [==============================] - 3s 101us/sample - loss: 1.0291 - val_loss: 1.4734\n",
      "Epoch 202/300\n",
      "26400/26400 [==============================] - 3s 103us/sample - loss: 1.0290 - val_loss: 1.4831\n",
      "Epoch 203/300\n",
      "26400/26400 [==============================] - 3s 102us/sample - loss: 1.0246 - val_loss: 1.5337\n",
      "Epoch 204/300\n",
      "26400/26400 [==============================] - 3s 103us/sample - loss: 1.0159 - val_loss: 1.4654\n",
      "Epoch 205/300\n",
      "26400/26400 [==============================] - 3s 102us/sample - loss: 1.0179 - val_loss: 1.5069\n",
      "Epoch 206/300\n",
      "26400/26400 [==============================] - 3s 102us/sample - loss: 1.0315 - val_loss: 1.4615\n",
      "Epoch 207/300\n",
      "26400/26400 [==============================] - 3s 103us/sample - loss: 1.0300 - val_loss: 1.5362\n",
      "Epoch 208/300\n",
      "26400/26400 [==============================] - 3s 102us/sample - loss: 1.0186 - val_loss: 1.5442\n",
      "Epoch 209/300\n",
      "26400/26400 [==============================] - 3s 101us/sample - loss: 1.0193 - val_loss: 1.4582\n",
      "Epoch 210/300\n",
      "26400/26400 [==============================] - 3s 103us/sample - loss: 1.0262 - val_loss: 1.5185\n",
      "Epoch 211/300\n",
      "26400/26400 [==============================] - 3s 102us/sample - loss: 1.0228 - val_loss: 1.4514\n",
      "Epoch 212/300\n",
      "26400/26400 [==============================] - 3s 101us/sample - loss: 1.0104 - val_loss: 1.5012\n",
      "Epoch 213/300\n",
      "26400/26400 [==============================] - 3s 103us/sample - loss: 1.0175 - val_loss: 1.5020\n",
      "Epoch 214/300\n",
      "26400/26400 [==============================] - 3s 102us/sample - loss: 1.0112 - val_loss: 1.4887\n",
      "Epoch 215/300\n",
      "26400/26400 [==============================] - 3s 102us/sample - loss: 1.0119 - val_loss: 1.4762\n",
      "Epoch 216/300\n",
      "26400/26400 [==============================] - 3s 102us/sample - loss: 1.0132 - val_loss: 1.4611\n",
      "Epoch 217/300\n",
      "26400/26400 [==============================] - 3s 102us/sample - loss: 1.0080 - val_loss: 1.4979\n",
      "Epoch 218/300\n",
      "26400/26400 [==============================] - 3s 102us/sample - loss: 1.0058 - val_loss: 1.4950\n",
      "Epoch 219/300\n",
      "26400/26400 [==============================] - 3s 101us/sample - loss: 1.0085 - val_loss: 1.5032\n",
      "Epoch 220/300\n",
      "26400/26400 [==============================] - 3s 102us/sample - loss: 1.0066 - val_loss: 1.4937\n",
      "Epoch 221/300\n",
      "26400/26400 [==============================] - 3s 102us/sample - loss: 1.0154 - val_loss: 1.4607\n",
      "Epoch 222/300\n",
      "26400/26400 [==============================] - 3s 102us/sample - loss: 1.0103 - val_loss: 1.4283\n",
      "Epoch 223/300\n",
      "26400/26400 [==============================] - 3s 103us/sample - loss: 1.0117 - val_loss: 1.5266\n",
      "Epoch 224/300\n",
      "26400/26400 [==============================] - 3s 102us/sample - loss: 0.9978 - val_loss: 1.4758\n",
      "Epoch 225/300\n",
      "26400/26400 [==============================] - 3s 104us/sample - loss: 1.0105 - val_loss: 1.4544\n",
      "Epoch 226/300\n",
      "26400/26400 [==============================] - 3s 103us/sample - loss: 1.0048 - val_loss: 1.4830\n",
      "Epoch 227/300\n",
      "26400/26400 [==============================] - 3s 102us/sample - loss: 0.9965 - val_loss: 1.4335\n",
      "Epoch 228/300\n",
      "26400/26400 [==============================] - 3s 102us/sample - loss: 0.9977 - val_loss: 1.4832\n",
      "Epoch 229/300\n",
      "26400/26400 [==============================] - 3s 103us/sample - loss: 1.0096 - val_loss: 1.4805\n",
      "Epoch 230/300\n",
      "26400/26400 [==============================] - 3s 102us/sample - loss: 0.9949 - val_loss: 1.4778\n",
      "Epoch 231/300\n",
      "26400/26400 [==============================] - 3s 102us/sample - loss: 0.9969 - val_loss: 1.4364\n",
      "Epoch 232/300\n",
      "26400/26400 [==============================] - 3s 103us/sample - loss: 0.9945 - val_loss: 1.5218\n",
      "Epoch 233/300\n",
      "26400/26400 [==============================] - 3s 103us/sample - loss: 1.0012 - val_loss: 1.4875\n",
      "Epoch 234/300\n",
      "26400/26400 [==============================] - 3s 102us/sample - loss: 0.9834 - val_loss: 1.4571\n",
      "Epoch 235/300\n",
      "26400/26400 [==============================] - 3s 103us/sample - loss: 0.9817 - val_loss: 1.5016\n",
      "Epoch 236/300\n",
      "26400/26400 [==============================] - 3s 104us/sample - loss: 0.9774 - val_loss: 1.4541\n",
      "Epoch 237/300\n",
      "26400/26400 [==============================] - 3s 102us/sample - loss: 1.0021 - val_loss: 1.4357\n",
      "Epoch 238/300\n",
      "26400/26400 [==============================] - 3s 102us/sample - loss: 0.9837 - val_loss: 1.5352\n",
      "Epoch 239/300\n",
      "26400/26400 [==============================] - 3s 102us/sample - loss: 0.9917 - val_loss: 1.5016\n",
      "Epoch 240/300\n",
      "26400/26400 [==============================] - 3s 103us/sample - loss: 0.9882 - val_loss: 1.4209\n",
      "Epoch 241/300\n",
      "26400/26400 [==============================] - 3s 107us/sample - loss: 0.9889 - val_loss: 1.4545\n",
      "Epoch 242/300\n",
      "26400/26400 [==============================] - 3s 104us/sample - loss: 0.9882 - val_loss: 1.4825\n",
      "Epoch 243/300\n",
      "26400/26400 [==============================] - 3s 105us/sample - loss: 0.9896 - val_loss: 1.4332\n",
      "Epoch 244/300\n",
      "26400/26400 [==============================] - 3s 105us/sample - loss: 0.9875 - val_loss: 1.4899\n",
      "Epoch 245/300\n",
      "26400/26400 [==============================] - 3s 102us/sample - loss: 0.9847 - val_loss: 1.4614\n",
      "Epoch 246/300\n",
      "26400/26400 [==============================] - 3s 103us/sample - loss: 0.9805 - val_loss: 1.4570\n",
      "Epoch 247/300\n",
      "26400/26400 [==============================] - 3s 102us/sample - loss: 0.9757 - val_loss: 1.4766\n",
      "Epoch 248/300\n",
      "26400/26400 [==============================] - 3s 103us/sample - loss: 0.9740 - val_loss: 1.4286\n",
      "Epoch 249/300\n",
      "26400/26400 [==============================] - 3s 102us/sample - loss: 0.9674 - val_loss: 1.4880\n",
      "Epoch 250/300\n",
      "26400/26400 [==============================] - 3s 103us/sample - loss: 0.9758 - val_loss: 1.4620\n",
      "Epoch 251/300\n",
      "26400/26400 [==============================] - 3s 101us/sample - loss: 0.9817 - val_loss: 1.4515\n",
      "Epoch 252/300\n",
      "26400/26400 [==============================] - 3s 102us/sample - loss: 0.9777 - val_loss: 1.4366\n",
      "Epoch 253/300\n",
      "26400/26400 [==============================] - 3s 102us/sample - loss: 0.9761 - val_loss: 1.4317\n",
      "Epoch 254/300\n",
      "26400/26400 [==============================] - 3s 102us/sample - loss: 0.9743 - val_loss: 1.4572\n",
      "Epoch 255/300\n",
      "26400/26400 [==============================] - 3s 102us/sample - loss: 0.9759 - val_loss: 1.4821\n",
      "Epoch 256/300\n",
      "26400/26400 [==============================] - 3s 102us/sample - loss: 0.9718 - val_loss: 1.5113\n",
      "Epoch 257/300\n",
      "26400/26400 [==============================] - 3s 101us/sample - loss: 0.9714 - val_loss: 1.5269\n",
      "Epoch 258/300\n",
      "26400/26400 [==============================] - 3s 102us/sample - loss: 0.9687 - val_loss: 1.4787\n",
      "Epoch 259/300\n",
      "26400/26400 [==============================] - 3s 103us/sample - loss: 0.9686 - val_loss: 1.4621\n",
      "Epoch 260/300\n",
      "26400/26400 [==============================] - 3s 101us/sample - loss: 0.9696 - val_loss: 1.4931\n",
      "Epoch 261/300\n",
      "26400/26400 [==============================] - 3s 103us/sample - loss: 0.9700 - val_loss: 1.4934\n",
      "Epoch 262/300\n",
      "26400/26400 [==============================] - 3s 103us/sample - loss: 0.9752 - val_loss: 1.4274\n",
      "Epoch 263/300\n",
      "26400/26400 [==============================] - 3s 102us/sample - loss: 0.9852 - val_loss: 1.4257\n",
      "Epoch 264/300\n",
      "26400/26400 [==============================] - 3s 102us/sample - loss: 0.9706 - val_loss: 1.4447\n",
      "Epoch 265/300\n",
      "26400/26400 [==============================] - 3s 102us/sample - loss: 0.9684 - val_loss: 1.4289\n",
      "Epoch 266/300\n",
      "26400/26400 [==============================] - 3s 102us/sample - loss: 0.9716 - val_loss: 1.4339\n",
      "Epoch 267/300\n",
      "26400/26400 [==============================] - 3s 102us/sample - loss: 0.9664 - val_loss: 1.4860\n",
      "Epoch 268/300\n",
      "26400/26400 [==============================] - 3s 101us/sample - loss: 0.9603 - val_loss: 1.4116\n",
      "Epoch 269/300\n",
      "26400/26400 [==============================] - 3s 103us/sample - loss: 0.9672 - val_loss: 1.4315\n",
      "Epoch 270/300\n",
      "26400/26400 [==============================] - 3s 103us/sample - loss: 0.9537 - val_loss: 1.5025\n",
      "Epoch 271/300\n",
      "26400/26400 [==============================] - 3s 102us/sample - loss: 0.9646 - val_loss: 1.4475\n",
      "Epoch 272/300\n",
      "26400/26400 [==============================] - 3s 101us/sample - loss: 0.9591 - val_loss: 1.4204\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 273/300\n",
      "26400/26400 [==============================] - 3s 102us/sample - loss: 0.9702 - val_loss: 1.4319\n",
      "Epoch 274/300\n",
      "26400/26400 [==============================] - 3s 103us/sample - loss: 0.9591 - val_loss: 1.4691\n",
      "Epoch 275/300\n",
      "26400/26400 [==============================] - 3s 102us/sample - loss: 0.9636 - val_loss: 1.4902\n",
      "Epoch 276/300\n",
      "26400/26400 [==============================] - 3s 102us/sample - loss: 0.9629 - val_loss: 1.4914\n",
      "Epoch 277/300\n",
      "26400/26400 [==============================] - 3s 102us/sample - loss: 0.9583 - val_loss: 1.4596\n",
      "Epoch 278/300\n",
      "26400/26400 [==============================] - 3s 105us/sample - loss: 0.9624 - val_loss: 1.4202\n",
      "Epoch 279/300\n",
      "26400/26400 [==============================] - 3s 103us/sample - loss: 0.9648 - val_loss: 1.4258\n",
      "Epoch 280/300\n",
      "26400/26400 [==============================] - 3s 102us/sample - loss: 0.9609 - val_loss: 1.4811\n",
      "Epoch 281/300\n",
      "26400/26400 [==============================] - 3s 102us/sample - loss: 0.9639 - val_loss: 1.5166\n",
      "Epoch 282/300\n",
      "26400/26400 [==============================] - 3s 102us/sample - loss: 0.9536 - val_loss: 1.4606\n",
      "Epoch 283/300\n",
      "26400/26400 [==============================] - 3s 102us/sample - loss: 0.9558 - val_loss: 1.4136\n",
      "Epoch 284/300\n",
      "26400/26400 [==============================] - 3s 104us/sample - loss: 0.9650 - val_loss: 1.4713\n",
      "Epoch 285/300\n",
      "26400/26400 [==============================] - 3s 102us/sample - loss: 0.9483 - val_loss: 1.4084\n",
      "Epoch 286/300\n",
      "26400/26400 [==============================] - 3s 101us/sample - loss: 0.9461 - val_loss: 1.4489\n",
      "Epoch 287/300\n",
      "26400/26400 [==============================] - 3s 102us/sample - loss: 0.9504 - val_loss: 1.4857\n",
      "Epoch 288/300\n",
      "26400/26400 [==============================] - 3s 101us/sample - loss: 0.9498 - val_loss: 1.5164\n",
      "Epoch 289/300\n",
      "26400/26400 [==============================] - 3s 102us/sample - loss: 0.9508 - val_loss: 1.4365\n",
      "Epoch 290/300\n",
      "26400/26400 [==============================] - 3s 102us/sample - loss: 0.9565 - val_loss: 1.4290\n",
      "Epoch 291/300\n",
      "26400/26400 [==============================] - 3s 102us/sample - loss: 0.9470 - val_loss: 1.4310\n",
      "Epoch 292/300\n",
      "26400/26400 [==============================] - 3s 101us/sample - loss: 0.9567 - val_loss: 1.5301\n",
      "Epoch 293/300\n",
      "26400/26400 [==============================] - 3s 102us/sample - loss: 0.9517 - val_loss: 1.4696\n",
      "Epoch 294/300\n",
      "26400/26400 [==============================] - 3s 102us/sample - loss: 0.9400 - val_loss: 1.4257\n",
      "Epoch 295/300\n",
      "26400/26400 [==============================] - 3s 102us/sample - loss: 0.9565 - val_loss: 1.4094\n",
      "Epoch 296/300\n",
      "26400/26400 [==============================] - 3s 102us/sample - loss: 0.9430 - val_loss: 1.4972\n",
      "Epoch 297/300\n",
      "26400/26400 [==============================] - 3s 101us/sample - loss: 0.9392 - val_loss: 1.4729\n",
      "Epoch 298/300\n",
      "26400/26400 [==============================] - 3s 102us/sample - loss: 0.9496 - val_loss: 1.4270\n",
      "Epoch 299/300\n",
      "26400/26400 [==============================] - 3s 102us/sample - loss: 0.9401 - val_loss: 1.4964\n",
      "Epoch 300/300\n",
      "26400/26400 [==============================] - 3s 102us/sample - loss: 0.9417 - val_loss: 1.4422\n",
      "loss: 0.954 | val_loss: 1.503\n",
      "fold 3\n",
      "Train on 26400 samples, validate on 6600 samples\n",
      "Epoch 1/300\n",
      "26400/26400 [==============================] - 3s 126us/sample - loss: 2.5128 - val_loss: 2.3478\n",
      "Epoch 2/300\n",
      "26400/26400 [==============================] - 3s 102us/sample - loss: 2.2636 - val_loss: 2.3918\n",
      "Epoch 3/300\n",
      "26400/26400 [==============================] - 3s 102us/sample - loss: 2.1645 - val_loss: 2.4503\n",
      "Epoch 4/300\n",
      "26400/26400 [==============================] - 3s 102us/sample - loss: 2.1032 - val_loss: 2.0896\n",
      "Epoch 5/300\n",
      "26400/26400 [==============================] - 3s 103us/sample - loss: 2.0890 - val_loss: 2.2439\n",
      "Epoch 6/300\n",
      "26400/26400 [==============================] - 3s 103us/sample - loss: 2.0621 - val_loss: 2.3643\n",
      "Epoch 7/300\n",
      "26400/26400 [==============================] - 3s 103us/sample - loss: 2.0370 - val_loss: 2.2369\n",
      "Epoch 8/300\n",
      "26400/26400 [==============================] - 3s 103us/sample - loss: 2.0117 - val_loss: 2.0112\n",
      "Epoch 9/300\n",
      "26400/26400 [==============================] - 3s 103us/sample - loss: 1.9904 - val_loss: 2.1027\n",
      "Epoch 10/300\n",
      "26400/26400 [==============================] - 3s 103us/sample - loss: 1.9674 - val_loss: 2.0249\n",
      "Epoch 11/300\n",
      "26400/26400 [==============================] - 3s 103us/sample - loss: 1.9411 - val_loss: 1.9980\n",
      "Epoch 12/300\n",
      "26400/26400 [==============================] - 3s 104us/sample - loss: 1.9187 - val_loss: 1.9911\n",
      "Epoch 13/300\n",
      "26400/26400 [==============================] - 3s 103us/sample - loss: 1.8983 - val_loss: 1.9184\n",
      "Epoch 14/300\n",
      "26400/26400 [==============================] - 3s 102us/sample - loss: 1.8917 - val_loss: 1.9566\n",
      "Epoch 15/300\n",
      "26400/26400 [==============================] - 3s 102us/sample - loss: 1.8849 - val_loss: 1.8986\n",
      "Epoch 16/300\n",
      "26400/26400 [==============================] - 3s 103us/sample - loss: 1.8525 - val_loss: 1.9767\n",
      "Epoch 17/300\n",
      "26400/26400 [==============================] - 3s 102us/sample - loss: 1.8324 - val_loss: 1.8960\n",
      "Epoch 18/300\n",
      "26400/26400 [==============================] - 3s 103us/sample - loss: 1.8043 - val_loss: 1.8461\n",
      "Epoch 19/300\n",
      "26400/26400 [==============================] - 3s 103us/sample - loss: 1.7910 - val_loss: 1.8311\n",
      "Epoch 20/300\n",
      "26400/26400 [==============================] - 3s 102us/sample - loss: 1.7750 - val_loss: 1.8448\n",
      "Epoch 21/300\n",
      "26400/26400 [==============================] - 3s 104us/sample - loss: 1.7583 - val_loss: 1.8485\n",
      "Epoch 22/300\n",
      "26400/26400 [==============================] - 3s 102us/sample - loss: 1.7355 - val_loss: 1.8459\n",
      "Epoch 23/300\n",
      "26400/26400 [==============================] - 3s 103us/sample - loss: 1.7141 - val_loss: 1.9140\n",
      "Epoch 24/300\n",
      "26400/26400 [==============================] - 3s 103us/sample - loss: 1.6973 - val_loss: 1.8129\n",
      "Epoch 25/300\n",
      "26400/26400 [==============================] - 3s 104us/sample - loss: 1.6888 - val_loss: 1.7667\n",
      "Epoch 26/300\n",
      "26400/26400 [==============================] - 3s 103us/sample - loss: 1.6725 - val_loss: 1.8736\n",
      "Epoch 27/300\n",
      "26400/26400 [==============================] - 3s 102us/sample - loss: 1.6612 - val_loss: 1.8083\n",
      "Epoch 28/300\n",
      "26400/26400 [==============================] - 3s 103us/sample - loss: 1.6494 - val_loss: 1.7776\n",
      "Epoch 29/300\n",
      "26400/26400 [==============================] - 3s 102us/sample - loss: 1.6188 - val_loss: 1.7953\n",
      "Epoch 30/300\n",
      "26400/26400 [==============================] - 3s 102us/sample - loss: 1.6201 - val_loss: 1.7542\n",
      "Epoch 31/300\n",
      "26400/26400 [==============================] - 3s 104us/sample - loss: 1.6047 - val_loss: 1.7762\n",
      "Epoch 32/300\n",
      "26400/26400 [==============================] - 3s 103us/sample - loss: 1.5861 - val_loss: 1.7367\n",
      "Epoch 33/300\n",
      "26400/26400 [==============================] - 3s 102us/sample - loss: 1.5803 - val_loss: 1.7519\n",
      "Epoch 34/300\n",
      "26400/26400 [==============================] - 3s 103us/sample - loss: 1.5584 - val_loss: 1.7490\n",
      "Epoch 35/300\n",
      "26400/26400 [==============================] - 3s 102us/sample - loss: 1.5588 - val_loss: 1.7541\n",
      "Epoch 36/300\n",
      "26400/26400 [==============================] - 3s 103us/sample - loss: 1.5535 - val_loss: 1.7334\n",
      "Epoch 37/300\n",
      "26400/26400 [==============================] - 3s 105us/sample - loss: 1.5460 - val_loss: 1.7706\n",
      "Epoch 38/300\n",
      "26400/26400 [==============================] - 3s 106us/sample - loss: 1.5271 - val_loss: 1.7132\n",
      "Epoch 39/300\n",
      "26400/26400 [==============================] - 3s 104us/sample - loss: 1.5356 - val_loss: 1.6962\n",
      "Epoch 40/300\n",
      "26400/26400 [==============================] - 3s 102us/sample - loss: 1.5237 - val_loss: 1.7413\n",
      "Epoch 41/300\n",
      "26400/26400 [==============================] - 3s 102us/sample - loss: 1.5026 - val_loss: 1.7285\n",
      "Epoch 42/300\n",
      "26400/26400 [==============================] - 3s 102us/sample - loss: 1.4974 - val_loss: 1.7259\n",
      "Epoch 43/300\n",
      "26400/26400 [==============================] - 3s 102us/sample - loss: 1.4836 - val_loss: 1.7421\n",
      "Epoch 44/300\n",
      "26400/26400 [==============================] - 3s 102us/sample - loss: 1.4707 - val_loss: 1.7260\n",
      "Epoch 45/300\n",
      "26400/26400 [==============================] - 3s 103us/sample - loss: 1.4590 - val_loss: 1.6874\n",
      "Epoch 46/300\n",
      "26400/26400 [==============================] - 3s 103us/sample - loss: 1.4639 - val_loss: 1.6628\n",
      "Epoch 47/300\n",
      "26400/26400 [==============================] - 3s 102us/sample - loss: 1.4544 - val_loss: 1.6999\n",
      "Epoch 48/300\n",
      "26400/26400 [==============================] - 3s 103us/sample - loss: 1.4560 - val_loss: 1.7014\n",
      "Epoch 49/300\n",
      "26400/26400 [==============================] - 3s 103us/sample - loss: 1.4382 - val_loss: 1.6849\n",
      "Epoch 50/300\n",
      "26400/26400 [==============================] - 3s 104us/sample - loss: 1.4259 - val_loss: 1.6539\n",
      "Epoch 51/300\n",
      "26400/26400 [==============================] - 3s 102us/sample - loss: 1.4205 - val_loss: 1.6700\n",
      "Epoch 52/300\n",
      "26400/26400 [==============================] - 3s 102us/sample - loss: 1.4137 - val_loss: 1.6327\n",
      "Epoch 53/300\n",
      "26400/26400 [==============================] - 3s 102us/sample - loss: 1.4040 - val_loss: 1.6426\n",
      "Epoch 54/300\n",
      "26400/26400 [==============================] - 3s 104us/sample - loss: 1.4026 - val_loss: 1.6821\n",
      "Epoch 55/300\n",
      "26400/26400 [==============================] - 3s 108us/sample - loss: 1.4028 - val_loss: 1.6495\n",
      "Epoch 56/300\n",
      "26400/26400 [==============================] - 3s 106us/sample - loss: 1.3883 - val_loss: 1.6632\n",
      "Epoch 57/300\n",
      "26400/26400 [==============================] - 3s 105us/sample - loss: 1.3864 - val_loss: 1.7227\n",
      "Epoch 58/300\n",
      "26400/26400 [==============================] - 3s 107us/sample - loss: 1.3803 - val_loss: 1.6632\n",
      "Epoch 59/300\n",
      "26400/26400 [==============================] - 3s 104us/sample - loss: 1.3718 - val_loss: 1.6137\n",
      "Epoch 60/300\n",
      "26400/26400 [==============================] - 3s 103us/sample - loss: 1.3683 - val_loss: 1.7841\n",
      "Epoch 61/300\n",
      "26400/26400 [==============================] - 3s 102us/sample - loss: 1.3578 - val_loss: 1.7150\n",
      "Epoch 62/300\n",
      "26400/26400 [==============================] - 3s 103us/sample - loss: 1.3565 - val_loss: 1.6447\n",
      "Epoch 63/300\n",
      "26400/26400 [==============================] - 3s 103us/sample - loss: 1.3483 - val_loss: 1.6238\n",
      "Epoch 64/300\n",
      "26400/26400 [==============================] - 3s 103us/sample - loss: 1.3436 - val_loss: 1.6013\n",
      "Epoch 65/300\n",
      "26400/26400 [==============================] - 3s 103us/sample - loss: 1.3497 - val_loss: 1.6085\n",
      "Epoch 66/300\n",
      "26400/26400 [==============================] - 3s 103us/sample - loss: 1.3356 - val_loss: 1.6136\n",
      "Epoch 67/300\n",
      "26400/26400 [==============================] - 3s 103us/sample - loss: 1.3285 - val_loss: 1.6767\n",
      "Epoch 68/300\n",
      "26400/26400 [==============================] - 3s 102us/sample - loss: 1.3178 - val_loss: 1.6738\n",
      "Epoch 69/300\n",
      "26400/26400 [==============================] - 3s 103us/sample - loss: 1.3202 - val_loss: 1.6280\n",
      "Epoch 70/300\n",
      "26400/26400 [==============================] - 3s 103us/sample - loss: 1.3124 - val_loss: 1.6206\n",
      "Epoch 71/300\n",
      "26400/26400 [==============================] - 3s 102us/sample - loss: 1.3097 - val_loss: 1.6191\n",
      "Epoch 72/300\n",
      "26400/26400 [==============================] - 3s 103us/sample - loss: 1.3135 - val_loss: 1.5820\n",
      "Epoch 73/300\n",
      "26400/26400 [==============================] - 3s 103us/sample - loss: 1.3038 - val_loss: 1.6118\n",
      "Epoch 74/300\n",
      "26400/26400 [==============================] - 3s 102us/sample - loss: 1.2975 - val_loss: 1.7391\n",
      "Epoch 75/300\n",
      "26400/26400 [==============================] - 3s 103us/sample - loss: 1.2962 - val_loss: 1.5802\n",
      "Epoch 76/300\n",
      "26400/26400 [==============================] - 3s 103us/sample - loss: 1.2933 - val_loss: 1.6338\n",
      "Epoch 77/300\n",
      "26400/26400 [==============================] - 3s 103us/sample - loss: 1.2872 - val_loss: 1.5985\n",
      "Epoch 78/300\n",
      "26400/26400 [==============================] - 3s 103us/sample - loss: 1.2905 - val_loss: 1.6632\n",
      "Epoch 79/300\n",
      "26400/26400 [==============================] - 3s 103us/sample - loss: 1.2702 - val_loss: 1.5889\n",
      "Epoch 80/300\n",
      "26400/26400 [==============================] - 3s 103us/sample - loss: 1.2747 - val_loss: 1.5688\n",
      "Epoch 81/300\n",
      "26400/26400 [==============================] - 3s 103us/sample - loss: 1.2734 - val_loss: 1.6874\n",
      "Epoch 82/300\n",
      "26400/26400 [==============================] - 3s 104us/sample - loss: 1.2731 - val_loss: 1.5753\n",
      "Epoch 83/300\n",
      "26400/26400 [==============================] - 3s 103us/sample - loss: 1.2640 - val_loss: 1.5701\n",
      "Epoch 84/300\n",
      "26400/26400 [==============================] - 3s 103us/sample - loss: 1.2511 - val_loss: 1.5350\n",
      "Epoch 85/300\n",
      "26400/26400 [==============================] - 3s 102us/sample - loss: 1.2690 - val_loss: 1.6028\n",
      "Epoch 86/300\n",
      "26400/26400 [==============================] - 3s 103us/sample - loss: 1.2461 - val_loss: 1.6857\n",
      "Epoch 87/300\n",
      "26400/26400 [==============================] - 3s 102us/sample - loss: 1.2550 - val_loss: 1.5710\n",
      "Epoch 88/300\n",
      "26400/26400 [==============================] - 3s 102us/sample - loss: 1.2406 - val_loss: 1.5512\n",
      "Epoch 89/300\n",
      "26400/26400 [==============================] - 3s 105us/sample - loss: 1.2427 - val_loss: 1.6018\n",
      "Epoch 90/300\n",
      "26400/26400 [==============================] - 3s 105us/sample - loss: 1.2486 - val_loss: 1.6201\n",
      "Epoch 91/300\n",
      "26400/26400 [==============================] - 3s 103us/sample - loss: 1.2337 - val_loss: 1.6305\n",
      "Epoch 92/300\n",
      "26400/26400 [==============================] - 3s 103us/sample - loss: 1.2318 - val_loss: 1.5337\n",
      "Epoch 93/300\n",
      "26400/26400 [==============================] - 3s 104us/sample - loss: 1.2218 - val_loss: 1.6214\n",
      "Epoch 94/300\n",
      "26400/26400 [==============================] - 3s 103us/sample - loss: 1.2209 - val_loss: 1.5765\n",
      "Epoch 95/300\n",
      "26400/26400 [==============================] - 3s 103us/sample - loss: 1.2187 - val_loss: 1.6498\n",
      "Epoch 96/300\n",
      "26400/26400 [==============================] - 3s 103us/sample - loss: 1.2189 - val_loss: 1.5691\n",
      "Epoch 97/300\n",
      "26400/26400 [==============================] - 3s 103us/sample - loss: 1.2192 - val_loss: 1.6142\n",
      "Epoch 98/300\n",
      "26400/26400 [==============================] - 3s 103us/sample - loss: 1.2183 - val_loss: 1.5525\n",
      "Epoch 99/300\n",
      "26400/26400 [==============================] - 3s 102us/sample - loss: 1.2185 - val_loss: 1.5770\n",
      "Epoch 100/300\n",
      "26400/26400 [==============================] - 3s 104us/sample - loss: 1.2021 - val_loss: 1.6131\n",
      "Epoch 101/300\n",
      "26400/26400 [==============================] - 3s 102us/sample - loss: 1.2061 - val_loss: 1.6055\n",
      "Epoch 102/300\n",
      "26400/26400 [==============================] - 3s 103us/sample - loss: 1.1997 - val_loss: 1.5341\n",
      "Epoch 103/300\n",
      "26400/26400 [==============================] - 3s 103us/sample - loss: 1.2090 - val_loss: 1.5955\n",
      "Epoch 104/300\n",
      "26400/26400 [==============================] - 3s 103us/sample - loss: 1.1920 - val_loss: 1.6722\n",
      "Epoch 105/300\n",
      "26400/26400 [==============================] - 3s 102us/sample - loss: 1.1926 - val_loss: 1.5227\n",
      "Epoch 106/300\n",
      "26400/26400 [==============================] - 3s 102us/sample - loss: 1.1881 - val_loss: 1.5483\n",
      "Epoch 107/300\n",
      "26400/26400 [==============================] - 3s 102us/sample - loss: 1.1820 - val_loss: 1.5560\n",
      "Epoch 108/300\n",
      "26400/26400 [==============================] - 3s 103us/sample - loss: 1.1753 - val_loss: 1.5259\n",
      "Epoch 109/300\n",
      "26400/26400 [==============================] - 3s 103us/sample - loss: 1.1784 - val_loss: 1.6671\n",
      "Epoch 110/300\n",
      "26400/26400 [==============================] - 3s 103us/sample - loss: 1.1774 - val_loss: 1.5322\n",
      "Epoch 111/300\n",
      "26400/26400 [==============================] - 3s 102us/sample - loss: 1.1867 - val_loss: 1.5657\n",
      "Epoch 112/300\n",
      "26400/26400 [==============================] - 3s 103us/sample - loss: 1.1814 - val_loss: 1.6242\n",
      "Epoch 113/300\n",
      "26400/26400 [==============================] - 3s 102us/sample - loss: 1.1695 - val_loss: 1.5425\n",
      "Epoch 114/300\n",
      "26400/26400 [==============================] - 3s 102us/sample - loss: 1.1692 - val_loss: 1.5857\n",
      "Epoch 115/300\n",
      "26400/26400 [==============================] - 3s 104us/sample - loss: 1.1705 - val_loss: 1.5775\n",
      "Epoch 116/300\n",
      "26400/26400 [==============================] - 3s 105us/sample - loss: 1.1582 - val_loss: 1.5549\n",
      "Epoch 117/300\n",
      "26400/26400 [==============================] - 3s 103us/sample - loss: 1.1607 - val_loss: 1.5221\n",
      "Epoch 118/300\n",
      "26400/26400 [==============================] - 3s 104us/sample - loss: 1.1626 - val_loss: 1.5705\n",
      "Epoch 119/300\n",
      "26400/26400 [==============================] - 3s 103us/sample - loss: 1.1599 - val_loss: 1.5090\n",
      "Epoch 120/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26400/26400 [==============================] - 3s 104us/sample - loss: 1.1528 - val_loss: 1.5651\n",
      "Epoch 121/300\n",
      "26400/26400 [==============================] - 3s 103us/sample - loss: 1.1516 - val_loss: 1.5607\n",
      "Epoch 122/300\n",
      "26400/26400 [==============================] - 3s 102us/sample - loss: 1.1483 - val_loss: 1.5253\n",
      "Epoch 123/300\n",
      "26400/26400 [==============================] - 3s 102us/sample - loss: 1.1475 - val_loss: 1.6028\n",
      "Epoch 124/300\n",
      "26400/26400 [==============================] - 3s 102us/sample - loss: 1.1534 - val_loss: 1.5428\n",
      "Epoch 125/300\n",
      "26400/26400 [==============================] - 3s 102us/sample - loss: 1.1486 - val_loss: 1.6172\n",
      "Epoch 126/300\n",
      "26400/26400 [==============================] - 3s 103us/sample - loss: 1.1423 - val_loss: 1.4798\n",
      "Epoch 127/300\n",
      "26400/26400 [==============================] - 3s 103us/sample - loss: 1.1397 - val_loss: 1.5361\n",
      "Epoch 128/300\n",
      "26400/26400 [==============================] - 3s 103us/sample - loss: 1.1403 - val_loss: 1.5393\n",
      "Epoch 129/300\n",
      "26400/26400 [==============================] - 3s 103us/sample - loss: 1.1392 - val_loss: 1.4716\n",
      "Epoch 130/300\n",
      "26400/26400 [==============================] - 3s 103us/sample - loss: 1.1333 - val_loss: 1.4843\n",
      "Epoch 131/300\n",
      "26400/26400 [==============================] - 3s 102us/sample - loss: 1.1191 - val_loss: 1.5091\n",
      "Epoch 132/300\n",
      "26400/26400 [==============================] - 3s 103us/sample - loss: 1.1190 - val_loss: 1.5293\n",
      "Epoch 133/300\n",
      "26400/26400 [==============================] - 3s 103us/sample - loss: 1.1331 - val_loss: 1.5218\n",
      "Epoch 134/300\n",
      "26400/26400 [==============================] - 3s 103us/sample - loss: 1.1192 - val_loss: 1.4768\n",
      "Epoch 135/300\n",
      "26400/26400 [==============================] - 3s 102us/sample - loss: 1.1225 - val_loss: 1.5610\n",
      "Epoch 136/300\n",
      "26400/26400 [==============================] - 3s 102us/sample - loss: 1.1227 - val_loss: 1.5076\n",
      "Epoch 137/300\n",
      "26400/26400 [==============================] - 3s 102us/sample - loss: 1.1108 - val_loss: 1.5544\n",
      "Epoch 138/300\n",
      "26400/26400 [==============================] - 3s 104us/sample - loss: 1.1216 - val_loss: 1.5498\n",
      "Epoch 139/300\n",
      "26400/26400 [==============================] - 3s 103us/sample - loss: 1.1223 - val_loss: 1.5204\n",
      "Epoch 140/300\n",
      "26400/26400 [==============================] - 3s 103us/sample - loss: 1.1216 - val_loss: 1.5649\n",
      "Epoch 141/300\n",
      "26400/26400 [==============================] - 3s 103us/sample - loss: 1.1106 - val_loss: 1.5178\n",
      "Epoch 142/300\n",
      "26400/26400 [==============================] - 3s 104us/sample - loss: 1.0999 - val_loss: 1.6022\n",
      "Epoch 143/300\n",
      "26400/26400 [==============================] - 3s 103us/sample - loss: 1.1100 - val_loss: 1.4785\n",
      "Epoch 144/300\n",
      "26400/26400 [==============================] - 3s 102us/sample - loss: 1.0960 - val_loss: 1.5395\n",
      "Epoch 145/300\n",
      "26400/26400 [==============================] - 3s 103us/sample - loss: 1.1007 - val_loss: 1.5262\n",
      "Epoch 146/300\n",
      "26400/26400 [==============================] - 3s 102us/sample - loss: 1.1117 - val_loss: 1.4854\n",
      "Epoch 147/300\n",
      "26400/26400 [==============================] - 3s 103us/sample - loss: 1.1051 - val_loss: 1.5841\n",
      "Epoch 148/300\n",
      "26400/26400 [==============================] - 3s 103us/sample - loss: 1.0973 - val_loss: 1.5954\n",
      "Epoch 149/300\n",
      "26400/26400 [==============================] - 3s 105us/sample - loss: 1.0972 - val_loss: 1.5187\n",
      "Epoch 150/300\n",
      "26400/26400 [==============================] - 3s 105us/sample - loss: 1.0866 - val_loss: 1.5273\n",
      "Epoch 151/300\n",
      "26400/26400 [==============================] - 3s 104us/sample - loss: 1.0831 - val_loss: 1.5298\n",
      "Epoch 152/300\n",
      "26400/26400 [==============================] - 3s 103us/sample - loss: 1.0903 - val_loss: 1.4883\n",
      "Epoch 153/300\n",
      "26400/26400 [==============================] - 3s 102us/sample - loss: 1.0841 - val_loss: 1.5161\n",
      "Epoch 154/300\n",
      "26400/26400 [==============================] - 3s 102us/sample - loss: 1.0806 - val_loss: 1.5296\n",
      "Epoch 155/300\n",
      "26400/26400 [==============================] - 3s 104us/sample - loss: 1.0844 - val_loss: 1.5275\n",
      "Epoch 156/300\n",
      "26400/26400 [==============================] - 3s 104us/sample - loss: 1.0865 - val_loss: 1.4671\n",
      "Epoch 157/300\n",
      "26400/26400 [==============================] - 3s 104us/sample - loss: 1.0747 - val_loss: 1.5496\n",
      "Epoch 158/300\n",
      "26400/26400 [==============================] - 3s 102us/sample - loss: 1.0814 - val_loss: 1.5054\n",
      "Epoch 159/300\n",
      "26400/26400 [==============================] - 3s 103us/sample - loss: 1.0760 - val_loss: 1.4654\n",
      "Epoch 160/300\n",
      "26400/26400 [==============================] - 3s 104us/sample - loss: 1.0848 - val_loss: 1.5121\n",
      "Epoch 161/300\n",
      "26400/26400 [==============================] - 3s 103us/sample - loss: 1.0825 - val_loss: 1.4838\n",
      "Epoch 162/300\n",
      "26400/26400 [==============================] - 3s 102us/sample - loss: 1.0763 - val_loss: 1.5135\n",
      "Epoch 163/300\n",
      "26400/26400 [==============================] - 3s 103us/sample - loss: 1.0678 - val_loss: 1.5379\n",
      "Epoch 164/300\n",
      "26400/26400 [==============================] - 3s 103us/sample - loss: 1.0702 - val_loss: 1.5254\n",
      "Epoch 165/300\n",
      "26400/26400 [==============================] - 3s 103us/sample - loss: 1.0682 - val_loss: 1.5683\n",
      "Epoch 166/300\n",
      "26400/26400 [==============================] - 3s 103us/sample - loss: 1.0614 - val_loss: 1.4811\n",
      "Epoch 167/300\n",
      "26400/26400 [==============================] - 3s 103us/sample - loss: 1.0666 - val_loss: 1.5147\n",
      "Epoch 168/300\n",
      "26400/26400 [==============================] - 3s 103us/sample - loss: 1.0752 - val_loss: 1.5105\n",
      "Epoch 169/300\n",
      "26400/26400 [==============================] - 3s 106us/sample - loss: 1.0595 - val_loss: 1.5167\n",
      "Epoch 170/300\n",
      "26400/26400 [==============================] - 3s 105us/sample - loss: 1.0661 - val_loss: 1.5046\n",
      "Epoch 171/300\n",
      "26400/26400 [==============================] - 3s 106us/sample - loss: 1.0550 - val_loss: 1.4577\n",
      "Epoch 172/300\n",
      "26400/26400 [==============================] - 3s 106us/sample - loss: 1.0617 - val_loss: 1.5326\n",
      "Epoch 173/300\n",
      "26400/26400 [==============================] - 3s 103us/sample - loss: 1.0575 - val_loss: 1.4893\n",
      "Epoch 174/300\n",
      "26400/26400 [==============================] - 3s 103us/sample - loss: 1.0588 - val_loss: 1.4694\n",
      "Epoch 175/300\n",
      "26400/26400 [==============================] - 3s 103us/sample - loss: 1.0477 - val_loss: 1.4554\n",
      "Epoch 176/300\n",
      "26400/26400 [==============================] - 3s 103us/sample - loss: 1.0477 - val_loss: 1.5931\n",
      "Epoch 177/300\n",
      "26400/26400 [==============================] - 3s 102us/sample - loss: 1.0528 - val_loss: 1.5444\n",
      "Epoch 178/300\n",
      "26400/26400 [==============================] - 3s 104us/sample - loss: 1.0521 - val_loss: 1.5255\n",
      "Epoch 179/300\n",
      "26400/26400 [==============================] - 3s 103us/sample - loss: 1.0388 - val_loss: 1.5037\n",
      "Epoch 180/300\n",
      "26400/26400 [==============================] - 3s 103us/sample - loss: 1.0479 - val_loss: 1.4803\n",
      "Epoch 181/300\n",
      "26400/26400 [==============================] - 3s 103us/sample - loss: 1.0475 - val_loss: 1.4774\n",
      "Epoch 182/300\n",
      "26400/26400 [==============================] - 3s 104us/sample - loss: 1.0438 - val_loss: 1.5304\n",
      "Epoch 183/300\n",
      "26400/26400 [==============================] - 3s 103us/sample - loss: 1.0424 - val_loss: 1.5254\n",
      "Epoch 184/300\n",
      "26400/26400 [==============================] - 3s 103us/sample - loss: 1.0428 - val_loss: 1.4779\n",
      "Epoch 185/300\n",
      "26400/26400 [==============================] - 3s 103us/sample - loss: 1.0455 - val_loss: 1.4817\n",
      "Epoch 186/300\n",
      "26400/26400 [==============================] - 3s 102us/sample - loss: 1.0387 - val_loss: 1.5138\n",
      "Epoch 187/300\n",
      "26400/26400 [==============================] - 3s 104us/sample - loss: 1.0368 - val_loss: 1.5138\n",
      "Epoch 188/300\n",
      "26400/26400 [==============================] - 3s 103us/sample - loss: 1.0447 - val_loss: 1.4889\n",
      "Epoch 189/300\n",
      "26400/26400 [==============================] - 3s 103us/sample - loss: 1.0247 - val_loss: 1.5452\n",
      "Epoch 190/300\n",
      "26400/26400 [==============================] - 3s 104us/sample - loss: 1.0355 - val_loss: 1.4575\n",
      "Epoch 191/300\n",
      "26400/26400 [==============================] - 3s 103us/sample - loss: 1.0385 - val_loss: 1.5055\n",
      "Epoch 192/300\n",
      "26400/26400 [==============================] - 3s 103us/sample - loss: 1.0292 - val_loss: 1.5613\n",
      "Epoch 193/300\n",
      "26400/26400 [==============================] - 3s 102us/sample - loss: 1.0301 - val_loss: 1.5039\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 194/300\n",
      "26400/26400 [==============================] - 3s 104us/sample - loss: 1.0358 - val_loss: 1.4920\n",
      "Epoch 195/300\n",
      "26400/26400 [==============================] - 3s 103us/sample - loss: 1.0341 - val_loss: 1.5042\n",
      "Epoch 196/300\n",
      "26400/26400 [==============================] - 3s 105us/sample - loss: 1.0267 - val_loss: 1.4797\n",
      "Epoch 197/300\n",
      "26400/26400 [==============================] - 3s 103us/sample - loss: 1.0235 - val_loss: 1.4772\n",
      "Epoch 198/300\n",
      "26400/26400 [==============================] - 3s 103us/sample - loss: 1.0311 - val_loss: 1.4276\n",
      "Epoch 199/300\n",
      "26400/26400 [==============================] - 3s 103us/sample - loss: 1.0320 - val_loss: 1.4581\n",
      "Epoch 200/300\n",
      "26400/26400 [==============================] - 3s 107us/sample - loss: 1.0172 - val_loss: 1.4360\n",
      "Epoch 201/300\n",
      "26400/26400 [==============================] - 3s 104us/sample - loss: 1.0260 - val_loss: 1.5046\n",
      "Epoch 202/300\n",
      "26400/26400 [==============================] - 3s 104us/sample - loss: 1.0195 - val_loss: 1.5160\n",
      "Epoch 203/300\n",
      "26400/26400 [==============================] - 3s 103us/sample - loss: 1.0242 - val_loss: 1.4599\n",
      "Epoch 204/300\n",
      "26400/26400 [==============================] - 3s 104us/sample - loss: 1.0225 - val_loss: 1.4511\n",
      "Epoch 205/300\n",
      "26400/26400 [==============================] - 3s 104us/sample - loss: 1.0194 - val_loss: 1.5264\n",
      "Epoch 206/300\n",
      "26400/26400 [==============================] - 3s 103us/sample - loss: 1.0117 - val_loss: 1.5034\n",
      "Epoch 207/300\n",
      "26400/26400 [==============================] - 3s 103us/sample - loss: 1.0211 - val_loss: 1.4802\n",
      "Epoch 208/300\n",
      "26400/26400 [==============================] - 3s 102us/sample - loss: 1.0218 - val_loss: 1.5307\n",
      "Epoch 209/300\n",
      "26400/26400 [==============================] - 3s 103us/sample - loss: 1.0124 - val_loss: 1.4887\n",
      "Epoch 210/300\n",
      "26400/26400 [==============================] - 3s 103us/sample - loss: 1.0081 - val_loss: 1.4870\n",
      "Epoch 211/300\n",
      "26400/26400 [==============================] - 3s 104us/sample - loss: 1.0093 - val_loss: 1.4623\n",
      "Epoch 212/300\n",
      "26400/26400 [==============================] - 3s 102us/sample - loss: 1.0134 - val_loss: 1.4433\n",
      "Epoch 213/300\n",
      "26400/26400 [==============================] - 3s 103us/sample - loss: 1.0209 - val_loss: 1.5166\n",
      "Epoch 214/300\n",
      "26400/26400 [==============================] - 3s 103us/sample - loss: 1.0107 - val_loss: 1.4560\n",
      "Epoch 215/300\n",
      "26400/26400 [==============================] - 3s 102us/sample - loss: 1.0122 - val_loss: 1.4806\n",
      "Epoch 216/300\n",
      "26400/26400 [==============================] - 3s 102us/sample - loss: 1.0049 - val_loss: 1.4442\n",
      "Epoch 217/300\n",
      "26400/26400 [==============================] - 3s 102us/sample - loss: 1.0011 - val_loss: 1.4497\n",
      "Epoch 218/300\n",
      "26400/26400 [==============================] - 3s 103us/sample - loss: 1.0059 - val_loss: 1.4344\n",
      "Epoch 219/300\n",
      "26400/26400 [==============================] - 3s 102us/sample - loss: 1.0013 - val_loss: 1.4305\n",
      "Epoch 220/300\n",
      "26400/26400 [==============================] - 3s 103us/sample - loss: 1.0085 - val_loss: 1.4247\n",
      "Epoch 221/300\n",
      "26400/26400 [==============================] - 3s 102us/sample - loss: 1.0135 - val_loss: 1.5075\n",
      "Epoch 222/300\n",
      "26400/26400 [==============================] - 3s 103us/sample - loss: 0.9920 - val_loss: 1.4771\n",
      "Epoch 223/300\n",
      "26400/26400 [==============================] - 3s 103us/sample - loss: 0.9998 - val_loss: 1.4484\n",
      "Epoch 224/300\n",
      "26400/26400 [==============================] - 3s 103us/sample - loss: 1.0001 - val_loss: 1.4156\n",
      "Epoch 225/300\n",
      "26400/26400 [==============================] - 3s 103us/sample - loss: 1.0068 - val_loss: 1.4522\n",
      "Epoch 226/300\n",
      "26400/26400 [==============================] - 3s 103us/sample - loss: 1.0046 - val_loss: 1.4982\n",
      "Epoch 227/300\n",
      "26400/26400 [==============================] - 3s 103us/sample - loss: 0.9990 - val_loss: 1.4039\n",
      "Epoch 228/300\n",
      "26400/26400 [==============================] - 3s 104us/sample - loss: 0.9927 - val_loss: 1.4422\n",
      "Epoch 229/300\n",
      "26400/26400 [==============================] - 3s 104us/sample - loss: 0.9853 - val_loss: 1.4810\n",
      "Epoch 230/300\n",
      "26400/26400 [==============================] - 3s 104us/sample - loss: 1.0018 - val_loss: 1.5008\n",
      "Epoch 231/300\n",
      "26400/26400 [==============================] - 3s 103us/sample - loss: 0.9977 - val_loss: 1.4965\n",
      "Epoch 232/300\n",
      "26400/26400 [==============================] - 3s 103us/sample - loss: 0.9941 - val_loss: 1.4644\n",
      "Epoch 233/300\n",
      "26400/26400 [==============================] - 3s 103us/sample - loss: 0.9866 - val_loss: 1.4395\n",
      "Epoch 234/300\n",
      "26400/26400 [==============================] - 3s 103us/sample - loss: 0.9972 - val_loss: 1.4622\n",
      "Epoch 235/300\n",
      "26400/26400 [==============================] - 3s 103us/sample - loss: 0.9935 - val_loss: 1.4423\n",
      "Epoch 236/300\n",
      "26400/26400 [==============================] - 3s 103us/sample - loss: 0.9831 - val_loss: 1.3959\n",
      "Epoch 237/300\n",
      "26400/26400 [==============================] - 3s 103us/sample - loss: 0.9980 - val_loss: 1.4634\n",
      "Epoch 238/300\n",
      "26400/26400 [==============================] - 3s 103us/sample - loss: 0.9864 - val_loss: 1.5187\n",
      "Epoch 239/300\n",
      "26400/26400 [==============================] - 3s 103us/sample - loss: 0.9817 - val_loss: 1.4731\n",
      "Epoch 240/300\n",
      "26400/26400 [==============================] - 3s 103us/sample - loss: 0.9813 - val_loss: 1.5105\n",
      "Epoch 241/300\n",
      "26400/26400 [==============================] - 3s 103us/sample - loss: 0.9920 - val_loss: 1.4939\n",
      "Epoch 242/300\n",
      "26400/26400 [==============================] - 3s 103us/sample - loss: 0.9839 - val_loss: 1.4420\n",
      "Epoch 243/300\n",
      "26400/26400 [==============================] - 3s 103us/sample - loss: 0.9867 - val_loss: 1.4575\n",
      "Epoch 244/300\n",
      "26400/26400 [==============================] - 3s 103us/sample - loss: 0.9763 - val_loss: 1.4175\n",
      "Epoch 245/300\n",
      "26400/26400 [==============================] - 3s 103us/sample - loss: 0.9885 - val_loss: 1.4784\n",
      "Epoch 246/300\n",
      "26400/26400 [==============================] - 3s 103us/sample - loss: 0.9850 - val_loss: 1.4402\n",
      "Epoch 247/300\n",
      "26400/26400 [==============================] - 3s 103us/sample - loss: 0.9853 - val_loss: 1.4151\n",
      "Epoch 248/300\n",
      "26400/26400 [==============================] - 3s 104us/sample - loss: 0.9863 - val_loss: 1.4659\n",
      "Epoch 249/300\n",
      "26400/26400 [==============================] - 3s 103us/sample - loss: 0.9858 - val_loss: 1.3883\n",
      "Epoch 250/300\n",
      "26400/26400 [==============================] - 3s 104us/sample - loss: 0.9802 - val_loss: 1.4622\n",
      "Epoch 251/300\n",
      "26400/26400 [==============================] - 3s 104us/sample - loss: 0.9763 - val_loss: 1.4441\n",
      "Epoch 252/300\n",
      "26400/26400 [==============================] - 3s 102us/sample - loss: 0.9694 - val_loss: 1.5012\n",
      "Epoch 253/300\n",
      "26400/26400 [==============================] - 3s 103us/sample - loss: 0.9744 - val_loss: 1.4828\n",
      "Epoch 254/300\n",
      "26400/26400 [==============================] - 3s 102us/sample - loss: 0.9722 - val_loss: 1.4883\n",
      "Epoch 255/300\n",
      "26400/26400 [==============================] - 3s 103us/sample - loss: 0.9798 - val_loss: 1.4666\n",
      "Epoch 256/300\n",
      "26400/26400 [==============================] - 3s 103us/sample - loss: 0.9688 - val_loss: 1.4620\n",
      "Epoch 257/300\n",
      "26400/26400 [==============================] - 3s 103us/sample - loss: 0.9641 - val_loss: 1.4644\n",
      "Epoch 258/300\n",
      "26400/26400 [==============================] - 3s 102us/sample - loss: 0.9750 - val_loss: 1.4827\n",
      "Epoch 259/300\n",
      "26400/26400 [==============================] - 3s 104us/sample - loss: 0.9778 - val_loss: 1.4661\n",
      "Epoch 260/300\n",
      "26400/26400 [==============================] - 3s 103us/sample - loss: 0.9668 - val_loss: 1.4555\n",
      "Epoch 261/300\n",
      "26400/26400 [==============================] - 3s 105us/sample - loss: 0.9646 - val_loss: 1.4717\n",
      "Epoch 262/300\n",
      "26400/26400 [==============================] - 3s 104us/sample - loss: 0.9738 - val_loss: 1.4633\n",
      "Epoch 263/300\n",
      "26400/26400 [==============================] - 3s 104us/sample - loss: 0.9670 - val_loss: 1.4212\n",
      "Epoch 264/300\n",
      "26400/26400 [==============================] - 3s 103us/sample - loss: 0.9810 - val_loss: 1.4232\n",
      "Epoch 265/300\n",
      "26400/26400 [==============================] - 3s 103us/sample - loss: 0.9737 - val_loss: 1.4931\n",
      "Epoch 266/300\n",
      "26400/26400 [==============================] - 3s 103us/sample - loss: 0.9652 - val_loss: 1.4745\n",
      "Epoch 267/300\n",
      "26400/26400 [==============================] - 3s 102us/sample - loss: 0.9606 - val_loss: 1.4021\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 268/300\n",
      "26400/26400 [==============================] - 3s 103us/sample - loss: 0.9582 - val_loss: 1.4855\n",
      "Epoch 269/300\n",
      "26400/26400 [==============================] - 3s 103us/sample - loss: 0.9607 - val_loss: 1.4988\n",
      "Epoch 270/300\n",
      "26400/26400 [==============================] - 3s 103us/sample - loss: 0.9621 - val_loss: 1.4829\n",
      "Epoch 271/300\n",
      "26400/26400 [==============================] - 3s 104us/sample - loss: 0.9674 - val_loss: 1.5070\n",
      "Epoch 272/300\n",
      "26400/26400 [==============================] - 3s 102us/sample - loss: 0.9486 - val_loss: 1.4438\n",
      "Epoch 273/300\n",
      "26400/26400 [==============================] - 3s 103us/sample - loss: 0.9644 - val_loss: 1.4443\n",
      "Epoch 274/300\n",
      "26400/26400 [==============================] - 3s 103us/sample - loss: 0.9578 - val_loss: 1.4600\n",
      "Epoch 275/300\n",
      "26400/26400 [==============================] - 3s 103us/sample - loss: 0.9638 - val_loss: 1.4231\n",
      "Epoch 276/300\n",
      "26400/26400 [==============================] - 3s 102us/sample - loss: 0.9598 - val_loss: 1.4672\n",
      "Epoch 277/300\n",
      "26400/26400 [==============================] - 3s 103us/sample - loss: 0.9521 - val_loss: 1.4146\n",
      "Epoch 278/300\n",
      "26400/26400 [==============================] - 3s 102us/sample - loss: 0.9550 - val_loss: 1.4226\n",
      "Epoch 279/300\n",
      "25920/26400 [============================>.] - ETA: 0s - loss: 0.9575Restoring model weights from the end of the best epoch.\n",
      "26400/26400 [==============================] - 3s 108us/sample - loss: 0.9574 - val_loss: 1.4417\n",
      "Epoch 00279: early stopping\n",
      "loss: 0.986 | val_loss: 1.388\n",
      "fold 4\n",
      "Train on 26400 samples, validate on 6600 samples\n",
      "Epoch 1/300\n",
      "26400/26400 [==============================] - 3s 130us/sample - loss: 2.5073 - val_loss: 2.2101\n",
      "Epoch 2/300\n",
      "26400/26400 [==============================] - 3s 103us/sample - loss: 2.2523 - val_loss: 2.0757\n",
      "Epoch 3/300\n",
      "26400/26400 [==============================] - 3s 105us/sample - loss: 2.1865 - val_loss: 2.2372\n",
      "Epoch 4/300\n",
      "26400/26400 [==============================] - 3s 106us/sample - loss: 2.1332 - val_loss: 2.0400\n",
      "Epoch 5/300\n",
      "26400/26400 [==============================] - 3s 105us/sample - loss: 2.1147 - val_loss: 1.9645\n",
      "Epoch 6/300\n",
      "26400/26400 [==============================] - 3s 106us/sample - loss: 2.0754 - val_loss: 1.9927\n",
      "Epoch 7/300\n",
      "26400/26400 [==============================] - 3s 103us/sample - loss: 2.0404 - val_loss: 2.0399\n",
      "Epoch 8/300\n",
      "26400/26400 [==============================] - 3s 103us/sample - loss: 2.0265 - val_loss: 1.9580\n",
      "Epoch 9/300\n",
      "26400/26400 [==============================] - 3s 104us/sample - loss: 1.9946 - val_loss: 1.9201\n",
      "Epoch 10/300\n",
      "26400/26400 [==============================] - 3s 104us/sample - loss: 1.9713 - val_loss: 1.9047\n",
      "Epoch 11/300\n",
      "26400/26400 [==============================] - 3s 103us/sample - loss: 1.9553 - val_loss: 1.9011\n",
      "Epoch 12/300\n",
      "26400/26400 [==============================] - 3s 104us/sample - loss: 1.9239 - val_loss: 1.8729\n",
      "Epoch 13/300\n",
      "26400/26400 [==============================] - 3s 104us/sample - loss: 1.9059 - val_loss: 1.8481\n",
      "Epoch 14/300\n",
      "26400/26400 [==============================] - 3s 103us/sample - loss: 1.8780 - val_loss: 1.8506\n",
      "Epoch 15/300\n",
      "26400/26400 [==============================] - 3s 102us/sample - loss: 1.8600 - val_loss: 1.8828\n",
      "Epoch 16/300\n",
      "26400/26400 [==============================] - 3s 102us/sample - loss: 1.8525 - val_loss: 1.9005\n",
      "Epoch 17/300\n",
      "26400/26400 [==============================] - 3s 103us/sample - loss: 1.8330 - val_loss: 1.8093\n",
      "Epoch 18/300\n",
      "26400/26400 [==============================] - 3s 102us/sample - loss: 1.8115 - val_loss: 1.7881\n",
      "Epoch 19/300\n",
      "26400/26400 [==============================] - 3s 103us/sample - loss: 1.7954 - val_loss: 1.8329\n",
      "Epoch 20/300\n",
      "26400/26400 [==============================] - 3s 104us/sample - loss: 1.7617 - val_loss: 1.7937\n",
      "Epoch 21/300\n",
      "26400/26400 [==============================] - 3s 103us/sample - loss: 1.7380 - val_loss: 1.7927\n",
      "Epoch 22/300\n",
      "26400/26400 [==============================] - 3s 104us/sample - loss: 1.7387 - val_loss: 1.8040\n",
      "Epoch 23/300\n",
      "26400/26400 [==============================] - 3s 102us/sample - loss: 1.7092 - val_loss: 1.7592\n",
      "Epoch 24/300\n",
      "26400/26400 [==============================] - 3s 102us/sample - loss: 1.7025 - val_loss: 1.7449\n",
      "Epoch 25/300\n",
      "26400/26400 [==============================] - 3s 102us/sample - loss: 1.6930 - val_loss: 1.7723\n",
      "Epoch 26/300\n",
      "26400/26400 [==============================] - 3s 103us/sample - loss: 1.6722 - val_loss: 1.8466\n",
      "Epoch 27/300\n",
      "26400/26400 [==============================] - 3s 103us/sample - loss: 1.6621 - val_loss: 1.7768\n",
      "Epoch 28/300\n",
      "26400/26400 [==============================] - 3s 103us/sample - loss: 1.6388 - val_loss: 1.7201\n",
      "Epoch 29/300\n",
      "26400/26400 [==============================] - 3s 102us/sample - loss: 1.6300 - val_loss: 1.7422\n",
      "Epoch 30/300\n",
      "26400/26400 [==============================] - 3s 102us/sample - loss: 1.6110 - val_loss: 1.7063\n",
      "Epoch 31/300\n",
      "26400/26400 [==============================] - 3s 105us/sample - loss: 1.6097 - val_loss: 1.7838\n",
      "Epoch 32/300\n",
      "26400/26400 [==============================] - 3s 103us/sample - loss: 1.5952 - val_loss: 1.7699\n",
      "Epoch 33/300\n",
      "26400/26400 [==============================] - 3s 104us/sample - loss: 1.5726 - val_loss: 1.8585\n",
      "Epoch 34/300\n",
      "26400/26400 [==============================] - 3s 104us/sample - loss: 1.5715 - val_loss: 1.7485\n",
      "Epoch 35/300\n",
      "26400/26400 [==============================] - 3s 103us/sample - loss: 1.5584 - val_loss: 1.7071\n",
      "Epoch 36/300\n",
      "26400/26400 [==============================] - 3s 103us/sample - loss: 1.5485 - val_loss: 1.7610\n",
      "Epoch 37/300\n",
      "26400/26400 [==============================] - 3s 103us/sample - loss: 1.5369 - val_loss: 1.6845\n",
      "Epoch 38/300\n",
      "26400/26400 [==============================] - 3s 103us/sample - loss: 1.5305 - val_loss: 1.7787\n",
      "Epoch 39/300\n",
      "26400/26400 [==============================] - 3s 103us/sample - loss: 1.5177 - val_loss: 1.7522\n",
      "Epoch 40/300\n",
      "26400/26400 [==============================] - 3s 103us/sample - loss: 1.5214 - val_loss: 1.6656\n",
      "Epoch 41/300\n",
      "26400/26400 [==============================] - 3s 103us/sample - loss: 1.5074 - val_loss: 1.6815\n",
      "Epoch 42/300\n",
      "26400/26400 [==============================] - 3s 102us/sample - loss: 1.4960 - val_loss: 1.6357\n",
      "Epoch 43/300\n",
      "26400/26400 [==============================] - 3s 103us/sample - loss: 1.4828 - val_loss: 1.7089\n",
      "Epoch 44/300\n",
      "26400/26400 [==============================] - 3s 102us/sample - loss: 1.4846 - val_loss: 1.6831\n",
      "Epoch 45/300\n",
      "26400/26400 [==============================] - 3s 103us/sample - loss: 1.4697 - val_loss: 1.6833\n",
      "Epoch 46/300\n",
      "26400/26400 [==============================] - 3s 102us/sample - loss: 1.4630 - val_loss: 1.6580\n",
      "Epoch 47/300\n",
      "26400/26400 [==============================] - 3s 102us/sample - loss: 1.4576 - val_loss: 1.6751\n",
      "Epoch 48/300\n",
      "26400/26400 [==============================] - 3s 104us/sample - loss: 1.4479 - val_loss: 1.6256\n",
      "Epoch 49/300\n",
      "26400/26400 [==============================] - 3s 102us/sample - loss: 1.4418 - val_loss: 1.8071\n",
      "Epoch 50/300\n",
      "26400/26400 [==============================] - 3s 103us/sample - loss: 1.4387 - val_loss: 1.6095\n",
      "Epoch 51/300\n",
      "26400/26400 [==============================] - 3s 102us/sample - loss: 1.4203 - val_loss: 1.6938\n",
      "Epoch 52/300\n",
      "26400/26400 [==============================] - 3s 103us/sample - loss: 1.4112 - val_loss: 1.6420\n",
      "Epoch 53/300\n",
      "26400/26400 [==============================] - 3s 103us/sample - loss: 1.4156 - val_loss: 1.6230\n",
      "Epoch 54/300\n",
      "26400/26400 [==============================] - 3s 104us/sample - loss: 1.4076 - val_loss: 1.6007\n",
      "Epoch 55/300\n",
      "26400/26400 [==============================] - 3s 103us/sample - loss: 1.3958 - val_loss: 1.6262\n",
      "Epoch 56/300\n",
      "26400/26400 [==============================] - 3s 104us/sample - loss: 1.3875 - val_loss: 1.6638\n",
      "Epoch 57/300\n",
      "26400/26400 [==============================] - 3s 103us/sample - loss: 1.3807 - val_loss: 1.6044\n",
      "Epoch 58/300\n",
      "26400/26400 [==============================] - 3s 103us/sample - loss: 1.3760 - val_loss: 1.6037\n",
      "Epoch 59/300\n",
      "26400/26400 [==============================] - 3s 102us/sample - loss: 1.3750 - val_loss: 1.5650\n",
      "Epoch 60/300\n",
      "26400/26400 [==============================] - 3s 103us/sample - loss: 1.3738 - val_loss: 1.6473\n",
      "Epoch 61/300\n",
      "26400/26400 [==============================] - 3s 103us/sample - loss: 1.3556 - val_loss: 1.6317\n",
      "Epoch 62/300\n",
      "26400/26400 [==============================] - 3s 103us/sample - loss: 1.3509 - val_loss: 1.5898\n",
      "Epoch 63/300\n",
      "26400/26400 [==============================] - 3s 102us/sample - loss: 1.3631 - val_loss: 1.6351\n",
      "Epoch 64/300\n",
      "26400/26400 [==============================] - 3s 103us/sample - loss: 1.3464 - val_loss: 1.6018\n",
      "Epoch 65/300\n",
      "26400/26400 [==============================] - 3s 103us/sample - loss: 1.3460 - val_loss: 1.6802\n",
      "Epoch 66/300\n",
      "26400/26400 [==============================] - 3s 103us/sample - loss: 1.3358 - val_loss: 1.6036\n",
      "Epoch 67/300\n",
      "26400/26400 [==============================] - 3s 102us/sample - loss: 1.3192 - val_loss: 1.5993\n",
      "Epoch 68/300\n",
      "26400/26400 [==============================] - 3s 102us/sample - loss: 1.3191 - val_loss: 1.5849\n",
      "Epoch 69/300\n",
      "26400/26400 [==============================] - 3s 102us/sample - loss: 1.3155 - val_loss: 1.6585\n",
      "Epoch 70/300\n",
      "26400/26400 [==============================] - 3s 103us/sample - loss: 1.3131 - val_loss: 1.5713\n",
      "Epoch 71/300\n",
      "26400/26400 [==============================] - 3s 104us/sample - loss: 1.3161 - val_loss: 1.6485\n",
      "Epoch 72/300\n",
      "26400/26400 [==============================] - 3s 103us/sample - loss: 1.2959 - val_loss: 1.5863\n",
      "Epoch 73/300\n",
      "26400/26400 [==============================] - 3s 102us/sample - loss: 1.2966 - val_loss: 1.6175\n",
      "Epoch 74/300\n",
      "26400/26400 [==============================] - 3s 102us/sample - loss: 1.2866 - val_loss: 1.5190\n",
      "Epoch 75/300\n",
      "26400/26400 [==============================] - 3s 103us/sample - loss: 1.2906 - val_loss: 1.5902\n",
      "Epoch 76/300\n",
      "26400/26400 [==============================] - 3s 103us/sample - loss: 1.2833 - val_loss: 1.5818\n",
      "Epoch 77/300\n",
      "26400/26400 [==============================] - 3s 102us/sample - loss: 1.2762 - val_loss: 1.6308\n",
      "Epoch 78/300\n",
      "26400/26400 [==============================] - 3s 103us/sample - loss: 1.2724 - val_loss: 1.5328\n",
      "Epoch 79/300\n",
      "26400/26400 [==============================] - 3s 103us/sample - loss: 1.2721 - val_loss: 1.5301\n",
      "Epoch 80/300\n",
      "26400/26400 [==============================] - 3s 103us/sample - loss: 1.2681 - val_loss: 1.5534\n",
      "Epoch 81/300\n",
      "26400/26400 [==============================] - 3s 103us/sample - loss: 1.2634 - val_loss: 1.6208\n",
      "Epoch 82/300\n",
      "26400/26400 [==============================] - 3s 104us/sample - loss: 1.2584 - val_loss: 1.5815\n",
      "Epoch 83/300\n",
      "26400/26400 [==============================] - 3s 104us/sample - loss: 1.2573 - val_loss: 1.6070\n",
      "Epoch 84/300\n",
      "26400/26400 [==============================] - 3s 103us/sample - loss: 1.2505 - val_loss: 1.5513\n",
      "Epoch 85/300\n",
      "26400/26400 [==============================] - 3s 103us/sample - loss: 1.2606 - val_loss: 1.6246\n",
      "Epoch 86/300\n",
      "26400/26400 [==============================] - 3s 103us/sample - loss: 1.2500 - val_loss: 1.5549\n",
      "Epoch 87/300\n",
      "26400/26400 [==============================] - 3s 105us/sample - loss: 1.2391 - val_loss: 1.5707\n",
      "Epoch 88/300\n",
      "26400/26400 [==============================] - 3s 103us/sample - loss: 1.2309 - val_loss: 1.5136\n",
      "Epoch 89/300\n",
      "26400/26400 [==============================] - 3s 103us/sample - loss: 1.2364 - val_loss: 1.5469\n",
      "Epoch 90/300\n",
      "26400/26400 [==============================] - 3s 103us/sample - loss: 1.2362 - val_loss: 1.5419\n",
      "Epoch 91/300\n",
      "26400/26400 [==============================] - 3s 105us/sample - loss: 1.2408 - val_loss: 1.6575\n",
      "Epoch 92/300\n",
      "26400/26400 [==============================] - 3s 103us/sample - loss: 1.2290 - val_loss: 1.5362\n",
      "Epoch 93/300\n",
      "26400/26400 [==============================] - 3s 105us/sample - loss: 1.2240 - val_loss: 1.5780\n",
      "Epoch 94/300\n",
      "26400/26400 [==============================] - 3s 104us/sample - loss: 1.2187 - val_loss: 1.5464\n",
      "Epoch 95/300\n",
      "26400/26400 [==============================] - 3s 104us/sample - loss: 1.2057 - val_loss: 1.5256\n",
      "Epoch 96/300\n",
      "26400/26400 [==============================] - 3s 104us/sample - loss: 1.2098 - val_loss: 1.5506\n",
      "Epoch 97/300\n",
      "26400/26400 [==============================] - 3s 104us/sample - loss: 1.1981 - val_loss: 1.5195\n",
      "Epoch 98/300\n",
      "26400/26400 [==============================] - 3s 102us/sample - loss: 1.2047 - val_loss: 1.6405\n",
      "Epoch 99/300\n",
      "26400/26400 [==============================] - 3s 103us/sample - loss: 1.1942 - val_loss: 1.5074\n",
      "Epoch 100/300\n",
      "26400/26400 [==============================] - 3s 104us/sample - loss: 1.1987 - val_loss: 1.5303\n",
      "Epoch 101/300\n",
      "26400/26400 [==============================] - 3s 104us/sample - loss: 1.1820 - val_loss: 1.5579\n",
      "Epoch 102/300\n",
      "26400/26400 [==============================] - 3s 102us/sample - loss: 1.1932 - val_loss: 1.5460\n",
      "Epoch 103/300\n",
      "26400/26400 [==============================] - 3s 103us/sample - loss: 1.1927 - val_loss: 1.5088\n",
      "Epoch 104/300\n",
      "26400/26400 [==============================] - 3s 103us/sample - loss: 1.1909 - val_loss: 1.5323\n",
      "Epoch 105/300\n",
      "26400/26400 [==============================] - 3s 103us/sample - loss: 1.1883 - val_loss: 1.5366\n",
      "Epoch 106/300\n",
      "26400/26400 [==============================] - 3s 103us/sample - loss: 1.1850 - val_loss: 1.5332\n",
      "Epoch 107/300\n",
      "26400/26400 [==============================] - 3s 103us/sample - loss: 1.1716 - val_loss: 1.5028\n",
      "Epoch 108/300\n",
      "26400/26400 [==============================] - 3s 103us/sample - loss: 1.1808 - val_loss: 1.4847\n",
      "Epoch 109/300\n",
      "26400/26400 [==============================] - 3s 103us/sample - loss: 1.1759 - val_loss: 1.5049\n",
      "Epoch 110/300\n",
      "26400/26400 [==============================] - 3s 103us/sample - loss: 1.1724 - val_loss: 1.5466\n",
      "Epoch 111/300\n",
      "26400/26400 [==============================] - 3s 102us/sample - loss: 1.1756 - val_loss: 1.5176\n",
      "Epoch 112/300\n",
      "26400/26400 [==============================] - 3s 103us/sample - loss: 1.1692 - val_loss: 1.5386\n",
      "Epoch 113/300\n",
      "26400/26400 [==============================] - 3s 102us/sample - loss: 1.1677 - val_loss: 1.5250\n",
      "Epoch 114/300\n",
      "26400/26400 [==============================] - 3s 103us/sample - loss: 1.1627 - val_loss: 1.5836\n",
      "Epoch 115/300\n",
      "26400/26400 [==============================] - 3s 103us/sample - loss: 1.1704 - val_loss: 1.5507\n",
      "Epoch 116/300\n",
      "26400/26400 [==============================] - 3s 102us/sample - loss: 1.1445 - val_loss: 1.4684\n",
      "Epoch 117/300\n",
      "26400/26400 [==============================] - 3s 106us/sample - loss: 1.1464 - val_loss: 1.4926\n",
      "Epoch 118/300\n",
      "26400/26400 [==============================] - 3s 106us/sample - loss: 1.1505 - val_loss: 1.5312\n",
      "Epoch 119/300\n",
      "26400/26400 [==============================] - 3s 107us/sample - loss: 1.1457 - val_loss: 1.5533\n",
      "Epoch 120/300\n",
      "26400/26400 [==============================] - 3s 107us/sample - loss: 1.1537 - val_loss: 1.5257\n",
      "Epoch 121/300\n",
      "26400/26400 [==============================] - 3s 103us/sample - loss: 1.1479 - val_loss: 1.5000\n",
      "Epoch 122/300\n",
      "26400/26400 [==============================] - 3s 104us/sample - loss: 1.1481 - val_loss: 1.5902\n",
      "Epoch 123/300\n",
      "26400/26400 [==============================] - 3s 103us/sample - loss: 1.1468 - val_loss: 1.5503\n",
      "Epoch 124/300\n",
      "26400/26400 [==============================] - 3s 103us/sample - loss: 1.1405 - val_loss: 1.4747\n",
      "Epoch 125/300\n",
      "26400/26400 [==============================] - 3s 103us/sample - loss: 1.1251 - val_loss: 1.4942\n",
      "Epoch 126/300\n",
      "26400/26400 [==============================] - 3s 103us/sample - loss: 1.1226 - val_loss: 1.5185\n",
      "Epoch 127/300\n",
      "26400/26400 [==============================] - 3s 104us/sample - loss: 1.1264 - val_loss: 1.4890\n",
      "Epoch 128/300\n",
      "26400/26400 [==============================] - 3s 104us/sample - loss: 1.1264 - val_loss: 1.5019\n",
      "Epoch 129/300\n",
      "26400/26400 [==============================] - 3s 103us/sample - loss: 1.1343 - val_loss: 1.5438\n",
      "Epoch 130/300\n",
      "26400/26400 [==============================] - 3s 102us/sample - loss: 1.1289 - val_loss: 1.4722\n",
      "Epoch 131/300\n",
      "26400/26400 [==============================] - 3s 102us/sample - loss: 1.1182 - val_loss: 1.5364\n",
      "Epoch 132/300\n",
      "26400/26400 [==============================] - 3s 102us/sample - loss: 1.1298 - val_loss: 1.4868\n",
      "Epoch 133/300\n",
      "26400/26400 [==============================] - 3s 103us/sample - loss: 1.1235 - val_loss: 1.4675\n",
      "Epoch 134/300\n",
      "26400/26400 [==============================] - 3s 102us/sample - loss: 1.1113 - val_loss: 1.4896\n",
      "Epoch 135/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26400/26400 [==============================] - 3s 103us/sample - loss: 1.1224 - val_loss: 1.5050\n",
      "Epoch 136/300\n",
      "26400/26400 [==============================] - 3s 103us/sample - loss: 1.1093 - val_loss: 1.4655\n",
      "Epoch 137/300\n",
      "26400/26400 [==============================] - 3s 104us/sample - loss: 1.1001 - val_loss: 1.5506\n",
      "Epoch 138/300\n",
      "26400/26400 [==============================] - 3s 103us/sample - loss: 1.1010 - val_loss: 1.5054\n",
      "Epoch 139/300\n",
      "26400/26400 [==============================] - 3s 102us/sample - loss: 1.1194 - val_loss: 1.5056\n",
      "Epoch 140/300\n",
      "26400/26400 [==============================] - 3s 103us/sample - loss: 1.1026 - val_loss: 1.5196\n",
      "Epoch 141/300\n",
      "26400/26400 [==============================] - 3s 103us/sample - loss: 1.1041 - val_loss: 1.5030\n",
      "Epoch 142/300\n",
      "26400/26400 [==============================] - 3s 103us/sample - loss: 1.0948 - val_loss: 1.5020\n",
      "Epoch 143/300\n",
      "26400/26400 [==============================] - 3s 105us/sample - loss: 1.1065 - val_loss: 1.4970\n",
      "Epoch 144/300\n",
      "26400/26400 [==============================] - 3s 104us/sample - loss: 1.0998 - val_loss: 1.4769\n",
      "Epoch 145/300\n",
      "26400/26400 [==============================] - 3s 104us/sample - loss: 1.1012 - val_loss: 1.5095\n",
      "Epoch 146/300\n",
      "26400/26400 [==============================] - 3s 102us/sample - loss: 1.0854 - val_loss: 1.4787\n",
      "Epoch 147/300\n",
      "26400/26400 [==============================] - 3s 103us/sample - loss: 1.0895 - val_loss: 1.5389\n",
      "Epoch 148/300\n",
      "26400/26400 [==============================] - 3s 102us/sample - loss: 1.0871 - val_loss: 1.5331\n",
      "Epoch 149/300\n",
      "26400/26400 [==============================] - 3s 103us/sample - loss: 1.1007 - val_loss: 1.4607\n",
      "Epoch 150/300\n",
      "26400/26400 [==============================] - 3s 103us/sample - loss: 1.0907 - val_loss: 1.4589\n",
      "Epoch 151/300\n",
      "26400/26400 [==============================] - 3s 103us/sample - loss: 1.0784 - val_loss: 1.5399\n",
      "Epoch 152/300\n",
      "26400/26400 [==============================] - 3s 102us/sample - loss: 1.0873 - val_loss: 1.5184\n",
      "Epoch 153/300\n",
      "26400/26400 [==============================] - 3s 102us/sample - loss: 1.0866 - val_loss: 1.5070\n",
      "Epoch 154/300\n",
      "26400/26400 [==============================] - 3s 102us/sample - loss: 1.0787 - val_loss: 1.4871\n",
      "Epoch 155/300\n",
      "26400/26400 [==============================] - 3s 103us/sample - loss: 1.0759 - val_loss: 1.5531\n",
      "Epoch 156/300\n",
      "26400/26400 [==============================] - 3s 102us/sample - loss: 1.0840 - val_loss: 1.4750\n",
      "Epoch 157/300\n",
      "26400/26400 [==============================] - 3s 102us/sample - loss: 1.0731 - val_loss: 1.5009\n",
      "Epoch 158/300\n",
      "26400/26400 [==============================] - 3s 102us/sample - loss: 1.0690 - val_loss: 1.5012\n",
      "Epoch 159/300\n",
      "26400/26400 [==============================] - 3s 103us/sample - loss: 1.0772 - val_loss: 1.5085\n",
      "Epoch 160/300\n",
      "26400/26400 [==============================] - 3s 102us/sample - loss: 1.0667 - val_loss: 1.4721\n",
      "Epoch 161/300\n",
      "26400/26400 [==============================] - 3s 102us/sample - loss: 1.0826 - val_loss: 1.4989\n",
      "Epoch 162/300\n",
      "26400/26400 [==============================] - 3s 102us/sample - loss: 1.0752 - val_loss: 1.4518\n",
      "Epoch 163/300\n",
      "26400/26400 [==============================] - 3s 102us/sample - loss: 1.0728 - val_loss: 1.4430\n",
      "Epoch 164/300\n",
      "26400/26400 [==============================] - 3s 103us/sample - loss: 1.0614 - val_loss: 1.5209\n",
      "Epoch 165/300\n",
      "26400/26400 [==============================] - 3s 102us/sample - loss: 1.0707 - val_loss: 1.4402\n",
      "Epoch 166/300\n",
      "26400/26400 [==============================] - 3s 103us/sample - loss: 1.0599 - val_loss: 1.4802\n",
      "Epoch 167/300\n",
      "26400/26400 [==============================] - 3s 103us/sample - loss: 1.0549 - val_loss: 1.5109\n",
      "Epoch 168/300\n",
      "26400/26400 [==============================] - 3s 103us/sample - loss: 1.0611 - val_loss: 1.4804\n",
      "Epoch 169/300\n",
      "26400/26400 [==============================] - 3s 102us/sample - loss: 1.0571 - val_loss: 1.5340\n",
      "Epoch 170/300\n",
      "26400/26400 [==============================] - 3s 103us/sample - loss: 1.0646 - val_loss: 1.4845\n",
      "Epoch 171/300\n",
      "26400/26400 [==============================] - 3s 103us/sample - loss: 1.0631 - val_loss: 1.4394\n",
      "Epoch 172/300\n",
      "26400/26400 [==============================] - 3s 102us/sample - loss: 1.0498 - val_loss: 1.4721\n",
      "Epoch 173/300\n",
      "26400/26400 [==============================] - 3s 103us/sample - loss: 1.0550 - val_loss: 1.4856\n",
      "Epoch 174/300\n",
      "26400/26400 [==============================] - 3s 102us/sample - loss: 1.0481 - val_loss: 1.4521\n",
      "Epoch 175/300\n",
      "26400/26400 [==============================] - 3s 102us/sample - loss: 1.0587 - val_loss: 1.4576\n",
      "Epoch 176/300\n",
      "26400/26400 [==============================] - 3s 102us/sample - loss: 1.0536 - val_loss: 1.5282\n",
      "Epoch 177/300\n",
      "26400/26400 [==============================] - 3s 103us/sample - loss: 1.0347 - val_loss: 1.4236\n",
      "Epoch 178/300\n",
      "26400/26400 [==============================] - 3s 103us/sample - loss: 1.0482 - val_loss: 1.4927\n",
      "Epoch 179/300\n",
      "26400/26400 [==============================] - 3s 102us/sample - loss: 1.0537 - val_loss: 1.5155\n",
      "Epoch 180/300\n",
      "26400/26400 [==============================] - 3s 103us/sample - loss: 1.0431 - val_loss: 1.5933\n",
      "Epoch 181/300\n",
      "26400/26400 [==============================] - 3s 102us/sample - loss: 1.0466 - val_loss: 1.4878\n",
      "Epoch 182/300\n",
      "26400/26400 [==============================] - 3s 103us/sample - loss: 1.0421 - val_loss: 1.4775\n",
      "Epoch 183/300\n",
      "26400/26400 [==============================] - 3s 103us/sample - loss: 1.0279 - val_loss: 1.4826\n",
      "Epoch 184/300\n",
      "26400/26400 [==============================] - 3s 103us/sample - loss: 1.0363 - val_loss: 1.4636\n",
      "Epoch 185/300\n",
      "26400/26400 [==============================] - 3s 103us/sample - loss: 1.0388 - val_loss: 1.4990\n",
      "Epoch 186/300\n",
      "26400/26400 [==============================] - 3s 103us/sample - loss: 1.0285 - val_loss: 1.4488\n",
      "Epoch 187/300\n",
      "26400/26400 [==============================] - 3s 103us/sample - loss: 1.0317 - val_loss: 1.4734\n",
      "Epoch 188/300\n",
      "26400/26400 [==============================] - 3s 103us/sample - loss: 1.0327 - val_loss: 1.4836\n",
      "Epoch 189/300\n",
      "26400/26400 [==============================] - 3s 104us/sample - loss: 1.0303 - val_loss: 1.4721\n",
      "Epoch 190/300\n",
      "26400/26400 [==============================] - 3s 103us/sample - loss: 1.0370 - val_loss: 1.4590\n",
      "Epoch 191/300\n",
      "26400/26400 [==============================] - 3s 103us/sample - loss: 1.0316 - val_loss: 1.4686\n",
      "Epoch 192/300\n",
      "26400/26400 [==============================] - 3s 102us/sample - loss: 1.0333 - val_loss: 1.5427\n",
      "Epoch 193/300\n",
      "26400/26400 [==============================] - 3s 104us/sample - loss: 1.0318 - val_loss: 1.4683\n",
      "Epoch 194/300\n",
      "26400/26400 [==============================] - 3s 103us/sample - loss: 1.0258 - val_loss: 1.4646\n",
      "Epoch 195/300\n",
      "26400/26400 [==============================] - 3s 103us/sample - loss: 1.0189 - val_loss: 1.4285\n",
      "Epoch 196/300\n",
      "26400/26400 [==============================] - 3s 103us/sample - loss: 1.0309 - val_loss: 1.5071\n",
      "Epoch 197/300\n",
      "26400/26400 [==============================] - 3s 103us/sample - loss: 1.0317 - val_loss: 1.4663\n",
      "Epoch 198/300\n",
      "26400/26400 [==============================] - 3s 102us/sample - loss: 1.0180 - val_loss: 1.5106\n",
      "Epoch 199/300\n",
      "26400/26400 [==============================] - 3s 103us/sample - loss: 1.0157 - val_loss: 1.5258\n",
      "Epoch 200/300\n",
      "26400/26400 [==============================] - 3s 102us/sample - loss: 1.0241 - val_loss: 1.5377\n",
      "Epoch 201/300\n",
      "26400/26400 [==============================] - 3s 102us/sample - loss: 1.0152 - val_loss: 1.4980\n",
      "Epoch 202/300\n",
      "26400/26400 [==============================] - 3s 102us/sample - loss: 1.0221 - val_loss: 1.3926\n",
      "Epoch 203/300\n",
      "26400/26400 [==============================] - 3s 102us/sample - loss: 1.0171 - val_loss: 1.4481\n",
      "Epoch 204/300\n",
      "26400/26400 [==============================] - 3s 103us/sample - loss: 1.0134 - val_loss: 1.4997\n",
      "Epoch 205/300\n",
      "26400/26400 [==============================] - 3s 102us/sample - loss: 1.0037 - val_loss: 1.4146\n",
      "Epoch 206/300\n",
      "26400/26400 [==============================] - 3s 105us/sample - loss: 1.0181 - val_loss: 1.4312\n",
      "Epoch 207/300\n",
      "26400/26400 [==============================] - 3s 105us/sample - loss: 1.0149 - val_loss: 1.4754\n",
      "Epoch 208/300\n",
      "26400/26400 [==============================] - 3s 103us/sample - loss: 1.0116 - val_loss: 1.4865\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 209/300\n",
      "26400/26400 [==============================] - 3s 102us/sample - loss: 1.0166 - val_loss: 1.4731\n",
      "Epoch 210/300\n",
      "26400/26400 [==============================] - 3s 103us/sample - loss: 1.0129 - val_loss: 1.4426\n",
      "Epoch 211/300\n",
      "26400/26400 [==============================] - 3s 104us/sample - loss: 1.0158 - val_loss: 1.4439\n",
      "Epoch 212/300\n",
      "26400/26400 [==============================] - 3s 102us/sample - loss: 1.0095 - val_loss: 1.4113\n",
      "Epoch 213/300\n",
      "26400/26400 [==============================] - 3s 103us/sample - loss: 1.0012 - val_loss: 1.4382\n",
      "Epoch 214/300\n",
      "26400/26400 [==============================] - 3s 103us/sample - loss: 1.0129 - val_loss: 1.4717\n",
      "Epoch 215/300\n",
      "26400/26400 [==============================] - 3s 104us/sample - loss: 1.0057 - val_loss: 1.4655\n",
      "Epoch 216/300\n",
      "26400/26400 [==============================] - 3s 103us/sample - loss: 1.0046 - val_loss: 1.4391\n",
      "Epoch 217/300\n",
      "26400/26400 [==============================] - 3s 104us/sample - loss: 1.0056 - val_loss: 1.4259\n",
      "Epoch 218/300\n",
      "26400/26400 [==============================] - 3s 103us/sample - loss: 0.9987 - val_loss: 1.4200\n",
      "Epoch 219/300\n",
      "26400/26400 [==============================] - 3s 103us/sample - loss: 0.9926 - val_loss: 1.5091\n",
      "Epoch 220/300\n",
      "26400/26400 [==============================] - 3s 103us/sample - loss: 1.0094 - val_loss: 1.5156\n",
      "Epoch 221/300\n",
      "26400/26400 [==============================] - 3s 104us/sample - loss: 1.0035 - val_loss: 1.4508\n",
      "Epoch 222/300\n",
      "26400/26400 [==============================] - 3s 103us/sample - loss: 1.0020 - val_loss: 1.4786\n",
      "Epoch 223/300\n",
      "26400/26400 [==============================] - 3s 103us/sample - loss: 1.0042 - val_loss: 1.4333\n",
      "Epoch 224/300\n",
      "26400/26400 [==============================] - 3s 103us/sample - loss: 1.0058 - val_loss: 1.5442\n",
      "Epoch 225/300\n",
      "26400/26400 [==============================] - 3s 103us/sample - loss: 0.9918 - val_loss: 1.5017\n",
      "Epoch 226/300\n",
      "26400/26400 [==============================] - 3s 102us/sample - loss: 1.0063 - val_loss: 1.4307\n",
      "Epoch 227/300\n",
      "26400/26400 [==============================] - 3s 102us/sample - loss: 0.9984 - val_loss: 1.4027\n",
      "Epoch 228/300\n",
      "26400/26400 [==============================] - 3s 103us/sample - loss: 1.0066 - val_loss: 1.4274\n",
      "Epoch 229/300\n",
      "26400/26400 [==============================] - 3s 103us/sample - loss: 0.9824 - val_loss: 1.4446\n",
      "Epoch 230/300\n",
      "26400/26400 [==============================] - 3s 103us/sample - loss: 0.9831 - val_loss: 1.4856\n",
      "Epoch 231/300\n",
      "26400/26400 [==============================] - 3s 104us/sample - loss: 0.9866 - val_loss: 1.4611\n",
      "Epoch 232/300\n",
      "26048/26400 [============================>.] - ETA: 0s - loss: 0.9872Restoring model weights from the end of the best epoch.\n",
      "26400/26400 [==============================] - 3s 111us/sample - loss: 0.9861 - val_loss: 1.4643\n",
      "Epoch 00232: early stopping\n",
      "loss: 1.022 | val_loss: 1.393\n",
      "CPU times: user 1h 5min 42s, sys: 4min 31s, total: 1h 10min 13s\n",
      "Wall time: 57min 46s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# n_fold = 5\n",
    "folds = KFold(n_splits=n_fold, shuffle=True, random_state=42)\n",
    "# 将每折预测结果保存到NN_oof里面，为了后面stacking\n",
    "NN_oof = np.zeros(len(train_X))\n",
    "\n",
    "NN_predictions = np.zeros(len(test_X))\n",
    "\n",
    "# 进行5折交叉验证\n",
    "for fold_, (trn_idx, val_idx) in enumerate(folds.split(train_X,train_y.values)):\n",
    "    strLog = \"fold {}\".format(fold_)\n",
    "    print(strLog)\n",
    "    \n",
    "    # 根据交叉验证得到训练集，测试集的X和y\n",
    "    X_tr, X_val = train_X[train_columns].iloc[trn_idx], train_X[train_columns].iloc[val_idx]\n",
    "    y_tr, y_val = train_y.iloc[trn_idx], train_y.iloc[val_idx]\n",
    "    \n",
    "    # 构造模型\n",
    "    model = create_model(train_X.shape[-1])\n",
    "    \n",
    "    # 迭代500个epoch，每个epoch的batch大小为64\n",
    "    model.fit(X_tr, y_tr, epochs=500, batch_size=64, verbose=1, callbacks=[call_ES,], validation_data=[X_val, y_val]) #\n",
    "    \n",
    "    # 得到NN的oof\n",
    "    NN_oof[val_idx] = model.predict(X_val)[:,0]\n",
    "    # 对NN预测结果取平均\n",
    "    NN_predictions += model.predict(test_X[train_columns])[:,0] / folds.n_splits\n",
    "    history = model.history.history\n",
    "    tr_loss = history[\"loss\"]\n",
    "    val_loss = history[\"val_loss\"]\n",
    "    print(f\"loss: {tr_loss[-patience-1]:.3f} | val_loss: {val_loss[-patience-1]:.3f}\")\n",
    "#     break\n",
    " \n",
    "# 得到cv_score的成绩\n",
    "cv_score = mean_absolute_error(train_y, NN_oof)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>seg_id</th>\n",
       "      <th>time_to_failure</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>seg_00030f</td>\n",
       "      <td>3.248064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>seg_0012b5</td>\n",
       "      <td>5.236308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>seg_00184e</td>\n",
       "      <td>4.278768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>seg_003339</td>\n",
       "      <td>7.400967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>seg_0042cc</td>\n",
       "      <td>6.239193</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       seg_id  time_to_failure\n",
       "0  seg_00030f         3.248064\n",
       "1  seg_0012b5         5.236308\n",
       "2  seg_00184e         4.278768\n",
       "3  seg_003339         7.400967\n",
       "4  seg_0042cc         6.239193"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 保存结果\n",
    "today = str(datetime.date.today())\n",
    "submission = pd.read_csv('../input/LANL-Earthquake-Prediction/sample_submission.csv')\n",
    "NN_saved=pd.DataFrame(NN_oof,columns=['oof'])\n",
    "NN_saved.to_csv('nn_oof.csv',index=False)\n",
    "submission[\"time_to_failure\"] = NN_predictions\n",
    "submission.to_csv(f'NN_submission_{cv_score:.3f}.csv', index=False)\n",
    "submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.4223067946969568\n"
     ]
    }
   ],
   "source": [
    "print(cv_score)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
